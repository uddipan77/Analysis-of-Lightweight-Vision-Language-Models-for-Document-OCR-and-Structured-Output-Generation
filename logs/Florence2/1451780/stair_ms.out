### Starting TaskPrologue of job 1451780 on tg072 at Sat Nov 29 01:21:11 PM CET 2025
Running on cores 0-1,8-9,16-17,24-25 with governor ondemand
Sat Nov 29 13:21:11 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           On  |   00000000:18:00.0 Off |                    0 |
| N/A   53C    P0             32W /  250W |       0MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

========================================
Florence-2 OCR Fine-tuning Job Configuration:
========================================
Job ID: 1451780
Log Directory: /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/logs/Florence2/1451780
CUDA Device: 0
Job started at: Sat Nov 29 01:21:13 PM CET 2025
========================================
Dataset: Staircase Dataset
Loading datasets...
Loaded 115 training samples
Loaded 25 validation samples
Loaded 24 test samples
Using device: cuda
Output directory: /home/vault/iwi5/iwi5298h/models_image_text/florence2/multi/stair/lora_multistage_run_20251129_132140
Loading Florence-2 model...
Applying LoRA...
âœ… Model with LoRA loaded!
Trainable params: 11,321,344 (1.44%)
LoRA modules: 408
Preparing datasets...
Train dataset size: 115
Validation dataset size: 25

===== STAGE 1: Warm-up training (no eval, teacher forcing) =====

Starting Stage 1 training...
{'loss': 7.6572, 'grad_norm': 10.487262725830078, 'learning_rate': 0.00010800000000000001, 'epoch': 0.69}
{'loss': 3.1851, 'grad_norm': 2.7109034061431885, 'learning_rate': 0.000228, 'epoch': 1.34}
{'loss': 1.7382, 'grad_norm': 7.443561553955078, 'learning_rate': 0.000348, 'epoch': 2.0}
{'loss': 1.6549, 'grad_norm': 0.9627166390419006, 'learning_rate': 0.00046800000000000005, 'epoch': 2.69}
{'loss': 1.5805, 'grad_norm': 2.434274435043335, 'learning_rate': 0.0005880000000000001, 'epoch': 3.34}
{'loss': 1.5507, 'grad_norm': 5.045059680938721, 'learning_rate': 0.00038400000000000006, 'epoch': 4.0}
{'loss': 1.5183, 'grad_norm': 0.7388930320739746, 'learning_rate': 0.000144, 'epoch': 4.69}
{'train_runtime': 469.6811, 'train_samples_per_second': 1.224, 'train_steps_per_second': 0.16, 'train_loss': 2.6176939646402997, 'epoch': 5.0}

===== STAGE 2: Main training (eval each epoch, CER-based best model) =====

Starting Stage 2 training (with generation-based CER eval)...
{'loss': 1.4942, 'grad_norm': 0.15100722014904022, 'learning_rate': 3.6e-05, 'epoch': 0.69}
{'eval_cer_token_level': 0.0003954915312092808, 'eval_loss': 1.4823193550109863, 'eval_runtime': 15.0216, 'eval_samples_per_second': 1.664, 'eval_steps_per_second': 0.865, 'epoch': 1.0}

ðŸ”Ž Running autoregressive validation CER (generation)...
ðŸ”š Autoregressive validation CER: 0.8346 (83.46%)

ðŸ“Š Epoch 1 - Generation-based Validation CER: 0.8346 (83.46%)
ðŸŽ¯ New best CER: 0.8346 (improved by inf)
âœ… Model saved to /home/vault/iwi5/iwi5298h/models_image_text/florence2/multi/stair/lora_multistage_run_20251129_132140/best_model

{'loss': 1.4886, 'grad_norm': 0.35666561126708984, 'learning_rate': 7.6e-05, 'epoch': 1.34}
{'loss': 1.4815, 'grad_norm': 0.27444806694984436, 'learning_rate': 0.000116, 'epoch': 2.0}
{'eval_cer_token_level': 0.0, 'eval_loss': 1.491708517074585, 'eval_runtime': 14.3685, 'eval_samples_per_second': 1.74, 'eval_steps_per_second': 0.905, 'epoch': 2.0}

ðŸ”Ž Running autoregressive validation CER (generation)...
ðŸ”š Autoregressive validation CER: 0.8336 (83.36%)

ðŸ“Š Epoch 2 - Generation-based Validation CER: 0.8336 (83.36%)
ðŸŽ¯ New best CER: 0.8336 (improved by 0.0009)
âœ… Model saved to /home/vault/iwi5/iwi5298h/models_image_text/florence2/multi/stair/lora_multistage_run_20251129_132140/best_model

{'loss': 1.4742, 'grad_norm': 0.2142789512872696, 'learning_rate': 0.00015600000000000002, 'epoch': 2.69}
{'eval_cer_token_level': 0.0, 'eval_loss': 1.4821102619171143, 'eval_runtime': 14.0475, 'eval_samples_per_second': 1.78, 'eval_steps_per_second': 0.925, 'epoch': 3.0}

ðŸ”Ž Running autoregressive validation CER (generation)...
ðŸ”š Autoregressive validation CER: 0.8482 (84.82%)

ðŸ“Š Epoch 3 - Generation-based Validation CER: 0.8482 (84.82%)
   Best CER so far: 0.8336

{'loss': 1.4674, 'grad_norm': 0.555713415145874, 'learning_rate': 0.000196, 'epoch': 3.34}
{'loss': 1.4635, 'grad_norm': 0.28251850605010986, 'learning_rate': 0.00018971428571428573, 'epoch': 4.0}
{'eval_cer_token_level': 0.0, 'eval_loss': 1.4762585163116455, 'eval_runtime': 14.3749, 'eval_samples_per_second': 1.739, 'eval_steps_per_second': 0.904, 'epoch': 4.0}

ðŸ”Ž Running autoregressive validation CER (generation)...
ðŸ”š Autoregressive validation CER: 0.8505 (85.05%)

ðŸ“Š Epoch 4 - Generation-based Validation CER: 0.8505 (85.05%)
   Best CER so far: 0.8336

{'loss': 1.4579, 'grad_norm': 0.3009777069091797, 'learning_rate': 0.0001782857142857143, 'epoch': 4.69}
{'eval_cer_token_level': 0.0, 'eval_loss': 1.4719394445419312, 'eval_runtime': 14.3975, 'eval_samples_per_second': 1.736, 'eval_steps_per_second': 0.903, 'epoch': 5.0}

ðŸ”Ž Running autoregressive validation CER (generation)...
ðŸ”š Autoregressive validation CER: 0.8710 (87.10%)

ðŸ“Š Epoch 5 - Generation-based Validation CER: 0.8710 (87.10%)
   Best CER so far: 0.8336

{'loss': 1.4545, 'grad_norm': 0.26175692677497864, 'learning_rate': 0.00016685714285714285, 'epoch': 5.34}
{'loss': 1.4528, 'grad_norm': 0.2650730013847351, 'learning_rate': 0.00015542857142857144, 'epoch': 6.0}
{'eval_cer_token_level': 0.0, 'eval_loss': 1.4667869806289673, 'eval_runtime': 14.3516, 'eval_samples_per_second': 1.742, 'eval_steps_per_second': 0.906, 'epoch': 6.0}

ðŸ”Ž Running autoregressive validation CER (generation)...
ðŸ”š Autoregressive validation CER: 0.9495 (94.95%)

ðŸ“Š Epoch 6 - Generation-based Validation CER: 0.9495 (94.95%)
   Best CER so far: 0.8336

{'loss': 1.4523, 'grad_norm': 0.5416761636734009, 'learning_rate': 0.000144, 'epoch': 6.69}
{'eval_cer_token_level': 0.0, 'eval_loss': 1.464504361152649, 'eval_runtime': 14.2699, 'eval_samples_per_second': 1.752, 'eval_steps_per_second': 0.911, 'epoch': 7.0}

ðŸ”Ž Running autoregressive validation CER (generation)...
ðŸ”š Autoregressive validation CER: 1.0295 (102.95%)

ðŸ“Š Epoch 7 - Generation-based Validation CER: 1.0295 (102.95%)
   Best CER so far: 0.8336

{'loss': 1.45, 'grad_norm': 0.10906639695167542, 'learning_rate': 0.00013257142857142856, 'epoch': 7.34}
{'loss': 1.4485, 'grad_norm': 0.229323148727417, 'learning_rate': 0.00012114285714285715, 'epoch': 8.0}
{'eval_cer_token_level': 0.0, 'eval_loss': 1.4602303504943848, 'eval_runtime': 14.5528, 'eval_samples_per_second': 1.718, 'eval_steps_per_second': 0.893, 'epoch': 8.0}

ðŸ”Ž Running autoregressive validation CER (generation)...
ðŸ”š Autoregressive validation CER: 0.9774 (97.74%)

ðŸ“Š Epoch 8 - Generation-based Validation CER: 0.9774 (97.74%)
   Best CER so far: 0.8336

{'loss': 1.4476, 'grad_norm': 0.2968558073043823, 'learning_rate': 0.00010971428571428573, 'epoch': 8.69}
{'eval_cer_token_level': 0.0, 'eval_loss': 1.4579417705535889, 'eval_runtime': 14.6894, 'eval_samples_per_second': 1.702, 'eval_steps_per_second': 0.885, 'epoch': 9.0}

ðŸ”Ž Running autoregressive validation CER (generation)...
ðŸ”š Autoregressive validation CER: 1.0257 (102.57%)

ðŸ“Š Epoch 9 - Generation-based Validation CER: 1.0257 (102.57%)
   Best CER so far: 0.8336

{'loss': 1.4467, 'grad_norm': 0.06343033164739609, 'learning_rate': 9.828571428571429e-05, 'epoch': 9.34}
{'loss': 1.446, 'grad_norm': 0.39126864075660706, 'learning_rate': 8.685714285714286e-05, 'epoch': 10.0}
{'eval_cer_token_level': 0.0, 'eval_loss': 1.4604504108428955, 'eval_runtime': 14.3203, 'eval_samples_per_second': 1.746, 'eval_steps_per_second': 0.908, 'epoch': 10.0}

ðŸ”Ž Running autoregressive validation CER (generation)...
ðŸ”š Autoregressive validation CER: 0.9952 (99.52%)

ðŸ“Š Epoch 10 - Generation-based Validation CER: 0.9952 (99.52%)
   Best CER so far: 0.8336

{'loss': 1.4459, 'grad_norm': 0.37033212184906006, 'learning_rate': 7.542857142857144e-05, 'epoch': 10.69}
{'eval_cer_token_level': 0.0, 'eval_loss': 1.4576311111450195, 'eval_runtime': 14.3071, 'eval_samples_per_second': 1.747, 'eval_steps_per_second': 0.909, 'epoch': 11.0}

ðŸ”Ž Running autoregressive validation CER (generation)...
ðŸ”š Autoregressive validation CER: 1.0094 (100.94%)

ðŸ“Š Epoch 11 - Generation-based Validation CER: 1.0094 (100.94%)
   Best CER so far: 0.8336

{'loss': 1.4449, 'grad_norm': 0.16681736707687378, 'learning_rate': 6.400000000000001e-05, 'epoch': 11.34}
{'loss': 1.4446, 'grad_norm': 0.20534174144268036, 'learning_rate': 5.257142857142857e-05, 'epoch': 12.0}
{'eval_cer_token_level': 0.0, 'eval_loss': 1.4590219259262085, 'eval_runtime': 14.4249, 'eval_samples_per_second': 1.733, 'eval_steps_per_second': 0.901, 'epoch': 12.0}

ðŸ”Ž Running autoregressive validation CER (generation)...
ðŸ”š Autoregressive validation CER: 1.0222 (102.22%)

ðŸ“Š Epoch 12 - Generation-based Validation CER: 1.0222 (102.22%)
   Best CER so far: 0.8336

{'loss': 1.4441, 'grad_norm': 0.17366856336593628, 'learning_rate': 4.1142857142857146e-05, 'epoch': 12.69}
{'eval_cer_token_level': 0.0, 'eval_loss': 1.4578202962875366, 'eval_runtime': 14.49, 'eval_samples_per_second': 1.725, 'eval_steps_per_second': 0.897, 'epoch': 13.0}

ðŸ”Ž Running autoregressive validation CER (generation)...
ðŸ”š Autoregressive validation CER: 0.9834 (98.34%)

ðŸ“Š Epoch 13 - Generation-based Validation CER: 0.9834 (98.34%)
   Best CER so far: 0.8336

{'loss': 1.4438, 'grad_norm': 0.06312667578458786, 'learning_rate': 2.9714285714285717e-05, 'epoch': 13.34}
{'loss': 1.4436, 'grad_norm': 0.09629907459020615, 'learning_rate': 1.8285714285714288e-05, 'epoch': 14.0}
{'eval_cer_token_level': 0.0, 'eval_loss': 1.45947265625, 'eval_runtime': 15.0707, 'eval_samples_per_second': 1.659, 'eval_steps_per_second': 0.863, 'epoch': 14.0}

ðŸ”Ž Running autoregressive validation CER (generation)...
ðŸ”š Autoregressive validation CER: 0.9973 (99.73%)

ðŸ“Š Epoch 14 - Generation-based Validation CER: 0.9973 (99.73%)
   Best CER so far: 0.8336

{'loss': 1.4438, 'grad_norm': 0.09065062552690506, 'learning_rate': 6.857142857142858e-06, 'epoch': 14.69}
{'eval_cer_token_level': 0.0, 'eval_loss': 1.4574406147003174, 'eval_runtime': 14.5341, 'eval_samples_per_second': 1.72, 'eval_steps_per_second': 0.894, 'epoch': 15.0}

ðŸ”Ž Running autoregressive validation CER (generation)...
ðŸ”š Autoregressive validation CER: 1.0081 (100.81%)

ðŸ“Š Epoch 15 - Generation-based Validation CER: 1.0081 (100.81%)
   Best CER so far: 0.8336

{'train_runtime': 18285.7144, 'train_samples_per_second': 0.094, 'train_steps_per_second': 0.012, 'train_loss': 1.4559267086452907, 'epoch': 15.0}

âœ… Training completed!
Best generation-based validation CER: 0.8336
Best model: /home/vault/iwi5/iwi5298h/models_image_text/florence2/multi/stair/lora_multistage_run_20251129_132140/best_model
Making predictions on 24 test images...
[1/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (83).jpg
  âœ… CER: 1.4545
[2/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (45).jpg
  âœ… CER: 1.3538
[3/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (27).jpg
  âœ… CER: 0.8994
[4/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (130).jpg
  âœ… CER: 0.9147
[5/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (129).jpg
  âœ… CER: 0.9239
[6/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (88).jpg
  âœ… CER: 0.8990
[7/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (102).jpg
  âœ… CER: 1.5283
[8/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (103).jpg
  âœ… CER: 1.5046
[9/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (165).jpg
  âœ… CER: 1.5753
[10/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (43).jpg
  âœ… CER: 0.9211
[11/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (11).jpg
  âœ… CER: 1.1233
[12/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (36).jpg
  âœ… CER: 0.9154
[13/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (87).jpg
  âœ… CER: 1.0243
[14/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (94).jpg
  âœ… CER: 0.9345
[15/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (58).jpg
  âœ… CER: 1.1549
[16/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (111).jpg
  âœ… CER: 0.9243
[17/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (99).jpg
  âœ… CER: 1.5904
[18/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (116).jpg
  âœ… CER: 1.4325
[19/24] FMIS_FormblaÌˆtterMielke_Vorlage3.jpg
  âœ… CER: 0.9554
[20/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (132).jpg
  âœ… CER: 0.9341
[21/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (139).jpg
  âœ… CER: 0.9121
[22/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (66).jpg
  âœ… CER: 0.9331
[23/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (105).jpg
  âœ… CER: 0.9013
[24/24] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (13).jpg
  âœ… CER: 0.9620

============================================================
TEST RESULTS (Staircase)
============================================================
Average CER: 1.1113 (111.13%)
Perfect matches: 0/24
JSON success rate: 0.0%
============================================================

LoRA multistage finetuning pipeline completed successfully!
Results saved in: /home/vault/iwi5/iwi5298h/models_image_text/florence2/multi/stair/lora_multistage_run_20251129_132140
========================================
Job completed at: Sat Nov 29 06:52:45 PM CET 2025
========================================
=== JOB_STATISTICS ===
=== current date     : Sat Nov 29 06:52:45 PM CET 2025
= Job-ID             : 1451780 on tinygpu
= Job-Name           : stair_ms
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_florence.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : v100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 05:31:40
= Total RAM usage    : 6.8 GiB of requested  GiB (%)   
= Node list          : tg072
= Subm/Elig/Start/End: 2025-11-29T12:44:01 / 2025-11-29T12:44:01 / 2025-11-29T13:21:05 / 2025-11-29T18:52:45
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody           197.4G  1000.0G  1500.0G        N/A     876K   5,000K   7,500K        N/A    
    /home/hpc              87.7G   104.9G   209.7G        N/A  27,843      500K   1,000K        N/A    
    /home/vault           886.7G  1048.6G  2097.2G        N/A   6,519      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:18:00.0, 2862400, 61 %, 19 %, 32012 MiB, 19869809 ms
