### Starting TaskPrologue of job 1524523 on tg091 at Fri Feb  6 08:07:00 AM CET 2026
Running on cores 0-31 with governor ondemand
Fri Feb  6 08:07:00 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.126.09             Driver Version: 580.126.09     CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:01:00.0 Off |                    0 |
| N/A   41C    P0             55W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Created run directory: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260206_080734

============================================================
GEMMA-3 INVENTORY - A100 OPTIMIZED + AUTOREGRESSIVE GEN-CER
============================================================
Loading Gemma-3 vision model with Unsloth for INVENTORY...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.7.3: Fast Gemma3 patching. Transformers: 4.51.3.
   \\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.493 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.1+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.1
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Gemma3 does not support SDPA - switching to eager!
Model loaded - Unsloth auto-configured dtype and attention
Unsloth: Making `base_model.model.vision_tower.vision_model` require gradients
Gemma-3 vision model loaded with A100-optimized LoRA config

============================================================
STARTING TRAINING (BEST MODEL BY AUTOREGRESSIVE GEN-CER)
============================================================
Preparing training and validation datasets...
Training: 215 samples, Validation: 46 samples
[GenCER Callback] Fixed val subset size = 46
GPU = NVIDIA A100-SXM4-40GB. Max memory = 39.493 GB.
4.809 GB of memory reserved.
Starting training with AUTOREGRESSIVE CER-based evaluation (A100-optimized)...
{'loss': 33.349, 'grad_norm': 271.4139099121094, 'learning_rate': 0.0, 'epoch': 0.07}
{'loss': 33.446, 'grad_norm': 237.66586303710938, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.37}
{'loss': 32.9911, 'grad_norm': 260.0005187988281, 'learning_rate': 2.7e-06, 'epoch': 0.74}
{'eval_loss': 3.465712070465088, 'eval_runtime': 21.8685, 'eval_samples_per_second': 2.103, 'eval_steps_per_second': 2.103, 'epoch': 1.0}

[GenCER Callback] Epoch 1.00 gen_cer = 0.3100 (31.00%)
{'loss': 26.5999, 'grad_norm': 146.64242553710938, 'learning_rate': 4.2000000000000004e-06, 'epoch': 1.07}
{'loss': 24.7817, 'grad_norm': 122.53472900390625, 'learning_rate': 5.7000000000000005e-06, 'epoch': 1.44}
{'loss': 21.0337, 'grad_norm': 54.09838104248047, 'learning_rate': 7.2e-06, 'epoch': 1.81}
{'eval_loss': 2.272400140762329, 'eval_runtime': 21.6806, 'eval_samples_per_second': 2.122, 'eval_steps_per_second': 2.122, 'epoch': 2.0}

[GenCER Callback] Epoch 2.00 gen_cer = 0.5303 (53.03%)
{'loss': 16.4486, 'grad_norm': 41.653987884521484, 'learning_rate': 8.7e-06, 'epoch': 2.15}
{'loss': 16.1909, 'grad_norm': 48.1409797668457, 'learning_rate': 1.02e-05, 'epoch': 2.52}
{'loss': 13.8912, 'grad_norm': 31.90079689025879, 'learning_rate': 1.1700000000000001e-05, 'epoch': 2.89}
{'eval_loss': 1.5189167261123657, 'eval_runtime': 21.7254, 'eval_samples_per_second': 2.117, 'eval_steps_per_second': 2.117, 'epoch': 3.0}

[GenCER Callback] Epoch 3.00 gen_cer = 0.3383 (33.83%)
{'loss': 10.7636, 'grad_norm': 36.38458251953125, 'learning_rate': 1.32e-05, 'epoch': 3.22}
{'loss': 10.8641, 'grad_norm': 30.036996841430664, 'learning_rate': 1.47e-05, 'epoch': 3.59}
{'loss': 10.2166, 'grad_norm': 30.817230224609375, 'learning_rate': 1.62e-05, 'epoch': 3.96}
{'eval_loss': 1.2499747276306152, 'eval_runtime': 21.7013, 'eval_samples_per_second': 2.12, 'eval_steps_per_second': 2.12, 'epoch': 4.0}

[GenCER Callback] Epoch 4.00 gen_cer = 0.1991 (19.91%)
{'loss': 8.8057, 'grad_norm': 31.176313400268555, 'learning_rate': 1.77e-05, 'epoch': 4.3}
{'loss': 9.3144, 'grad_norm': 58.35807418823242, 'learning_rate': 1.9200000000000003e-05, 'epoch': 4.67}
{'loss': 8.2184, 'grad_norm': 8.939373970031738, 'learning_rate': 2.07e-05, 'epoch': 5.0}
{'eval_loss': 1.145941972732544, 'eval_runtime': 21.724, 'eval_samples_per_second': 2.117, 'eval_steps_per_second': 2.117, 'epoch': 5.0}

[GenCER Callback] Epoch 5.00 gen_cer = 0.1809 (18.09%)
{'loss': 8.7793, 'grad_norm': 12.170119285583496, 'learning_rate': 2.22e-05, 'epoch': 5.37}
{'loss': 8.5499, 'grad_norm': 39.56028366088867, 'learning_rate': 2.37e-05, 'epoch': 5.74}
{'eval_loss': 1.071826696395874, 'eval_runtime': 21.7451, 'eval_samples_per_second': 2.115, 'eval_steps_per_second': 2.115, 'epoch': 6.0}

[GenCER Callback] Epoch 6.00 gen_cer = 0.1444 (14.44%)
{'loss': 7.5547, 'grad_norm': 8.44761848449707, 'learning_rate': 2.52e-05, 'epoch': 6.07}
{'loss': 8.1295, 'grad_norm': 13.822726249694824, 'learning_rate': 2.6700000000000002e-05, 'epoch': 6.44}
{'loss': 8.0352, 'grad_norm': 8.839760780334473, 'learning_rate': 2.8199999999999998e-05, 'epoch': 6.81}
{'eval_loss': 1.0505214929580688, 'eval_runtime': 21.7664, 'eval_samples_per_second': 2.113, 'eval_steps_per_second': 2.113, 'epoch': 7.0}

[GenCER Callback] Epoch 7.00 gen_cer = 0.1097 (10.97%)
{'loss': 7.1285, 'grad_norm': 9.092530250549316, 'learning_rate': 2.97e-05, 'epoch': 7.15}
{'loss': 7.7868, 'grad_norm': 13.848001480102539, 'learning_rate': 2.9623918682727355e-05, 'epoch': 7.52}
{'loss': 7.7431, 'grad_norm': 14.382941246032715, 'learning_rate': 2.8128351328631307e-05, 'epoch': 7.89}
{'eval_loss': 1.0289850234985352, 'eval_runtime': 21.7276, 'eval_samples_per_second': 2.117, 'eval_steps_per_second': 2.117, 'epoch': 8.0}

[GenCER Callback] Epoch 8.00 gen_cer = 0.1320 (13.20%)
{'loss': 6.7898, 'grad_norm': 9.273523330688477, 'learning_rate': 2.5606601717798212e-05, 'epoch': 8.22}
{'loss': 7.5495, 'grad_norm': 8.170584678649902, 'learning_rate': 2.2255783306578596e-05, 'epoch': 8.59}
{'loss': 7.4864, 'grad_norm': 6.528987884521484, 'learning_rate': 1.8337814009344716e-05, 'epoch': 8.96}
{'eval_loss': 1.017998218536377, 'eval_runtime': 21.7797, 'eval_samples_per_second': 2.112, 'eval_steps_per_second': 2.112, 'epoch': 9.0}

[GenCER Callback] Epoch 9.00 gen_cer = 0.0969 (9.69%)
{'loss': 6.61, 'grad_norm': 5.702898979187012, 'learning_rate': 1.4158943291442121e-05, 'epoch': 9.3}
{'loss': 7.3649, 'grad_norm': 8.335440635681152, 'learning_rate': 1.0045814070672498e-05, 'epoch': 9.67}
{'loss': 6.5888, 'grad_norm': 4.31721305847168, 'learning_rate': 6.319930557302914e-06, 'epoch': 10.0}
{'eval_loss': 1.0176469087600708, 'eval_runtime': 21.6861, 'eval_samples_per_second': 2.121, 'eval_steps_per_second': 2.121, 'epoch': 10.0}

[GenCER Callback] Epoch 10.00 gen_cer = 0.1046 (10.46%)
{'loss': 7.2531, 'grad_norm': 9.908517837524414, 'learning_rate': 3.272527762979553e-06, 'epoch': 10.37}
{'loss': 7.2679, 'grad_norm': 11.180267333984375, 'learning_rate': 1.1418070123306989e-06, 'epoch': 10.74}
{'eval_loss': 1.0192584991455078, 'eval_runtime': 21.8271, 'eval_samples_per_second': 2.107, 'eval_steps_per_second': 2.107, 'epoch': 11.0}

[GenCER Callback] Epoch 11.00 gen_cer = 0.1062 (10.62%)
{'loss': 6.5058, 'grad_norm': 5.0840888023376465, 'learning_rate': 9.431685160136094e-08, 'epoch': 11.07}
{'eval_loss': 1.0186691284179688, 'eval_runtime': 21.7658, 'eval_samples_per_second': 2.113, 'eval_steps_per_second': 2.113, 'epoch': 11.15}

[GenCER Callback] Epoch 11.15 gen_cer = 0.1039 (10.39%)
{'train_runtime': 28988.8721, 'train_samples_per_second': 0.089, 'train_steps_per_second': 0.005, 'train_loss': 11.927047796738453, 'epoch': 11.15}
28988.8721 seconds used for training.
483.15 minutes used for training.
Peak reserved memory = 15.203 GB.
Peak reserved memory for training = 10.394 GB.
Peak reserved memory % of max memory = 38.495 %.
Peak reserved memory for training % of max memory = 26.319 %.

Saving model to /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260206_080734...
Model (LoRA adapters) saved successfully!

============================================================
STARTING EVALUATION ON TEST.JSONL (USING BEST MODEL)
============================================================
Starting evaluation on test.jsonl with aggressive chunking...
Loaded 47 test samples

============================================================
Chunk 1/10 (5 images)
============================================================

[1/47] Processing: inventarbuch-036.jpg
  âœ… CER: 0.1393 (13.93%)

[2/47] Processing: inventarbuch-100.jpg
  âœ… CER: 0.0737 (7.37%)

[3/47] Processing: inventarbuch-190.jpg
  âœ… CER: 0.0681 (6.81%)

[4/47] Processing: inventarbuch-153.jpg
  âœ… CER: 0.0000 (0.00%)

[5/47] Processing: inventarbuch-041.jpg
  âœ… CER: 0.0635 (6.35%)

Chunk 1 completed. Cleaning memory...

============================================================
Chunk 2/10 (5 images)
============================================================

[6/47] Processing: inventarbuch-198.jpg
  âœ… CER: 0.0618 (6.18%)

[7/47] Processing: inventarbuch-065.jpg
  âœ… CER: 0.1483 (14.83%)

[8/47] Processing: inventarbuch-242.jpg
  âœ… CER: 0.1046 (10.46%)

[9/47] Processing: inventarbuch-023.jpg
  âœ… CER: 0.1895 (18.95%)

[10/47] Processing: inventarbuch-137.jpg
  âœ… CER: 0.0853 (8.53%)

Chunk 2 completed. Cleaning memory...

============================================================
Chunk 3/10 (5 images)
============================================================

[11/47] Processing: inventarbuch-180.jpg
  âœ… CER: 0.1147 (11.47%)

[12/47] Processing: inventarbuch-188.jpg
  âœ… CER: 0.0422 (4.22%)

[13/47] Processing: inventarbuch-051.jpg
  âœ… CER: 0.0296 (2.96%)

[14/47] Processing: inventarbuch-199.jpg
  âœ… CER: 0.0000 (0.00%)

[15/47] Processing: inventarbuch-296.jpg
  âœ… CER: 0.1715 (17.15%)

Chunk 3 completed. Cleaning memory...
Saved intermediate results to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260206_080734/test_predictions_chunk_3.jsonl

============================================================
Chunk 4/10 (5 images)
============================================================

[16/47] Processing: inventarbuch-302.jpg
  âœ… CER: 0.0068 (0.68%)

[17/47] Processing: inventarbuch-176.jpg
  âœ… CER: 0.0324 (3.24%)

[18/47] Processing: inventarbuch-112.jpg
  âœ… CER: 0.0164 (1.64%)

[19/47] Processing: inventarbuch-081.jpg
  âœ… CER: 0.0852 (8.52%)

[20/47] Processing: inventarbuch-290.jpg
  âœ… CER: 0.0985 (9.85%)

Chunk 4 completed. Cleaning memory...

============================================================
Chunk 5/10 (5 images)
============================================================

[21/47] Processing: inventarbuch-178.jpg
  âœ… CER: 0.0996 (9.96%)

[22/47] Processing: inventarbuch-299.jpg
  âœ… CER: 0.1072 (10.72%)

[23/47] Processing: inventarbuch-083.jpg
  âœ… CER: 0.1653 (16.53%)

[24/47] Processing: inventarbuch-004.jpg
  âœ… CER: 0.0826 (8.26%)

[25/47] Processing: inventarbuch-145.jpg
  âœ… CER: 0.1212 (12.12%)

Chunk 5 completed. Cleaning memory...

============================================================
Chunk 6/10 (5 images)
============================================================

[26/47] Processing: inventarbuch-236.jpg
  âœ… CER: 0.0764 (7.64%)

[27/47] Processing: inventarbuch-114.jpg
  âœ… CER: 0.0994 (9.94%)

[28/47] Processing: inventarbuch-220.jpg
  âœ… CER: 0.0881 (8.81%)

[29/47] Processing: inventarbuch-301.jpg
  âœ… CER: 0.0209 (2.09%)

[30/47] Processing: inventarbuch-103.jpg
  âœ… CER: 0.0850 (8.50%)

Chunk 6 completed. Cleaning memory...
Saved intermediate results to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260206_080734/test_predictions_chunk_6.jsonl

============================================================
Chunk 7/10 (5 images)
============================================================

[31/47] Processing: inventarbuch-014.jpg
  âœ… CER: 0.1912 (19.12%)

[32/47] Processing: inventarbuch-265.jpg
  âœ… CER: 0.0462 (4.62%)

[33/47] Processing: inventarbuch-121.jpg
  âœ… CER: 0.0582 (5.82%)

[34/47] Processing: inventarbuch-113.jpg
  âœ… CER: 0.0524 (5.24%)

[35/47] Processing: inventarbuch-049.jpg
  âœ… CER: 0.0000 (0.00%)

Chunk 7 completed. Cleaning memory...

============================================================
Chunk 8/10 (5 images)
============================================================

[36/47] Processing: inventarbuch-016.jpg
  âœ… CER: 0.0961 (9.61%)

[37/47] Processing: inventarbuch-017.jpg
  âœ… CER: 0.0307 (3.07%)

[38/47] Processing: inventarbuch-223.jpg
  âœ… CER: 0.0398 (3.98%)

[39/47] Processing: inventarbuch-046.jpg
  âœ… CER: 1.0000 (100.00%)

[40/47] Processing: inventarbuch-286.jpg
  âœ… CER: 0.0973 (9.73%)

Chunk 8 completed. Cleaning memory...

============================================================
Chunk 9/10 (5 images)
============================================================

[41/47] Processing: inventarbuch-054.jpg
  âœ… CER: 0.1901 (19.01%)

[42/47] Processing: inventarbuch-073.jpg
  âœ… CER: 0.2304 (23.04%)

[43/47] Processing: inventarbuch-116.jpg
  âœ… CER: 0.0274 (2.74%)

[44/47] Processing: inventarbuch-127.jpg
  âœ… CER: 0.0712 (7.12%)

[45/47] Processing: inventarbuch-143.jpg
  âœ… CER: 0.0286 (2.86%)

Chunk 9 completed. Cleaning memory...
Saved intermediate results to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260206_080734/test_predictions_chunk_9.jsonl

============================================================
Chunk 10/10 (2 images)
============================================================

[46/47] Processing: inventarbuch-013.jpg
  âœ… CER: 0.1304 (13.04%)

[47/47] Processing: inventarbuch-059.jpg
  âœ… CER: 0.1125 (11.25%)

Chunk 10 completed. Cleaning memory...
Saved intermediate results to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260206_080734/test_predictions_chunk_10.jsonl

CER evaluation results saved to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260206_080734/cer_evaluation_results.txt

ðŸŽ‰ Gemma-3 Inventory training completed!
All outputs saved to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260206_080734

Final TEST CER: 0.1038 (10.38%)
Gemma-3 training completed at: Fri Feb  6 04:44:37 PM CET 2026
=== JOB_STATISTICS ===
=== current date     : Fri Feb  6 04:44:37 PM CET 2026
= Job-ID             : 1524523 on tinygpu
= Job-Name           : inventory_updated
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_gemma.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : a100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 08:37:42
= Total RAM usage    : 12.4 GiB of requested  GiB (%)   
= Node list          : tg091
= Subm/Elig/Start/End: 2026-02-04T15:58:01 / 2026-02-04T15:58:01 / 2026-02-06T08:06:55 / 2026-02-06T16:44:37
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc              91.4G   104.9G   209.7G        N/A  29,905      500K   1,000K        N/A    
    /home/woody           408.1G  1000.0G  1500.0G        N/A   1,018K   5,000K   7,500K        N/A    
    /home/vault           870.6G  1048.6G  2097.2G        N/A   9,121      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:01:00.0, 3948148, 23 %, 3 %, 16110 MiB, 31047516 ms
