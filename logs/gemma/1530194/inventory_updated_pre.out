### Starting TaskPrologue of job 1530194 on tg097 at Sun Feb 15 09:57:31 AM CET 2026
Running on cores 96-127 with governor ondemand
Sun Feb 15 09:57:31 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.126.16             Driver Version: 580.126.16     CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:C1:00.0 Off |                    0 |
| N/A   38C    P0             56W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Created run directory: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260215_095759

============================================================
GEMMA-3 INVENTORY - A100 OPTIMIZED + AUTOREGRESSIVE GEN-CER
============================================================
Loading Gemma-3 vision model with Unsloth for INVENTORY...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.7.3: Fast Gemma3 patching. Transformers: 4.51.3.
   \\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.493 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.1+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.1
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Gemma3 does not support SDPA - switching to eager!
Model loaded - Unsloth auto-configured dtype and attention
Unsloth: Making `base_model.model.vision_tower.vision_model` require gradients
Gemma-3 vision model loaded with A100-optimized LoRA config

============================================================
STARTING TRAINING (BEST MODEL BY AUTOREGRESSIVE GEN-CER)
============================================================
Preparing training and validation datasets...
   ðŸ“Š Loaded 215 valid samples (out of 215 total)
   ðŸ“Š Loaded 46 valid samples (out of 46 total)
Training: 215 samples, Validation: 46 samples
[GenCER Callback] Fixed val subset size = 46
GPU = NVIDIA A100-SXM4-40GB. Max memory = 39.493 GB.
4.809 GB of memory reserved.
Starting training with AUTOREGRESSIVE CER-based evaluation (A100-optimized)...
{'loss': 33.0707, 'grad_norm': 5686.916015625, 'learning_rate': 0.0, 'epoch': 0.07}
{'loss': 33.1052, 'grad_norm': 498.6178283691406, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.37}
{'loss': 32.7614, 'grad_norm': 599.755126953125, 'learning_rate': 2.7e-06, 'epoch': 0.74}
{'eval_loss': 3.5255331993103027, 'eval_runtime': 23.5084, 'eval_samples_per_second': 1.957, 'eval_steps_per_second': 1.957, 'epoch': 1.0}

[GenCER Callback] Epoch 1.00 gen_cer = 0.4285 (42.85%)
{'loss': 26.8456, 'grad_norm': 872.4655151367188, 'learning_rate': 4.2000000000000004e-06, 'epoch': 1.07}
{'loss': 25.5341, 'grad_norm': 163.24497985839844, 'learning_rate': 5.7000000000000005e-06, 'epoch': 1.44}
{'loss': 21.7748, 'grad_norm': 120.62965393066406, 'learning_rate': 7.2e-06, 'epoch': 1.81}
{'eval_loss': 2.342625379562378, 'eval_runtime': 23.4975, 'eval_samples_per_second': 1.958, 'eval_steps_per_second': 1.958, 'epoch': 2.0}

[GenCER Callback] Epoch 2.00 gen_cer = 0.5806 (58.06%)
{'loss': 16.9002, 'grad_norm': 123.50395202636719, 'learning_rate': 8.7e-06, 'epoch': 2.15}
{'loss': 16.6483, 'grad_norm': 62.81694412231445, 'learning_rate': 1.02e-05, 'epoch': 2.52}
{'loss': 14.2493, 'grad_norm': 101.64537811279297, 'learning_rate': 1.1700000000000001e-05, 'epoch': 2.89}
{'eval_loss': 1.5649689435958862, 'eval_runtime': 23.5523, 'eval_samples_per_second': 1.953, 'eval_steps_per_second': 1.953, 'epoch': 3.0}

[GenCER Callback] Epoch 3.00 gen_cer = 0.3225 (32.25%)
{'loss': 11.0664, 'grad_norm': 64.18608856201172, 'learning_rate': 1.32e-05, 'epoch': 3.22}
{'loss': 11.1535, 'grad_norm': 40.531951904296875, 'learning_rate': 1.47e-05, 'epoch': 3.59}
{'loss': 10.4465, 'grad_norm': 24.449960708618164, 'learning_rate': 1.62e-05, 'epoch': 3.96}
{'eval_loss': 1.2724449634552002, 'eval_runtime': 23.5664, 'eval_samples_per_second': 1.952, 'eval_steps_per_second': 1.952, 'epoch': 4.0}

[GenCER Callback] Epoch 4.00 gen_cer = 0.2232 (22.32%)
{'loss': 8.9639, 'grad_norm': 34.55768585205078, 'learning_rate': 1.77e-05, 'epoch': 4.3}
{'loss': 9.4411, 'grad_norm': 54.798057556152344, 'learning_rate': 1.9200000000000003e-05, 'epoch': 4.67}
{'loss': 8.3419, 'grad_norm': 13.191271781921387, 'learning_rate': 2.07e-05, 'epoch': 5.0}
{'eval_loss': 1.165592074394226, 'eval_runtime': 23.4841, 'eval_samples_per_second': 1.959, 'eval_steps_per_second': 1.959, 'epoch': 5.0}

[GenCER Callback] Epoch 5.00 gen_cer = 0.2080 (20.80%)
{'loss': 8.8783, 'grad_norm': 12.98205280303955, 'learning_rate': 2.22e-05, 'epoch': 5.37}
{'loss': 8.6386, 'grad_norm': 48.722537994384766, 'learning_rate': 2.37e-05, 'epoch': 5.74}
{'eval_loss': 1.0882270336151123, 'eval_runtime': 23.5223, 'eval_samples_per_second': 1.956, 'eval_steps_per_second': 1.956, 'epoch': 6.0}

[GenCER Callback] Epoch 6.00 gen_cer = 0.1375 (13.75%)
{'loss': 7.6193, 'grad_norm': 13.36963939666748, 'learning_rate': 2.52e-05, 'epoch': 6.07}
{'loss': 8.1966, 'grad_norm': 16.487361907958984, 'learning_rate': 2.6700000000000002e-05, 'epoch': 6.44}
{'loss': 8.1166, 'grad_norm': 13.344491004943848, 'learning_rate': 2.8199999999999998e-05, 'epoch': 6.81}
{'eval_loss': 1.056744933128357, 'eval_runtime': 23.3598, 'eval_samples_per_second': 1.969, 'eval_steps_per_second': 1.969, 'epoch': 7.0}

[GenCER Callback] Epoch 7.00 gen_cer = 0.1415 (14.15%)
{'loss': 7.1257, 'grad_norm': 12.746277809143066, 'learning_rate': 2.97e-05, 'epoch': 7.15}
{'loss': 7.759, 'grad_norm': 16.077192306518555, 'learning_rate': 2.9623918682727355e-05, 'epoch': 7.52}
{'loss': 7.7227, 'grad_norm': 13.83922004699707, 'learning_rate': 2.8128351328631307e-05, 'epoch': 7.89}
{'eval_loss': 1.0431112051010132, 'eval_runtime': 23.4655, 'eval_samples_per_second': 1.96, 'eval_steps_per_second': 1.96, 'epoch': 8.0}

[GenCER Callback] Epoch 8.00 gen_cer = 0.1131 (11.31%)
{'loss': 6.7835, 'grad_norm': 10.652507781982422, 'learning_rate': 2.5606601717798212e-05, 'epoch': 8.22}
{'loss': 7.502, 'grad_norm': 10.51636791229248, 'learning_rate': 2.2255783306578596e-05, 'epoch': 8.59}
{'loss': 7.4619, 'grad_norm': 20.471158981323242, 'learning_rate': 1.8337814009344716e-05, 'epoch': 8.96}
{'eval_loss': 1.034040093421936, 'eval_runtime': 23.3437, 'eval_samples_per_second': 1.971, 'eval_steps_per_second': 1.971, 'epoch': 9.0}

[GenCER Callback] Epoch 9.00 gen_cer = 0.1098 (10.98%)
{'loss': 6.5975, 'grad_norm': 9.818008422851562, 'learning_rate': 1.4158943291442121e-05, 'epoch': 9.3}
{'loss': 7.3281, 'grad_norm': 12.034441947937012, 'learning_rate': 1.0045814070672498e-05, 'epoch': 9.67}
{'loss': 6.5787, 'grad_norm': 3.2629289627075195, 'learning_rate': 6.319930557302914e-06, 'epoch': 10.0}
{'eval_loss': 1.0360002517700195, 'eval_runtime': 23.434, 'eval_samples_per_second': 1.963, 'eval_steps_per_second': 1.963, 'epoch': 10.0}

[GenCER Callback] Epoch 10.00 gen_cer = 0.1096 (10.96%)
{'loss': 7.2247, 'grad_norm': 11.363831520080566, 'learning_rate': 3.272527762979553e-06, 'epoch': 10.37}
{'loss': 7.2509, 'grad_norm': 5.254037380218506, 'learning_rate': 1.1418070123306989e-06, 'epoch': 10.74}
{'eval_loss': 1.0367506742477417, 'eval_runtime': 23.4323, 'eval_samples_per_second': 1.963, 'eval_steps_per_second': 1.963, 'epoch': 11.0}

[GenCER Callback] Epoch 11.00 gen_cer = 0.1170 (11.70%)
{'train_runtime': 27446.3883, 'train_samples_per_second': 0.094, 'train_steps_per_second': 0.006, 'train_loss': 12.112274467171012, 'epoch': 11.0}
27446.3883 seconds used for training.
457.44 minutes used for training.
Peak reserved memory = 15.203 GB.
Peak reserved memory for training = 10.394 GB.
Peak reserved memory % of max memory = 38.495 %.
Peak reserved memory for training % of max memory = 26.319 %.

Saving model to /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260215_095759...
Model (LoRA adapters) saved successfully!

============================================================
STARTING EVALUATION ON TEST.JSONL (USING BEST MODEL)
============================================================
Starting evaluation on test.jsonl with aggressive chunking...
Loaded 47 test samples

============================================================
Chunk 1/10 (5 images)
============================================================

[1/47] Processing: inventarbuch-036.jpg
  âœ… CER: 0.1458 (14.58%)

[2/47] Processing: inventarbuch-100.jpg
  âœ… CER: 0.0576 (5.76%)

[3/47] Processing: inventarbuch-190.jpg
  âœ… CER: 0.0720 (7.20%)

[4/47] Processing: inventarbuch-153.jpg
  âœ… CER: 0.0046 (0.46%)

[5/47] Processing: inventarbuch-041.jpg
  âœ… CER: 0.0470 (4.70%)

Chunk 1 completed. Cleaning memory...

============================================================
Chunk 2/10 (5 images)
============================================================

[6/47] Processing: inventarbuch-198.jpg
  âœ… CER: 0.1023 (10.23%)

[7/47] Processing: inventarbuch-065.jpg
  âœ… CER: 0.2614 (26.14%)

[8/47] Processing: inventarbuch-242.jpg
  âœ… CER: 0.0935 (9.35%)

[9/47] Processing: inventarbuch-023.jpg
  âœ… CER: 0.1694 (16.94%)

[10/47] Processing: inventarbuch-137.jpg
  âœ… CER: 0.0844 (8.44%)

Chunk 2 completed. Cleaning memory...

============================================================
Chunk 3/10 (5 images)
============================================================

[11/47] Processing: inventarbuch-180.jpg
  âœ… CER: 0.1250 (12.50%)

[12/47] Processing: inventarbuch-188.jpg
  âœ… CER: 0.1280 (12.80%)

[13/47] Processing: inventarbuch-051.jpg
  âœ… CER: 0.0207 (2.07%)

[14/47] Processing: inventarbuch-199.jpg
  âœ… CER: 0.0000 (0.00%)

[15/47] Processing: inventarbuch-296.jpg
  âœ… CER: 0.1725 (17.25%)

Chunk 3 completed. Cleaning memory...
Saved intermediate results to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260215_095759/test_predictions_chunk_3.jsonl

============================================================
Chunk 4/10 (5 images)
============================================================

[16/47] Processing: inventarbuch-302.jpg
  âœ… CER: 0.0240 (2.40%)

[17/47] Processing: inventarbuch-176.jpg
  âœ… CER: 0.0324 (3.24%)

[18/47] Processing: inventarbuch-112.jpg
  âœ… CER: 0.0209 (2.09%)

[19/47] Processing: inventarbuch-081.jpg
  âœ… CER: 0.1522 (15.22%)

[20/47] Processing: inventarbuch-290.jpg
  âœ… CER: 0.0893 (8.93%)

Chunk 4 completed. Cleaning memory...

============================================================
Chunk 5/10 (5 images)
============================================================

[21/47] Processing: inventarbuch-178.jpg
  âœ… CER: 0.0664 (6.64%)

[22/47] Processing: inventarbuch-299.jpg
  âœ… CER: 0.1516 (15.16%)

[23/47] Processing: inventarbuch-083.jpg
  âœ… CER: 0.2526 (25.26%)

[24/47] Processing: inventarbuch-004.jpg
  âœ… CER: 0.1026 (10.26%)

[25/47] Processing: inventarbuch-145.jpg
  âœ… CER: 0.1308 (13.08%)

Chunk 5 completed. Cleaning memory...

============================================================
Chunk 6/10 (5 images)
============================================================

[26/47] Processing: inventarbuch-236.jpg
  âœ… CER: 0.0879 (8.79%)

[27/47] Processing: inventarbuch-114.jpg
  âœ… CER: 0.1242 (12.42%)

[28/47] Processing: inventarbuch-220.jpg
  âœ… CER: 0.1069 (10.69%)

[29/47] Processing: inventarbuch-301.jpg
  âœ… CER: 0.0209 (2.09%)

[30/47] Processing: inventarbuch-103.jpg
  âœ… CER: 0.0928 (9.28%)

Chunk 6 completed. Cleaning memory...
Saved intermediate results to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260215_095759/test_predictions_chunk_6.jsonl

============================================================
Chunk 7/10 (5 images)
============================================================

[31/47] Processing: inventarbuch-014.jpg
  âœ… CER: 0.2521 (25.21%)

[32/47] Processing: inventarbuch-265.jpg
  âœ… CER: 0.0416 (4.16%)

[33/47] Processing: inventarbuch-121.jpg
  âœ… CER: 0.0725 (7.25%)

[34/47] Processing: inventarbuch-113.jpg
  âœ… CER: 0.0550 (5.50%)

[35/47] Processing: inventarbuch-049.jpg
  âœ… CER: 0.0221 (2.21%)

Chunk 7 completed. Cleaning memory...

============================================================
Chunk 8/10 (5 images)
============================================================

[36/47] Processing: inventarbuch-016.jpg
  âœ… CER: 0.1243 (12.43%)

[37/47] Processing: inventarbuch-017.jpg
  âœ… CER: 0.0268 (2.68%)

[38/47] Processing: inventarbuch-223.jpg
  âœ… CER: 0.0427 (4.27%)

[39/47] Processing: inventarbuch-046.jpg
  âœ… CER: 0.1564 (15.64%)

[40/47] Processing: inventarbuch-286.jpg
  âœ… CER: 0.0780 (7.80%)

Chunk 8 completed. Cleaning memory...

============================================================
Chunk 9/10 (5 images)
============================================================

[41/47] Processing: inventarbuch-054.jpg
  âœ… CER: 0.3002 (30.02%)

[42/47] Processing: inventarbuch-073.jpg
  âœ… CER: 0.2614 (26.14%)

[43/47] Processing: inventarbuch-116.jpg
  âœ… CER: 0.0457 (4.57%)

[44/47] Processing: inventarbuch-127.jpg
  âœ… CER: 0.0762 (7.62%)

[45/47] Processing: inventarbuch-143.jpg
  âœ… CER: 0.0422 (4.22%)

Chunk 9 completed. Cleaning memory...
Saved intermediate results to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260215_095759/test_predictions_chunk_9.jsonl

============================================================
Chunk 10/10 (2 images)
============================================================

[46/47] Processing: inventarbuch-013.jpg
  âœ… CER: 0.1750 (17.50%)

[47/47] Processing: inventarbuch-059.jpg
  âœ… CER: 0.1556 (15.56%)

Chunk 10 completed. Cleaning memory...
Saved intermediate results to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260215_095759/test_predictions_chunk_10.jsonl

CER evaluation results saved to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260215_095759/cer_evaluation_results.txt

ðŸŽ‰ Gemma-3 Inventory training completed!
All outputs saved to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260215_095759

Final TEST CER: 0.1036 (10.36%)
Gemma-3 training completed at: Sun Feb 15 06:09:12 PM CET 2026
=== JOB_STATISTICS ===
=== current date     : Sun Feb 15 06:09:12 PM CET 2026
= Job-ID             : 1530194 on tinygpu
= Job-Name           : inventory_updated_pre
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_gemma.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : a100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 08:11:43
= Total RAM usage    : 7.9 GiB of requested  GiB (%)   
= Node list          : tg097
= Subm/Elig/Start/End: 2026-02-13T17:58:51 / 2026-02-13T17:58:51 / 2026-02-15T09:57:29 / 2026-02-15T18:09:12
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody           408.1G  1000.0G  1500.0G        N/A   1,018K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:C1:00.0, 130154, 23 %, 4 %, 16110 MiB, 29493684 ms
