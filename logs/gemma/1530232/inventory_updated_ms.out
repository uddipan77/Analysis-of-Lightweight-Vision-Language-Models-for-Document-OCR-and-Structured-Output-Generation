### Starting TaskPrologue of job 1530232 on tg097 at Sun Feb 15 10:05:10 AM CET 2026
Running on cores 0-31 with governor ondemand
Sun Feb 15 10:05:10 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.126.16             Driver Version: 580.126.16     CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:01:00.0 Off |                    0 |
| N/A   42C    P0             55W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Created run directory: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_multistage_genCER_INV_noSort_20260215_100532

============================================================
GEMMA-3 INVENTORY - MULTI-STAGE + BEST BY AUTOREGRESSIVE GEN-CER (NO SORT, SAVE ONLY ONE)
============================================================
Loading Gemma-3 vision model with Unsloth for INVENTORY...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.7.3: Fast Gemma3 patching. Transformers: 4.51.3.
   \\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.493 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.1+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.1
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Gemma3 does not support SDPA - switching to eager!
Model loaded - Unsloth auto-configured dtype and attention
Unsloth: Making `base_model.model.vision_tower.vision_model` require gradients
Gemma-3 vision model loaded with A100-optimized LoRA config

============================================================
STARTING MULTI-STAGE TRAINING
============================================================
Preparing training and validation datasets for INVENTORY...
Data: 215 valid samples out of 215 total (no augmentation)
Data: 46 valid samples out of 46 total (no augmentation)
Training: 215 samples, Validation: 46 samples

======================================================================
STAGE 1: Warm-up training (no eval, teacher forcing)
======================================================================

{'loss': 33.349, 'grad_norm': 271.66937255859375, 'learning_rate': 0.0, 'epoch': 0.07}
{'loss': 32.9118, 'grad_norm': 447.2009582519531, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.37}
{'loss': 26.02, 'grad_norm': 93.34457397460938, 'learning_rate': 1.62e-05, 'epoch': 0.74}
{'loss': 17.1544, 'grad_norm': 48.1639518737793, 'learning_rate': 2.5200000000000003e-05, 'epoch': 1.07}
{'loss': 14.5424, 'grad_norm': 34.80072784423828, 'learning_rate': 3.4200000000000005e-05, 'epoch': 1.44}
{'loss': 11.4237, 'grad_norm': 24.650606155395508, 'learning_rate': 4.32e-05, 'epoch': 1.81}
{'loss': 8.7903, 'grad_norm': 12.816038131713867, 'learning_rate': 5.22e-05, 'epoch': 2.15}
{'loss': 9.213, 'grad_norm': 10.95083999633789, 'learning_rate': 6.120000000000001e-05, 'epoch': 2.52}
{'loss': 8.7149, 'grad_norm': 19.819656372070312, 'learning_rate': 7.020000000000001e-05, 'epoch': 2.89}
{'loss': 7.3148, 'grad_norm': 11.073100090026855, 'learning_rate': 7.92e-05, 'epoch': 3.22}
{'loss': 8.0088, 'grad_norm': 11.033507347106934, 'learning_rate': 8.82e-05, 'epoch': 3.59}
{'train_runtime': 792.7025, 'train_samples_per_second': 1.085, 'train_steps_per_second': 0.066, 'train_loss': 14.166466639592098, 'epoch': 3.74}

======================================================================
STAGE 2: Main training (eval each epoch, BEST by autoregressive gen-CER)
======================================================================

[GenCER Callback] Fixed val subset size = 46
GPU = NVIDIA A100-SXM4-40GB. Max memory = 39.493 GB.
15.027 GB of memory reserved.
Starting Stage 2 training (Trainer selects BEST by eval_gen_cer)...
{'loss': 7.4891, 'grad_norm': 11.748858451843262, 'learning_rate': 0.0, 'epoch': 0.07}
{'loss': 7.6439, 'grad_norm': 5.449509620666504, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.37}
{'loss': 7.7691, 'grad_norm': 6.289079666137695, 'learning_rate': 5.4e-06, 'epoch': 0.74}
{'eval_loss': 1.0149625539779663, 'eval_runtime': 20.8946, 'eval_samples_per_second': 2.202, 'eval_steps_per_second': 2.202, 'epoch': 1.0}

[GenCER Callback] Epoch 1.00 gen_cer = 0.0960 (9.60%)
{'loss': 6.8946, 'grad_norm': 28.421659469604492, 'learning_rate': 8.400000000000001e-06, 'epoch': 1.07}
{'loss': 7.5999, 'grad_norm': 7.342669486999512, 'learning_rate': 1.1400000000000001e-05, 'epoch': 1.44}
{'loss': 7.6146, 'grad_norm': 9.332091331481934, 'learning_rate': 1.44e-05, 'epoch': 1.81}
{'eval_loss': 1.0108098983764648, 'eval_runtime': 20.582, 'eval_samples_per_second': 2.235, 'eval_steps_per_second': 2.235, 'epoch': 2.0}

[GenCER Callback] Epoch 2.00 gen_cer = 0.1094 (10.94%)
{'loss': 6.6963, 'grad_norm': 4.063374996185303, 'learning_rate': 1.74e-05, 'epoch': 2.15}
{'loss': 7.4797, 'grad_norm': 4.853774070739746, 'learning_rate': 2.04e-05, 'epoch': 2.52}
{'loss': 7.4017, 'grad_norm': 12.255997657775879, 'learning_rate': 2.3400000000000003e-05, 'epoch': 2.89}
{'eval_loss': 1.0073257684707642, 'eval_runtime': 20.6302, 'eval_samples_per_second': 2.23, 'eval_steps_per_second': 2.23, 'epoch': 3.0}

[GenCER Callback] Epoch 3.00 gen_cer = 0.0976 (9.76%)
{'loss': 6.5189, 'grad_norm': 4.095938682556152, 'learning_rate': 2.64e-05, 'epoch': 3.22}
{'loss': 7.2517, 'grad_norm': 8.661981582641602, 'learning_rate': 2.94e-05, 'epoch': 3.59}
{'loss': 7.2702, 'grad_norm': 6.442061901092529, 'learning_rate': 2.959567305869736e-05, 'epoch': 3.96}
{'eval_loss': 1.005732774734497, 'eval_runtime': 20.6269, 'eval_samples_per_second': 2.23, 'eval_steps_per_second': 2.23, 'epoch': 4.0}

[GenCER Callback] Epoch 4.00 gen_cer = 0.0971 (9.71%)
{'train_runtime': 8690.234, 'train_samples_per_second': 0.198, 'train_steps_per_second': 0.012, 'train_loss': 7.216837619032178, 'epoch': 4.0}

=== BEST CHECKPOINT INFO (Stage 2) ===
Best checkpoint: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_multistage_genCER_INV_noSort_20260215_100532/stage2/checkpoint-14
Best metric (gen_cer): 0.0960061043940026

Saving ONLY best model to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_multistage_genCER_INV_noSort_20260215_100532/best_model_gen_cer

Cleaning up: removing stage2 checkpoint-* folders (keeping only best_model_gen_cer)...
8690.234 seconds used for training.
Peak reserved memory = 15.184 GB (38.447%).

Best model already saved (ONLY ONE) at: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_multistage_genCER_INV_noSort_20260215_100532/best_model_gen_cer

============================================================
STARTING EVALUATION ON TEST.JSONL (IN-MEMORY BEST MODEL)
============================================================
Starting evaluation on INVENTORY test.jsonl with aggressive chunking...
Loaded 47 test samples

============================================================
Chunk 1/10 (5 images)
============================================================

[1/47] Processing: inventarbuch-036.jpg
  âœ… CER: 0.1175 (11.75%)

[2/47] Processing: inventarbuch-100.jpg
  âœ… CER: 0.0808 (8.08%)

[3/47] Processing: inventarbuch-190.jpg
  âœ… CER: 0.0566 (5.66%)

[4/47] Processing: inventarbuch-153.jpg
  âœ… CER: 0.0000 (0.00%)

[5/47] Processing: inventarbuch-041.jpg
  âœ… CER: 0.0663 (6.63%)

============================================================
Chunk 2/10 (5 images)
============================================================

[6/47] Processing: inventarbuch-198.jpg
  âœ… CER: 0.0737 (7.37%)

[7/47] Processing: inventarbuch-065.jpg
  âœ… CER: 0.1416 (14.16%)

[8/47] Processing: inventarbuch-242.jpg
  âœ… CER: 0.0861 (8.61%)

[9/47] Processing: inventarbuch-023.jpg
  âœ… CER: 0.1915 (19.15%)

[10/47] Processing: inventarbuch-137.jpg
  âœ… CER: 0.0967 (9.67%)

============================================================
Chunk 3/10 (5 images)
============================================================

[11/47] Processing: inventarbuch-180.jpg
  âœ… CER: 0.1118 (11.18%)

[12/47] Processing: inventarbuch-188.jpg
  âœ… CER: 0.0542 (5.42%)

[13/47] Processing: inventarbuch-051.jpg
  âœ… CER: 0.0266 (2.66%)

[14/47] Processing: inventarbuch-199.jpg
  âœ… CER: 0.0000 (0.00%)

[15/47] Processing: inventarbuch-296.jpg
  âœ… CER: 0.1540 (15.40%)

============================================================
Chunk 4/10 (5 images)
============================================================

[16/47] Processing: inventarbuch-302.jpg
  âœ… CER: 0.0068 (0.68%)

[17/47] Processing: inventarbuch-176.jpg
  âœ… CER: 0.0522 (5.22%)

[18/47] Processing: inventarbuch-112.jpg
  âœ… CER: 0.0179 (1.79%)

[19/47] Processing: inventarbuch-081.jpg
  âœ… CER: 0.1796 (17.96%)

[20/47] Processing: inventarbuch-290.jpg
  âœ… CER: 0.0687 (6.87%)

============================================================
Chunk 5/10 (5 images)
============================================================

[21/47] Processing: inventarbuch-178.jpg
  âœ… CER: 0.0788 (7.88%)

[22/47] Processing: inventarbuch-299.jpg
  âœ… CER: 0.1017 (10.17%)

[23/47] Processing: inventarbuch-083.jpg
  âœ… CER: 0.1486 (14.86%)

[24/47] Processing: inventarbuch-004.jpg
  âœ… CER: 0.0741 (7.41%)

[25/47] Processing: inventarbuch-145.jpg
  âœ… CER: 0.0575 (5.75%)

============================================================
Chunk 6/10 (5 images)
============================================================

[26/47] Processing: inventarbuch-236.jpg
  âœ… CER: 0.0955 (9.55%)

[27/47] Processing: inventarbuch-114.jpg
  âœ… CER: 0.1046 (10.46%)

[28/47] Processing: inventarbuch-220.jpg
  âœ… CER: 0.0667 (6.67%)

[29/47] Processing: inventarbuch-301.jpg
  âœ… CER: 0.0209 (2.09%)

[30/47] Processing: inventarbuch-103.jpg
  âœ… CER: 0.0588 (5.88%)

============================================================
Chunk 7/10 (5 images)
============================================================

[31/47] Processing: inventarbuch-014.jpg
  âœ… CER: 0.1688 (16.88%)

[32/47] Processing: inventarbuch-265.jpg
  âœ… CER: 0.0289 (2.89%)

[33/47] Processing: inventarbuch-121.jpg
  âœ… CER: 0.0341 (3.41%)

[34/47] Processing: inventarbuch-113.jpg
  âœ… CER: 0.0432 (4.32%)

[35/47] Processing: inventarbuch-049.jpg
  âœ… CER: 0.0000 (0.00%)

============================================================
Chunk 8/10 (5 images)
============================================================

[36/47] Processing: inventarbuch-016.jpg
  âœ… CER: 0.0815 (8.15%)

[37/47] Processing: inventarbuch-017.jpg
  âœ… CER: 0.0038 (0.38%)

[38/47] Processing: inventarbuch-223.jpg
  âœ… CER: 0.0191 (1.91%)

[39/47] Processing: inventarbuch-046.jpg
  âœ… CER: 0.1800 (18.00%)

[40/47] Processing: inventarbuch-286.jpg
  âœ… CER: 0.1003 (10.03%)

============================================================
Chunk 9/10 (5 images)
============================================================

[41/47] Processing: inventarbuch-054.jpg
  âœ… CER: 0.2359 (23.59%)

[42/47] Processing: inventarbuch-073.jpg
  âœ… CER: 0.1601 (16.01%)

[43/47] Processing: inventarbuch-116.jpg
  âœ… CER: 0.0183 (1.83%)

[44/47] Processing: inventarbuch-127.jpg
  âœ… CER: 0.0650 (6.50%)

[45/47] Processing: inventarbuch-143.jpg
  âœ… CER: 0.0259 (2.59%)

============================================================
Chunk 10/10 (2 images)
============================================================

[46/47] Processing: inventarbuch-013.jpg
  âœ… CER: 0.1630 (16.30%)

[47/47] Processing: inventarbuch-059.jpg
  âœ… CER: 0.1042 (10.42%)

CER evaluation results saved to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_multistage_genCER_INV_noSort_20260215_100532/cer_evaluation_results.txt

ðŸŽ‰ Multi-stage training completed!
All outputs saved to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_multistage_genCER_INV_noSort_20260215_100532

Final TEST CER: 0.0813 (8.13%)
Best VALIDATION gen-CER (Stage 2): 0.0960 (9.60%)
ONLY saved best model at: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_multistage_genCER_INV_noSort_20260215_100532/best_model_gen_cer
Gemma-3 training completed at: Sun Feb 15 01:17:02 PM CET 2026
=== JOB_STATISTICS ===
=== current date     : Sun Feb 15 01:17:02 PM CET 2026
= Job-ID             : 1530232 on tinygpu
= Job-Name           : inventory_updated_ms
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_gemma3.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : a100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 03:12:02
= Total RAM usage    : 6.7 GiB of requested  GiB (%)   
= Node list          : tg097
= Subm/Elig/Start/End: 2026-02-13T18:15:51 / 2026-02-13T18:15:51 / 2026-02-15T10:05:00 / 2026-02-15T13:17:02
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody           408.1G  1000.0G  1500.0G        N/A   1,018K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:01:00.0, 131507, 25 %, 5 %, 16090 MiB, 11507895 ms
