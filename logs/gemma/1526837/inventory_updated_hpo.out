### Starting TaskPrologue of job 1526837 on tg096 at Thu Feb 12 05:10:34 PM CET 2026
Running on cores 32-63 with governor ondemand
Thu Feb 12 17:10:34 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.126.16             Driver Version: 580.126.16     CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:41:00.0 Off |                    0 |
| N/A   36C    P0             54W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Created run directory: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260212_171100

============================================================
GEMMA-3 INVENTORY - A100 OPTIMIZED + AUTOREGRESSIVE GEN-CER
============================================================
Loading Gemma-3 vision model with Unsloth for INVENTORY...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.7.3: Fast Gemma3 patching. Transformers: 4.51.3.
   \\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.493 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.1+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.1
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Gemma3 does not support SDPA - switching to eager!
Model loaded - Unsloth auto-configured dtype and attention
Unsloth: Making `base_model.model.vision_tower.vision_model` require gradients
Gemma-3 vision model loaded with A100-optimized LoRA config

============================================================
STARTING TRAINING (BEST MODEL BY AUTOREGRESSIVE GEN-CER)
============================================================
Preparing training and validation datasets...
Training: 215 samples, Validation: 46 samples
[GenCER Callback] Fixed val subset size = 46
GPU = NVIDIA A100-SXM4-40GB. Max memory = 39.493 GB.
4.809 GB of memory reserved.
Starting training with AUTOREGRESSIVE CER-based evaluation (A100-optimized)...
{'loss': 16.7547, 'grad_norm': 747.75244140625, 'learning_rate': 0.0, 'epoch': 0.04}
{'loss': 16.5525, 'grad_norm': 579.7420043945312, 'learning_rate': 2.558313145397147e-06, 'epoch': 0.19}
{'loss': 12.7167, 'grad_norm': 375.2240295410156, 'learning_rate': 5.75620457714358e-06, 'epoch': 0.37}
{'loss': 9.6428, 'grad_norm': 81.9478530883789, 'learning_rate': 8.954096008890014e-06, 'epoch': 0.56}
{'loss': 7.7315, 'grad_norm': 185.44166564941406, 'learning_rate': 1.2151987440636447e-05, 'epoch': 0.74}
{'loss': 5.9828, 'grad_norm': 82.44496154785156, 'learning_rate': 1.534987887238288e-05, 'epoch': 0.93}
{'eval_loss': 1.3045417070388794, 'eval_runtime': 21.3165, 'eval_samples_per_second': 2.158, 'eval_steps_per_second': 2.158, 'epoch': 1.0}

[GenCER Callback] Epoch 1.00 gen_cer = 0.2546 (25.46%)
{'loss': 5.1477, 'grad_norm': 40.692535400390625, 'learning_rate': 1.8547770304129314e-05, 'epoch': 1.11}
{'loss': 4.7693, 'grad_norm': 28.61204719543457, 'learning_rate': 2.174566173587575e-05, 'epoch': 1.3}
{'loss': 4.505, 'grad_norm': 44.03654861450195, 'learning_rate': 2.4943553167622183e-05, 'epoch': 1.48}
{'loss': 4.4585, 'grad_norm': 33.02421569824219, 'learning_rate': 2.8141444599368616e-05, 'epoch': 1.67}
{'loss': 4.3074, 'grad_norm': 31.682146072387695, 'learning_rate': 3.133933603111505e-05, 'epoch': 1.85}
{'eval_loss': 1.0459649562835693, 'eval_runtime': 21.1719, 'eval_samples_per_second': 2.173, 'eval_steps_per_second': 2.173, 'epoch': 2.0}

[GenCER Callback] Epoch 2.00 gen_cer = 0.1250 (12.50%)
{'loss': 4.1169, 'grad_norm': 18.150739669799805, 'learning_rate': 3.4537227462861485e-05, 'epoch': 2.04}
{'loss': 3.9675, 'grad_norm': 52.33396530151367, 'learning_rate': 3.7735118894607915e-05, 'epoch': 2.22}
{'loss': 3.9739, 'grad_norm': 57.872581481933594, 'learning_rate': 4.093301032635435e-05, 'epoch': 2.41}
{'loss': 3.9761, 'grad_norm': 41.28802490234375, 'learning_rate': 4.413090175810078e-05, 'epoch': 2.59}
{'loss': 3.9216, 'grad_norm': 117.62594604492188, 'learning_rate': 4.7328793189847216e-05, 'epoch': 2.78}
{'loss': 3.8146, 'grad_norm': 17.497861862182617, 'learning_rate': 5.052668462159365e-05, 'epoch': 2.96}
{'eval_loss': 0.9953769445419312, 'eval_runtime': 21.0978, 'eval_samples_per_second': 2.18, 'eval_steps_per_second': 2.18, 'epoch': 3.0}

[GenCER Callback] Epoch 3.00 gen_cer = 0.1009 (10.09%)
{'loss': 3.6873, 'grad_norm': 20.197031021118164, 'learning_rate': 5.372457605334008e-05, 'epoch': 3.15}
{'loss': 3.6832, 'grad_norm': 13.974190711975098, 'learning_rate': 5.692246748508652e-05, 'epoch': 3.33}
{'loss': 3.7387, 'grad_norm': 43.719810485839844, 'learning_rate': 6.012035891683295e-05, 'epoch': 3.52}
{'loss': 3.7105, 'grad_norm': 28.038965225219727, 'learning_rate': 6.331825034857938e-05, 'epoch': 3.7}
{'loss': 3.6822, 'grad_norm': 19.919178009033203, 'learning_rate': 6.363959080533925e-05, 'epoch': 3.89}
{'eval_loss': 0.990232527256012, 'eval_runtime': 21.0997, 'eval_samples_per_second': 2.18, 'eval_steps_per_second': 2.18, 'epoch': 4.0}

[GenCER Callback] Epoch 4.00 gen_cer = 0.1107 (11.07%)
{'loss': 3.6893, 'grad_norm': 16.070919036865234, 'learning_rate': 6.235759739045993e-05, 'epoch': 4.07}
{'loss': 3.5963, 'grad_norm': 20.211637496948242, 'learning_rate': 6.0131758212508895e-05, 'epoch': 4.26}
{'loss': 3.5741, 'grad_norm': 18.022741317749023, 'learning_rate': 5.703122863521078e-05, 'epoch': 4.44}
{'loss': 3.547, 'grad_norm': 12.690464973449707, 'learning_rate': 5.315234007944315e-05, 'epoch': 4.63}
{'loss': 3.5767, 'grad_norm': 24.855688095092773, 'learning_rate': 4.861560706915662e-05, 'epoch': 4.81}
{'loss': 3.5572, 'grad_norm': 18.60344886779785, 'learning_rate': 4.356198292413988e-05, 'epoch': 5.0}
{'eval_loss': 0.9718380570411682, 'eval_runtime': 21.1245, 'eval_samples_per_second': 2.178, 'eval_steps_per_second': 2.178, 'epoch': 5.0}

[GenCER Callback] Epoch 5.00 gen_cer = 0.1102 (11.02%)
{'loss': 3.4965, 'grad_norm': 9.432515144348145, 'learning_rate': 3.814848043280015e-05, 'epoch': 5.19}
{'loss': 3.5078, 'grad_norm': 9.170610427856445, 'learning_rate': 3.254329356778438e-05, 'epoch': 5.37}
{'loss': 3.4709, 'grad_norm': 5.454932689666748, 'learning_rate': 2.69205718095377e-05, 'epoch': 5.56}
{'loss': 3.5052, 'grad_norm': 16.88237762451172, 'learning_rate': 2.1455009436139933e-05, 'epoch': 5.74}
{'loss': 3.4682, 'grad_norm': 5.022516250610352, 'learning_rate': 1.631641788663669e-05, 'epoch': 5.93}
{'eval_loss': 0.9663751125335693, 'eval_runtime': 21.0371, 'eval_samples_per_second': 2.187, 'eval_steps_per_second': 2.187, 'epoch': 6.0}

[GenCER Callback] Epoch 6.00 gen_cer = 0.0766 (7.66%)
{'loss': 3.4689, 'grad_norm': 6.629140377044678, 'learning_rate': 1.1664449830977497e-05, 'epoch': 6.11}
{'loss': 3.4404, 'grad_norm': 4.863889694213867, 'learning_rate': 7.64363886624847e-06, 'epoch': 6.3}
{'loss': 3.446, 'grad_norm': 4.000773906707764, 'learning_rate': 4.378908952584841e-06, 'epoch': 6.48}
{'loss': 3.4347, 'grad_norm': 7.298525810241699, 'learning_rate': 1.9716931076451005e-06, 'epoch': 6.67}
{'loss': 3.4347, 'grad_norm': 6.077546119689941, 'learning_rate': 4.967819492643262e-07, 'epoch': 6.85}
{'eval_loss': 0.9676170945167542, 'eval_runtime': 21.0156, 'eval_samples_per_second': 2.189, 'eval_steps_per_second': 2.189, 'epoch': 7.0}

[GenCER Callback] Epoch 7.00 gen_cer = 0.0774 (7.74%)
{'train_runtime': 15077.727, 'train_samples_per_second': 0.1, 'train_steps_per_second': 0.013, 'train_loss': 4.684868641000576, 'epoch': 7.0}
15077.727 seconds used for training.
251.3 minutes used for training.
Peak reserved memory = 14.447 GB.
Peak reserved memory for training = 9.638 GB.
Peak reserved memory % of max memory = 36.581 %.
Peak reserved memory for training % of max memory = 24.404 %.

Saving model to /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260212_171100...
Model (LoRA adapters) saved successfully!

============================================================
STARTING EVALUATION ON TEST.JSONL (USING BEST MODEL)
============================================================
Starting evaluation on test.jsonl with aggressive chunking...
Loaded 47 test samples

============================================================
Chunk 1/10 (5 images)
============================================================

[1/47] Processing: inventarbuch-036.jpg
  âœ… CER: 0.1621 (16.21%)

[2/47] Processing: inventarbuch-100.jpg
  âœ… CER: 0.1061 (10.61%)

[3/47] Processing: inventarbuch-190.jpg
  âœ… CER: 0.1234 (12.34%)

[4/47] Processing: inventarbuch-153.jpg
  âœ… CER: 0.0000 (0.00%)

[5/47] Processing: inventarbuch-041.jpg
  âœ… CER: 0.0580 (5.80%)

Chunk 1 completed. Cleaning memory...

============================================================
Chunk 2/10 (5 images)
============================================================

[6/47] Processing: inventarbuch-198.jpg
  âœ… CER: 0.0797 (7.97%)

[7/47] Processing: inventarbuch-065.jpg
  âœ… CER: 0.1264 (12.64%)

[8/47] Processing: inventarbuch-242.jpg
  âœ… CER: 0.0652 (6.52%)

[9/47] Processing: inventarbuch-023.jpg
  âœ… CER: 0.3468 (34.68%)

[10/47] Processing: inventarbuch-137.jpg
  âœ… CER: 0.0572 (5.72%)

Chunk 2 completed. Cleaning memory...

============================================================
Chunk 3/10 (5 images)
============================================================

[11/47] Processing: inventarbuch-180.jpg
  âœ… CER: 0.0809 (8.09%)

[12/47] Processing: inventarbuch-188.jpg
  âœ… CER: 0.0422 (4.22%)

[13/47] Processing: inventarbuch-051.jpg
  âœ… CER: 0.0178 (1.78%)

[14/47] Processing: inventarbuch-199.jpg
  âœ… CER: 0.0105 (1.05%)

[15/47] Processing: inventarbuch-296.jpg
  âœ… CER: 0.1384 (13.84%)

Chunk 3 completed. Cleaning memory...
Saved intermediate results to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260212_171100/test_predictions_chunk_3.jsonl

============================================================
Chunk 4/10 (5 images)
============================================================

[16/47] Processing: inventarbuch-302.jpg
  âœ… CER: 0.0068 (0.68%)

[17/47] Processing: inventarbuch-176.jpg
  âœ… CER: 0.0071 (0.71%)

[18/47] Processing: inventarbuch-112.jpg
  âœ… CER: 0.0030 (0.30%)

[19/47] Processing: inventarbuch-081.jpg
  âœ… CER: 0.1263 (12.63%)

[20/47] Processing: inventarbuch-290.jpg
  âœ… CER: 0.0756 (7.56%)

Chunk 4 completed. Cleaning memory...

============================================================
Chunk 5/10 (5 images)
============================================================

[21/47] Processing: inventarbuch-178.jpg
  âœ… CER: 0.0477 (4.77%)

[22/47] Processing: inventarbuch-299.jpg
  âœ… CER: 0.0481 (4.81%)

[23/47] Processing: inventarbuch-083.jpg
  âœ… CER: 0.1123 (11.23%)

[24/47] Processing: inventarbuch-004.jpg
  âœ… CER: 0.0584 (5.84%)

[25/47] Processing: inventarbuch-145.jpg
  âœ… CER: 0.0523 (5.23%)

Chunk 5 completed. Cleaning memory...

============================================================
Chunk 6/10 (5 images)
============================================================

[26/47] Processing: inventarbuch-236.jpg
  âœ… CER: 0.0395 (3.95%)

[27/47] Processing: inventarbuch-114.jpg
  âœ… CER: 0.1418 (14.18%)

[28/47] Processing: inventarbuch-220.jpg
  âœ… CER: 0.0201 (2.01%)

[29/47] Processing: inventarbuch-301.jpg
  âœ… CER: 0.0209 (2.09%)

[30/47] Processing: inventarbuch-103.jpg
  âœ… CER: 0.0601 (6.01%)

Chunk 6 completed. Cleaning memory...
Saved intermediate results to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260212_171100/test_predictions_chunk_6.jsonl

============================================================
Chunk 7/10 (5 images)
============================================================

[31/47] Processing: inventarbuch-014.jpg
  âœ… CER: 0.1784 (17.84%)

[32/47] Processing: inventarbuch-265.jpg
  âœ… CER: 0.0208 (2.08%)

[33/47] Processing: inventarbuch-121.jpg
  âœ… CER: 0.0462 (4.62%)

[34/47] Processing: inventarbuch-113.jpg
  âœ… CER: 0.0445 (4.45%)

[35/47] Processing: inventarbuch-049.jpg
  âœ… CER: 0.0000 (0.00%)

Chunk 7 completed. Cleaning memory...

============================================================
Chunk 8/10 (5 images)
============================================================

[36/47] Processing: inventarbuch-016.jpg
  âœ… CER: 0.1139 (11.39%)

[37/47] Processing: inventarbuch-017.jpg
  âœ… CER: 0.0460 (4.60%)

[38/47] Processing: inventarbuch-223.jpg
  âœ… CER: 0.0295 (2.95%)

[39/47] Processing: inventarbuch-046.jpg
  âœ… CER: 0.1173 (11.73%)

[40/47] Processing: inventarbuch-286.jpg
  âœ… CER: 0.8652 (86.52%)

Chunk 8 completed. Cleaning memory...

============================================================
Chunk 9/10 (5 images)
============================================================

[41/47] Processing: inventarbuch-054.jpg
  âœ… CER: 0.1452 (14.52%)

[42/47] Processing: inventarbuch-073.jpg
  âœ… CER: 0.1798 (17.98%)

[43/47] Processing: inventarbuch-116.jpg
  âœ… CER: 0.0396 (3.96%)

[44/47] Processing: inventarbuch-127.jpg
  âœ… CER: 0.0500 (5.00%)

[45/47] Processing: inventarbuch-143.jpg
  âœ… CER: 0.0150 (1.50%)

Chunk 9 completed. Cleaning memory...
Saved intermediate results to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260212_171100/test_predictions_chunk_9.jsonl

============================================================
Chunk 10/10 (2 images)
============================================================

[46/47] Processing: inventarbuch-013.jpg
  âœ… CER: 0.0652 (6.52%)

[47/47] Processing: inventarbuch-059.jpg
  âœ… CER: 0.1819 (18.19%)

Chunk 10 completed. Cleaning memory...
Saved intermediate results to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260212_171100/test_predictions_chunk_10.jsonl

CER evaluation results saved to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260212_171100/cer_evaluation_results.txt

ðŸŽ‰ Gemma-3 Inventory training completed!
All outputs saved to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/inventory_dataset/run_A100_genCER_20260212_171100

Final TEST CER: 0.0930 (9.30%)
Gemma-3 training completed at: Thu Feb 12 09:55:26 PM CET 2026
=== JOB_STATISTICS ===
=== current date     : Thu Feb 12 09:55:26 PM CET 2026
= Job-ID             : 1526837 on tinygpu
= Job-Name           : inventory_updated_hpo
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_gemma2.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : a100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 04:44:52
= Total RAM usage    : 7.7 GiB of requested  GiB (%)   
= Node list          : tg096
= Subm/Elig/Start/End: 2026-02-08T17:16:17 / 2026-02-08T17:16:17 / 2026-02-12T17:10:34 / 2026-02-12T21:55:26
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody           408.1G  1000.0G  1500.0G        N/A   1,018K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:41:00.0, 20877, 23 %, 4 %, 15336 MiB, 17085597 ms
