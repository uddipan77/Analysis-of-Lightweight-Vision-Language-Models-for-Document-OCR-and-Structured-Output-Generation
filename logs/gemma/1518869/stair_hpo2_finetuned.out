### Starting TaskPrologue of job 1518869 on tg091 at Wed Jan 28 03:23:37 AM CET 2026
Running on cores 8-39 with governor ondemand
Wed Jan 28 03:23:37 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:41:00.0 Off |                    0 |
| N/A   36C    P0             56W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Created run directory: /home/vault/iwi5/iwi5298h/models_image_text/gemma/stair/finetune/run_A100_genCER_20260128_032403

======================================================================
GEMMA-3 STAIRCASE - GEN-CER BEST CHECKPOINT TRAINING
======================================================================
Loading Gemma-3 vision model with Unsloth for STAIRCASE...
Temporary directory for augmented images: /tmp/1518869.tinygpu/stair_gemma_aug_joiqu_9o
Augmentation factor (per original image): 1
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.7.3: Fast Gemma3 patching. Transformers: 4.51.3.
   \\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.494 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.1+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.1
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Gemma3 does not support SDPA - switching to eager!
Model loaded - Unsloth auto-configured dtype and attention
Unsloth: Making `base_model.model.vision_tower.vision_model` require gradients
Gemma-3 vision model loaded with LoRA config: r=32, alpha=32, dropout=0.05, rslora=True

======================================================================
STARTING TRAINING (best checkpoint selected by generation CER)
======================================================================
Preparing training and validation datasets for STAIRCASE...
Preparing TRAIN data with augmentation factor = 1
Training: 230 samples (original: 115, augmented: 115)
Val/Test: 25 valid samples out of 25 total (no augmentation)
Training: 230 samples, Validation: 25 samples
[GenCER Callback] Fixed val subset size = 25
GPU = NVIDIA A100-SXM4-40GB. Max memory = 39.494 GB.
4.809 GB of memory reserved.
Starting training (best checkpoint selected by gen_cer)...
{'loss': 37.6351, 'grad_norm': 524.645751953125, 'learning_rate': 0.0, 'epoch': 0.07}
{'loss': 37.7174, 'grad_norm': 516.8115234375, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.35}
{'loss': 36.9888, 'grad_norm': 3746.524169921875, 'learning_rate': 2.7e-06, 'epoch': 0.7}
{'loss': 28.4079, 'grad_norm': 144.60400390625, 'learning_rate': 4.2000000000000004e-06, 'epoch': 1.0}
{'eval_loss': 3.599055767059326, 'eval_cer': 0.3232231779085559, 'eval_cer_percentage': 32.32231779085559, 'eval_runtime': 21.9936, 'eval_samples_per_second': 1.137, 'eval_steps_per_second': 1.137, 'epoch': 1.0}

[GenCER Callback] gen_cer = 0.7334 (73.34%)
{'loss': 26.5922, 'grad_norm': 302.93670654296875, 'learning_rate': 5.7000000000000005e-06, 'epoch': 1.35}
{'loss': 22.9317, 'grad_norm': 62.321685791015625, 'learning_rate': 7.2e-06, 'epoch': 1.7}
{'loss': 18.0617, 'grad_norm': 61.367671966552734, 'learning_rate': 8.7e-06, 'epoch': 2.0}
{'eval_loss': 2.416975259780884, 'eval_cer': 0.29425079221367134, 'eval_cer_percentage': 29.425079221367135, 'eval_runtime': 21.1747, 'eval_samples_per_second': 1.181, 'eval_steps_per_second': 1.181, 'epoch': 2.0}

[GenCER Callback] gen_cer = 0.8635 (86.35%)
{'loss': 18.286, 'grad_norm': 111.72447967529297, 'learning_rate': 1.02e-05, 'epoch': 2.35}
{'loss': 16.0835, 'grad_norm': 77.8818359375, 'learning_rate': 1.1700000000000001e-05, 'epoch': 2.7}
{'loss': 12.3514, 'grad_norm': 22.96921157836914, 'learning_rate': 1.32e-05, 'epoch': 3.0}
{'eval_loss': 1.5757975578308105, 'eval_cer': 0.11634223630602082, 'eval_cer_percentage': 11.634223630602083, 'eval_runtime': 21.3416, 'eval_samples_per_second': 1.171, 'eval_steps_per_second': 1.171, 'epoch': 3.0}

[GenCER Callback] gen_cer = 0.8256 (82.56%)
{'loss': 11.9118, 'grad_norm': 26.063020706176758, 'learning_rate': 1.47e-05, 'epoch': 3.35}
{'loss': 10.4122, 'grad_norm': 29.97841453552246, 'learning_rate': 1.62e-05, 'epoch': 3.7}
{'loss': 8.3546, 'grad_norm': 11.611579895019531, 'learning_rate': 1.77e-05, 'epoch': 4.0}
{'eval_loss': 1.158806324005127, 'eval_cer': 0.01765504753282028, 'eval_cer_percentage': 1.765504753282028, 'eval_runtime': 21.8937, 'eval_samples_per_second': 1.142, 'eval_steps_per_second': 1.142, 'epoch': 4.0}

[GenCER Callback] gen_cer = 0.5648 (56.48%)
{'loss': 9.0815, 'grad_norm': 38.71500015258789, 'learning_rate': 1.9200000000000003e-05, 'epoch': 4.35}
{'loss': 8.638, 'grad_norm': 13.5718994140625, 'learning_rate': 2.07e-05, 'epoch': 4.7}
{'loss': 7.361, 'grad_norm': 7.322473526000977, 'learning_rate': 2.22e-05, 'epoch': 5.0}
{'eval_loss': 1.0413289070129395, 'eval_cer': 0.012222725215029425, 'eval_cer_percentage': 1.2222725215029424, 'eval_runtime': 21.3109, 'eval_samples_per_second': 1.173, 'eval_steps_per_second': 1.173, 'epoch': 5.0}

[GenCER Callback] gen_cer = 0.1185 (11.85%)
{'loss': 8.1192, 'grad_norm': 15.425642967224121, 'learning_rate': 2.37e-05, 'epoch': 5.35}
{'loss': 7.8773, 'grad_norm': 11.837386131286621, 'learning_rate': 2.52e-05, 'epoch': 5.7}
{'loss': 6.8717, 'grad_norm': 5.2943196296691895, 'learning_rate': 2.6700000000000002e-05, 'epoch': 6.0}
{'eval_loss': 0.9822946786880493, 'eval_cer': 0.009506564056133997, 'eval_cer_percentage': 0.9506564056133997, 'eval_runtime': 21.2182, 'eval_samples_per_second': 1.178, 'eval_steps_per_second': 1.178, 'epoch': 6.0}

[GenCER Callback] gen_cer = 0.0835 (8.35%)
{'loss': 7.5788, 'grad_norm': 11.555381774902344, 'learning_rate': 2.8199999999999998e-05, 'epoch': 6.35}
{'loss': 7.5058, 'grad_norm': 11.320958137512207, 'learning_rate': 2.97e-05, 'epoch': 6.7}
{'loss': 6.4831, 'grad_norm': 4.386453151702881, 'learning_rate': 2.974459649525853e-05, 'epoch': 7.0}
{'eval_loss': 0.9634445905685425, 'eval_cer': 0.011770031688546853, 'eval_cer_percentage': 1.1770031688546854, 'eval_runtime': 21.202, 'eval_samples_per_second': 1.179, 'eval_steps_per_second': 1.179, 'epoch': 7.0}

[GenCER Callback] gen_cer = 0.0588 (5.88%)
{'loss': 7.261, 'grad_norm': 8.838675498962402, 'learning_rate': 2.8721908027320315e-05, 'epoch': 7.35}
{'loss': 7.2741, 'grad_norm': 14.445279121398926, 'learning_rate': 2.6970258409203596e-05, 'epoch': 7.7}
{'loss': 6.3226, 'grad_norm': 6.03158712387085, 'learning_rate': 2.458270208477942e-05, 'epoch': 8.0}
{'eval_loss': 0.9602853655815125, 'eval_cer': 0.007695789950203712, 'eval_cer_percentage': 0.7695789950203712, 'eval_runtime': 21.2294, 'eval_samples_per_second': 1.178, 'eval_steps_per_second': 1.178, 'epoch': 8.0}

[GenCER Callback] gen_cer = 0.0552 (5.52%)
{'loss': 7.1322, 'grad_norm': 14.504765510559082, 'learning_rate': 2.1686075336648075e-05, 'epoch': 8.35}
{'loss': 7.114, 'grad_norm': 7.710724830627441, 'learning_rate': 1.843425824925201e-05, 'epoch': 8.7}
{'loss': 6.1933, 'grad_norm': 3.717337131500244, 'learning_rate': 1.5e-05, 'epoch': 9.0}
{'eval_loss': 0.9617113471031189, 'eval_cer': 0.009959257582616569, 'eval_cer_percentage': 0.9959257582616569, 'eval_runtime': 21.2007, 'eval_samples_per_second': 1.179, 'eval_steps_per_second': 1.179, 'epoch': 9.0}

[GenCER Callback] gen_cer = 0.0478 (4.78%)
{'loss': 7.0182, 'grad_norm': 7.67644739151001, 'learning_rate': 1.1565741750747992e-05, 'epoch': 9.35}
{'loss': 6.9868, 'grad_norm': 4.307408332824707, 'learning_rate': 8.313924663351927e-06, 'epoch': 9.7}
{'loss': 6.1457, 'grad_norm': 5.2128753662109375, 'learning_rate': 5.417297915220584e-06, 'epoch': 10.0}
{'eval_loss': 0.9610886573791504, 'eval_cer': 0.009506564056133997, 'eval_cer_percentage': 0.9506564056133997, 'eval_runtime': 21.2606, 'eval_samples_per_second': 1.176, 'eval_steps_per_second': 1.176, 'epoch': 10.0}

[GenCER Callback] gen_cer = 0.0486 (4.86%)
{'train_runtime': 28239.4108, 'train_samples_per_second': 0.098, 'train_steps_per_second': 0.006, 'train_loss': 12.634901746114094, 'epoch': 10.0}

=== BEST CHECKPOINT INFO ===
Best checkpoint: /home/vault/iwi5/iwi5298h/models_image_text/gemma/stair/finetune/run_A100_genCER_20260128_032403/checkpoint-135
Best metric (gen_cer): 0.047822633275423784
28239.4108 seconds used for training.
Peak reserved memory = 16.939 GB (42.89%).

Saving model to /home/vault/iwi5/iwi5298h/models_image_text/gemma/stair/finetune/run_A100_genCER_20260128_032403...
Model (LoRA adapters) saved successfully!

======================================================================
STARTING EVALUATION ON TEST.JSONL
======================================================================
Starting evaluation on STAIRCASE test.jsonl...
Loaded 24 test samples

============================================================
Chunk 1/5 (5 images)
============================================================

[1/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (83).jpg
  âœ… CER: 0.0312 (3.12%)

[2/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (45).jpg
  âœ… CER: 0.0373 (3.73%)

[3/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (27).jpg
  âœ… CER: 0.0297 (2.97%)

[4/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (130).jpg
  âœ… CER: 0.0337 (3.37%)

[5/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (129).jpg
  âœ… CER: 0.0384 (3.84%)

============================================================
Chunk 2/5 (5 images)
============================================================

[6/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (88).jpg
  âœ… CER: 0.0203 (2.03%)

[7/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (102).jpg
  âœ… CER: 0.0287 (2.87%)

[8/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (103).jpg
  âœ… CER: 0.0306 (3.06%)

[9/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (165).jpg
  âœ… CER: 0.0022 (0.22%)

[10/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (43).jpg
  âœ… CER: 0.0135 (1.35%)

============================================================
Chunk 3/5 (5 images)
============================================================

[11/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (11).jpg
  âœ… CER: 0.0306 (3.06%)

[12/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (36).jpg
  âœ… CER: 0.0775 (7.75%)

[13/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (87).jpg
  âœ… CER: 0.0150 (1.50%)

[14/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (94).jpg
  âœ… CER: 0.1073 (10.73%)

[15/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (58).jpg
  âœ… CER: 0.0466 (4.66%)
Saved intermediate results to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/stair/finetune/run_A100_genCER_20260128_032403/test_predictions_chunk_3.jsonl

============================================================
Chunk 4/5 (5 images)
============================================================

[16/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (111).jpg
  âœ… CER: 0.0088 (0.88%)

[17/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (99).jpg
  âœ… CER: 0.0324 (3.24%)

[18/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (116).jpg
  âœ… CER: 0.0261 (2.61%)

[19/24] Processing: FMIS_FormblaÌˆtterMielke_Vorlage3.jpg
  âœ… CER: 0.0467 (4.67%)

[20/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (132).jpg
  âœ… CER: 0.0190 (1.90%)

============================================================
Chunk 5/5 (4 images)
============================================================

[21/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (139).jpg
  âœ… CER: 0.0490 (4.90%)

[22/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (66).jpg
  âœ… CER: 0.0345 (3.45%)

[23/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (105).jpg
  âœ… CER: 0.0369 (3.69%)

[24/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (13).jpg
  âœ… CER: 0.0277 (2.77%)
Saved intermediate results to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/stair/finetune/run_A100_genCER_20260128_032403/test_predictions_chunk_5.jsonl

CER evaluation results saved to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/stair/finetune/run_A100_genCER_20260128_032403/cer_evaluation_results.txt

ðŸŽ‰ Training completed!
All outputs saved to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/stair/finetune/run_A100_genCER_20260128_032403

Final TEST CER: 0.0343 (3.43%)
Cleaned up temporary directory: /tmp/1518869.tinygpu/stair_gemma_aug_joiqu_9o
Gemma-3 training completed at: Wed Jan 28 11:49:22 AM CET 2026
=== JOB_STATISTICS ===
=== current date     : Wed Jan 28 11:49:23 AM CET 2026
= Job-ID             : 1518869 on tinygpu
= Job-Name           : stair_hpo2
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_gemma2.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : a100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 08:25:47
= Total RAM usage    : 9.3 GiB of requested  GiB (%)   
= Node list          : tg091
= Subm/Elig/Start/End: 2026-01-27T22:05:34 / 2026-01-27T22:05:34 / 2026-01-28T03:23:35 / 2026-01-28T11:49:22
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc              88.1G   104.9G   209.7G        N/A  29,260      500K   1,000K        N/A    
    /home/woody           219.6G  1000.0G  1500.0G        N/A   1,017K   5,000K   7,500K        N/A    
    /home/vault          1045.0G  1048.6G  2097.2G        N/A   8,590      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:41:00.0, 2252223, 22 %, 3 %, 17888 MiB, 30334763 ms
