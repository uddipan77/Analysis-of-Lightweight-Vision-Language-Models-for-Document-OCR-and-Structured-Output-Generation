Unsloth: KwargsForCausalLM cannot be inherited from TransformersKwargs since it's of type = <class 'type'>
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.
Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.
  0%|          | 0/168 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  1%|          | 1/168 [00:24<1:07:03, 24.09s/it]                                                   1%|          | 1/168 [00:24<1:07:03, 24.09s/it]  1%|          | 2/168 [00:46<1:04:25, 23.29s/it]  2%|â–         | 3/168 [01:08<1:02:31, 22.73s/it]  2%|â–         | 4/168 [01:30<1:01:08, 22.37s/it]  3%|â–Ž         | 5/168 [01:52<1:00:32, 22.29s/it]                                                   3%|â–Ž         | 5/168 [01:52<1:00:32, 22.29s/it]  4%|â–Ž         | 6/168 [02:14<1:00:02, 22.24s/it]  4%|â–         | 7/168 [02:36<59:24, 22.14s/it]    5%|â–         | 8/168 [02:59<59:03, 22.15s/it]  5%|â–Œ         | 9/168 [03:21<58:44, 22.17s/it]  6%|â–Œ         | 10/168 [03:43<58:08, 22.08s/it]                                                  6%|â–Œ         | 10/168 [03:43<58:08, 22.08s/it]  7%|â–‹         | 11/168 [04:05<57:56, 22.14s/it]  7%|â–‹         | 12/168 [04:27<57:30, 22.12s/it]  8%|â–Š         | 13/168 [04:49<56:57, 22.05s/it]  8%|â–Š         | 14/168 [05:11<56:33, 22.03s/it]  9%|â–‰         | 15/168 [05:18<45:00, 17.65s/it]                                                  9%|â–‰         | 15/168 [05:18<45:00, 17.65s/it]Unsloth: Not an error, but Gemma3ForConditionalGeneration does not accept `num_items_in_batch`.
Using gradient accumulation will be very slightly less accurate.
Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:12,  1.78it/s][A
 12%|â–ˆâ–        | 3/25 [00:01<00:15,  1.46it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:02<00:15,  1.35it/s][A
 20%|â–ˆâ–ˆ        | 5/25 [00:03<00:15,  1.29it/s][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:04<00:15,  1.24it/s][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:05<00:14,  1.21it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:06<00:14,  1.19it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:07<00:13,  1.18it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:07<00:12,  1.18it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:08<00:12,  1.16it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:09<00:11,  1.16it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:10<00:11,  1.05it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:12<00:11,  1.02s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:13<00:10,  1.07s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:14<00:09,  1.06s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:15<00:07,  1.01it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:15<00:06,  1.06it/s][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:16<00:05,  1.11it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:17<00:04,  1.14it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:18<00:03,  1.15it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:19<00:02,  1.16it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:20<00:01,  1.08it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:21<00:00,  1.12it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:21<00:00,  1.32it/s][A                                                
                                               [A  9%|â–‰         | 15/168 [05:42<45:00, 17.65s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:22<00:00,  1.32it/s][Aearly stopping required metric_for_best_model, but did not find eval_gen_cer so early stopping is disabled

                                               [ATraceback (most recent call last):
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/transformers/trainer.py", line 3165, in _determine_best_metric
    metric_value = metrics[metric_to_check]
                   ~~~~~~~^^^^^^^^^^^^^^^^^
KeyError: 'eval_gen_cer'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/gemma3/finetune/stair_hpo2.py", line 988, in <module>
    main()
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/gemma3/finetune/stair_hpo2.py", line 952, in main
    trainer = finetuner.train_model(
              ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/gemma3/finetune/stair_hpo2.py", line 685, in train_model
    trainer_stats = trainer.train()
                    ^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/transformers/trainer.py", line 2661, in _inner_training_loop
    self._maybe_log_save_evaluate(
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/transformers/trainer.py", line 3097, in _maybe_log_save_evaluate
    is_new_best_metric = self._determine_best_metric(metrics=metrics, trial=trial)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/transformers/trainer.py", line 3167, in _determine_best_metric
    raise KeyError(
KeyError: "The `metric_for_best_model` training argument is set to 'eval_gen_cer', which is not found in the evaluation metrics. The available evaluation metrics are: ['eval_loss', 'eval_cer', 'eval_cer_percentage', 'eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second', 'gen_cer', 'gen_cer_percentage']. Consider changing the `metric_for_best_model` via the TrainingArguments."
  9%|â–‰         | 15/168 [41:45<7:05:56, 167.03s/it]
