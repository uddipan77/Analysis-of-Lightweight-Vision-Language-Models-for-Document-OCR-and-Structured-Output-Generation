### Starting TaskPrologue of job 1311884 on tg092 at Wed Nov 12 10:19:01 PM CET 2025
Running on cores 0-31 with governor ondemand
Wed Nov 12 22:19:01 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:01:00.0 Off |                    0 |
| N/A   42C    P0             60W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Created run directory: /home/vault/iwi5/iwi5298h/models_image_text/gemma/stair/finetune/run_A100_20251112_221932

============================================================
GEMMA-3 STAIRCASE - A100 OPTIMIZED + AUGMENTATION (factor=1)
============================================================
Loading Gemma-3 vision model with Unsloth for STAIRCASE...
Temporary directory for augmented images: /tmp/1311884.tinygpu/stair_gemma_aug_x27pmhdx
Augmentation factor (per original image): 1
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.7.3: Fast Gemma3 patching. Transformers: 4.51.3.
   \\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.494 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.1+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.1
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Gemma3 does not support SDPA - switching to eager!
Model loaded - Unsloth auto-configured dtype and attention
Unsloth: Making `base_model.model.vision_tower.vision_model` require gradients
Gemma-3 vision model loaded with A100-optimized LoRA config

============================================================
STARTING TRAINING (A100-OPTIMIZED, STAIRCASE)
============================================================
Preparing training and validation datasets for STAIRCASE...
Preparing staircase TRAIN data with augmentation factor = 1
  Augmenting [1/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (10).jpg (1/1)
  Augmenting [2/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (114).jpg (1/1)
  Augmenting [3/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (12).jpg (1/1)
  Augmenting [4/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (123).jpg (1/1)
  Augmenting [5/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (125).jpg (1/1)
  Augmenting [6/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (126).jpg (1/1)
  Augmenting [7/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (134).jpg (1/1)
  Augmenting [8/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (136).jpg (1/1)
  Augmenting [9/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (138).jpg (1/1)
  Augmenting [10/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (14).jpg (1/1)
  Augmenting [11/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (149).jpg (1/1)
  Augmenting [12/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (15).jpg (1/1)
  Augmenting [13/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (152).jpg (1/1)
  Augmenting [14/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (154).jpg (1/1)
  Augmenting [15/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (159).jpg (1/1)
  Augmenting [16/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (160).jpg (1/1)
  Augmenting [17/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (163).jpg (1/1)
  Augmenting [18/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (164).jpg (1/1)
  Augmenting [19/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (18).jpg (1/1)
  Augmenting [20/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (20).jpg (1/1)
  Augmenting [21/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (28).jpg (1/1)
  Augmenting [22/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (29).jpg (1/1)
  Augmenting [23/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (30).jpg (1/1)
  Augmenting [24/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (31).jpg (1/1)
  Augmenting [25/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (33).jpg (1/1)
  Augmenting [26/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (38).jpg (1/1)
  Augmenting [27/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (51).jpg (1/1)
  Augmenting [28/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (52).jpg (1/1)
  Augmenting [29/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (53).jpg (1/1)
  Augmenting [30/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (55).jpg (1/1)
  Augmenting [31/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (56).jpg (1/1)
  Augmenting [32/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (6).jpg (1/1)
  Augmenting [33/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (81).jpg (1/1)
  Augmenting [34/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (85).jpg (1/1)
  Augmenting [35/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (89).jpg (1/1)
  Augmenting [36/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (108).jpg (1/1)
  Augmenting [37/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (65).jpg (1/1)
  Augmenting [38/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (75).jpg (1/1)
  Augmenting [39/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (46).jpg (1/1)
  Augmenting [40/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (157).jpg (1/1)
  Augmenting [41/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (115).jpg (1/1)
  Augmenting [42/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (25).jpg (1/1)
  Augmenting [43/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (4).jpg (1/1)
  Augmenting [44/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (77).jpg (1/1)
  Augmenting [45/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (73).jpg (1/1)
  Augmenting [46/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (155).jpg (1/1)
  Augmenting [47/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (120).jpg (1/1)
  Augmenting [48/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (131).jpg (1/1)
  Augmenting [49/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (59).jpg (1/1)
  Augmenting [50/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (133).jpg (1/1)
  Augmenting [51/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (158).jpg (1/1)
  Augmenting [52/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (26).jpg (1/1)
  Augmenting [53/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (97).jpg (1/1)
  Augmenting [54/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (69).jpg (1/1)
  Augmenting [55/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (117).jpg (1/1)
  Augmenting [56/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (67).jpg (1/1)
  Augmenting [57/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (101).jpg (1/1)
  Augmenting [58/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (32).jpg (1/1)
  Augmenting [59/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (49).jpg (1/1)
  Augmenting [60/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (140).jpg (1/1)
  Augmenting [61/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (92).jpg (1/1)
  Augmenting [62/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (106).jpg (1/1)
  Augmenting [63/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (100).jpg (1/1)
  Augmenting [64/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (60).jpg (1/1)
  Augmenting [65/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (48).jpg (1/1)
  Augmenting [66/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (128).jpg (1/1)
  Augmenting [67/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (64).jpg (1/1)
  Augmenting [68/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (23).jpg (1/1)
  Augmenting [69/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (41).jpg (1/1)
  Augmenting [70/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (68).jpg (1/1)
  Augmenting [71/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (22).jpg (1/1)
  Augmenting [72/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (143).jpg (1/1)
  Augmenting [73/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (40).jpg (1/1)
  Augmenting [74/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (137).jpg (1/1)
  Augmenting [75/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (16).jpg (1/1)
  Augmenting [76/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (24).jpg (1/1)
  Augmenting [77/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (142).jpg (1/1)
  Augmenting [78/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (84).jpg (1/1)
  Augmenting [79/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (145).jpg (1/1)
  Augmenting [80/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (57).jpg (1/1)
  Augmenting [81/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (47).jpg (1/1)
  Augmenting [82/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (19).jpg (1/1)
  Augmenting [83/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (146).jpg (1/1)
  Augmenting [84/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (54).jpg (1/1)
  Augmenting [85/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (121).jpg (1/1)
  Augmenting [86/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (161).jpg (1/1)
  Augmenting [87/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (76).jpg (1/1)
  Augmenting [88/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (122).jpg (1/1)
  Augmenting [89/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (7).jpg (1/1)
  Augmenting [90/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (144).jpg (1/1)
  Augmenting [91/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (79).jpg (1/1)
  Augmenting [92/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (95).jpg (1/1)
  Augmenting [93/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (34).jpg (1/1)
  Augmenting [94/115] FMIS_FormblaÌˆtterMielke_Vorlage2.jpg (1/1)
  Augmenting [95/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (17).jpg (1/1)
  Augmenting [96/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (112).jpg (1/1)
  Augmenting [97/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (62).jpg (1/1)
  Augmenting [98/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (3).jpg (1/1)
  Augmenting [99/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (71).jpg (1/1)
  Augmenting [100/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (8).jpg (1/1)
  Augmenting [101/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (44).jpg (1/1)
  Augmenting [102/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (107).jpg (1/1)
  Augmenting [103/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (124).jpg (1/1)
  Augmenting [104/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (153).jpg (1/1)
  Augmenting [105/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (141).jpg (1/1)
  Augmenting [106/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (37).jpg (1/1)
  Augmenting [107/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (109).jpg (1/1)
  Augmenting [108/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (5).jpg (1/1)
  Augmenting [109/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (113).jpg (1/1)
  Augmenting [110/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (35).jpg (1/1)
  Augmenting [111/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (21).jpg (1/1)
  Augmenting [112/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (104).jpg (1/1)
  Augmenting [113/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (135).jpg (1/1)
  Augmenting [114/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (78).jpg (1/1)
  Augmenting [115/115] FMIS_FormblaÌˆtterMielke_gefÃ¼llt (148).jpg (1/1)
Training: 230 samples (original: 115, augmented: 115)
Validation/Test: 25 valid samples out of 25 total (no augmentation)
Training: 230 samples (with augmentation), Validation: 25 samples
GPU = NVIDIA A100-SXM4-40GB. Max memory = 39.494 GB.
4.809 GB of memory reserved.
Starting training with CER-based evaluation (A100-optimized, STAIRCASE)...
{'loss': 12.6583, 'grad_norm': 163.8400421142578, 'learning_rate': 0.0, 'epoch': 0.07}
{'loss': 12.543, 'grad_norm': 229.06410217285156, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.35}
{'loss': 12.2627, 'grad_norm': 204.60372924804688, 'learning_rate': 2.7e-06, 'epoch': 0.7}
{'loss': 9.4838, 'grad_norm': 66.53907775878906, 'learning_rate': 4.2000000000000004e-06, 'epoch': 1.0}
{'eval_loss': 1.179611086845398, 'eval_cer': 0.19960861056751467, 'eval_cer_percentage': 19.960861056751465, 'eval_runtime': 24.6599, 'eval_samples_per_second': 1.014, 'eval_steps_per_second': 1.014, 'epoch': 1.0}
{'loss': 8.5757, 'grad_norm': 79.0790786743164, 'learning_rate': 5.7000000000000005e-06, 'epoch': 1.35}
{'loss': 7.0143, 'grad_norm': 60.35579299926758, 'learning_rate': 7.2e-06, 'epoch': 1.7}
{'loss': 5.0963, 'grad_norm': 15.766021728515625, 'learning_rate': 8.7e-06, 'epoch': 2.0}
{'eval_loss': 0.6380663514137268, 'eval_cer': 0.14760972882303605, 'eval_cer_percentage': 14.760972882303605, 'eval_runtime': 22.8557, 'eval_samples_per_second': 1.094, 'eval_steps_per_second': 1.094, 'epoch': 2.0}
{'loss': 4.567, 'grad_norm': 32.53172302246094, 'learning_rate': 1.02e-05, 'epoch': 2.35}
{'loss': 3.439, 'grad_norm': 25.90792465209961, 'learning_rate': 1.1700000000000001e-05, 'epoch': 2.7}
{'loss': 2.1375, 'grad_norm': 23.06782341003418, 'learning_rate': 1.32e-05, 'epoch': 3.0}
{'eval_loss': 0.21365179121494293, 'eval_cer': 0.033547665641599105, 'eval_cer_percentage': 3.3547665641599105, 'eval_runtime': 22.7583, 'eval_samples_per_second': 1.098, 'eval_steps_per_second': 1.098, 'epoch': 3.0}
{'loss': 1.4449, 'grad_norm': 12.000293731689453, 'learning_rate': 1.47e-05, 'epoch': 3.35}
{'loss': 0.9817, 'grad_norm': 15.60952091217041, 'learning_rate': 1.62e-05, 'epoch': 3.7}
{'loss': 0.6224, 'grad_norm': 6.361422538757324, 'learning_rate': 1.77e-05, 'epoch': 4.0}
{'eval_loss': 0.08970239758491516, 'eval_cer': 0.01062342745317305, 'eval_cer_percentage': 1.062342745317305, 'eval_runtime': 22.7391, 'eval_samples_per_second': 1.099, 'eval_steps_per_second': 1.099, 'epoch': 4.0}
{'loss': 0.6061, 'grad_norm': 7.4701948165893555, 'learning_rate': 1.9200000000000003e-05, 'epoch': 4.35}
{'loss': 0.4937, 'grad_norm': 7.220584392547607, 'learning_rate': 2.07e-05, 'epoch': 4.7}
{'loss': 0.3791, 'grad_norm': 4.755666255950928, 'learning_rate': 2.22e-05, 'epoch': 5.0}
{'eval_loss': 0.06448841840028763, 'eval_cer': 0.007548224769359799, 'eval_cer_percentage': 0.7548224769359799, 'eval_runtime': 22.7693, 'eval_samples_per_second': 1.098, 'eval_steps_per_second': 1.098, 'epoch': 5.0}
{'loss': 0.3276, 'grad_norm': 7.599928855895996, 'learning_rate': 2.37e-05, 'epoch': 5.35}
{'loss': 0.2497, 'grad_norm': 6.776315212249756, 'learning_rate': 2.52e-05, 'epoch': 5.7}
{'loss': 0.2506, 'grad_norm': 5.185243606567383, 'learning_rate': 2.6700000000000002e-05, 'epoch': 6.0}
{'eval_loss': 0.0573439821600914, 'eval_cer': 0.009505171931786413, 'eval_cer_percentage': 0.9505171931786414, 'eval_runtime': 157.7801, 'eval_samples_per_second': 0.158, 'eval_steps_per_second': 0.158, 'epoch': 6.0}
{'loss': 0.1953, 'grad_norm': 12.468496322631836, 'learning_rate': 2.8199999999999998e-05, 'epoch': 6.35}
{'loss': 0.1977, 'grad_norm': 9.055450439453125, 'learning_rate': 2.97e-05, 'epoch': 6.7}
{'loss': 0.1336, 'grad_norm': 3.895944356918335, 'learning_rate': 2.974459649525853e-05, 'epoch': 7.0}
{'eval_loss': 0.06093442067503929, 'eval_cer': 0.007548224769359799, 'eval_cer_percentage': 0.7548224769359799, 'eval_runtime': 22.8112, 'eval_samples_per_second': 1.096, 'eval_steps_per_second': 1.096, 'epoch': 7.0}
{'train_runtime': 2782.2266, 'train_samples_per_second': 0.992, 'train_steps_per_second': 0.06, 'train_loss': 3.3821376613208227, 'epoch': 7.0}
2782.2266 seconds used for training.
46.37 minutes used for training.
Peak reserved memory = 19.324 GB.
Peak reserved memory for training = 14.515 GB.
Peak reserved memory % of max memory = 48.929 %.
Peak reserved memory for training % of max memory = 36.752 %.

Saving model to /home/vault/iwi5/iwi5298h/models_image_text/gemma/stair/finetune/run_A100_20251112_221932...
Model (LoRA adapters) saved successfully!

============================================================
STARTING EVALUATION ON STAIRCASE TEST.JSONL
============================================================
Starting evaluation on STAIRCASE test.jsonl with aggressive chunking...
Loaded 24 test samples

============================================================
Chunk 1/5 (5 images)
============================================================

[1/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (83).jpg
  âœ… CER: 0.6100 (61.00%)

[2/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (45).jpg
  âœ… CER: 0.6056 (60.56%)

[3/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (27).jpg
  âœ… CER: 0.3418 (34.18%)

[4/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (130).jpg
  âœ… CER: 0.3162 (31.62%)

[5/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (129).jpg
  âœ… CER: 0.6124 (61.24%)

Chunk 1 completed. Cleaning memory...

============================================================
Chunk 2/5 (5 images)
============================================================

[6/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (88).jpg
  âœ… CER: 0.6155 (61.55%)

[7/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (102).jpg
  âœ… CER: 0.2902 (29.02%)

[8/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (103).jpg
  âœ… CER: 0.6137 (61.37%)

[9/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (165).jpg
  âœ… CER: 0.6102 (61.02%)

[10/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (43).jpg
  âœ… CER: 0.5988 (59.88%)

Chunk 2 completed. Cleaning memory...

============================================================
Chunk 3/5 (5 images)
============================================================

[11/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (11).jpg
  âœ… CER: 0.6012 (60.12%)

[12/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (36).jpg
  âœ… CER: 0.8992 (89.92%)

[13/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (87).jpg
  âœ… CER: 0.6104 (61.04%)

[14/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (94).jpg
  âœ… CER: 0.6156 (61.56%)

[15/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (58).jpg
  âœ… CER: 0.8887 (88.87%)

Chunk 3 completed. Cleaning memory...
Saved intermediate results to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/stair/finetune/run_A100_20251112_221932/test_predictions_chunk_3.jsonl

============================================================
Chunk 4/5 (5 images)
============================================================

[16/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (111).jpg
  âœ… CER: 0.6086 (60.86%)

[17/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (99).jpg
  âœ… CER: 0.6131 (61.31%)

[18/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (116).jpg
  âœ… CER: 0.6039 (60.39%)

[19/24] Processing: FMIS_FormblaÌˆtterMielke_Vorlage3.jpg
  âœ… CER: 0.0408 (4.08%)

[20/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (132).jpg
  âœ… CER: 0.6078 (60.78%)

Chunk 4 completed. Cleaning memory...

============================================================
Chunk 5/5 (4 images)
============================================================

[21/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (139).jpg
  âœ… CER: 0.6202 (62.02%)

[22/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (66).jpg
  âœ… CER: 0.6128 (61.28%)

[23/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (105).jpg
  âœ… CER: 0.5954 (59.54%)

[24/24] Processing: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (13).jpg
  âœ… CER: 0.6119 (61.19%)

Chunk 5 completed. Cleaning memory...
Saved intermediate results to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/stair/finetune/run_A100_20251112_221932/test_predictions_chunk_5.jsonl

CER evaluation results saved to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/stair/finetune/run_A100_20251112_221932/cer_evaluation_results.txt

ðŸŽ‰ Gemma-3 Staircase training completed!
All outputs saved to: /home/vault/iwi5/iwi5298h/models_image_text/gemma/stair/finetune/run_A100_20251112_221932

Final CER: 0.5727 (57.27%)
Cleaned up temporary directory: /tmp/1311884.tinygpu/stair_gemma_aug_x27pmhdx
Gemma-3 training completed at: Thu Nov 13 12:00:56 AM CET 2025
=== JOB_STATISTICS ===
=== current date     : Thu Nov 13 12:00:56 AM CET 2025
= Job-ID             : 1311884 on tinygpu
= Job-Name           : gemma_stair2
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_gemma.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : a100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 01:41:56
= Total RAM usage    : 12.3 GiB of requested  GiB (%)   
= Node list          : tg092
= Subm/Elig/Start/End: 2025-11-12T17:57:47 / 2025-11-12T17:57:47 / 2025-11-12T22:19:00 / 2025-11-13T00:00:56
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc             102.1G   104.9G   209.7G        N/A  30,751      500K   1,000K        N/A    
    /home/woody           184.5G  1000.0G  1500.0G        N/A     841K   5,000K   7,500K        N/A    
!!! /home/vault          1049.2G  1048.6G  2097.2G  -29299days   6,283      200K     400K        N/A !!!
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:01:00.0, 2327159, 31 %, 11 %, 20328 MiB, 6107141 ms
