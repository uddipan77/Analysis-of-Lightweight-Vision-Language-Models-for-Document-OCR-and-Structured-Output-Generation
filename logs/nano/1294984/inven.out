### Starting TaskPrologue of job 1294984 on tg072 at Sun Nov  2 05:59:33 PM CET 2025
Running on cores 6-7,14-15,22-23,30-31 with governor ondemand
Sun Nov  2 17:59:33 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           Off |   00000000:AF:00.0 Off |                    0 |
| N/A   28C    P0             26W /  250W |       0MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.
ü¶• Unsloth Zoo will now patch everything to make training faster!

================================================================================
üöÄ NANONETS-OCR-S FINETUNING + OPTUNA HPO
   Inventory Dataset with Data Augmentation
================================================================================

üíæ Config saved to: /home/vault/iwi5/iwi5298h/models_image_text/nanonets/hpo/inven/training_config.json

================================================================================
üìä PHASE 1: OPTUNA HYPERPARAMETER OPTIMIZATION
================================================================================

‚è≥ Loading/creating Optuna study...
   Database: /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/vlmmodels.db
   Study name: nanonets_inven

üìä Study Status:
   ‚Ä¢ Completed trials: 0/20
   ‚Ä¢ Remaining trials: 20

üöÄ Starting Optuna optimization (20 trials)...

================================================================================
üî¨ OPTUNA TRIAL #0 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #0:
   ‚Ä¢ num_epochs:    11
   ‚Ä¢ learning_rate: 2.47e-05
   ‚Ä¢ weight_decay:  0.0306
   ‚Ä¢ batch_size:    2

‚è≥ Loading model for Trial #0...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_njyjxthg
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #0...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 3.594 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 2, Grad accum: 4
================================================================================

üöÄ Starting training...
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.7893, 'grad_norm': 1.4003472328186035, 'learning_rate': 4.4501298245280214e-06, 'epoch': 0.19}
{'loss': 0.7301, 'grad_norm': 0.6493849158287048, 'learning_rate': 9.394718518448045e-06, 'epoch': 0.38}
{'loss': 0.6251, 'grad_norm': 0.3788015842437744, 'learning_rate': 1.4339307212368068e-05, 'epoch': 0.56}
{'loss': 0.5539, 'grad_norm': 0.3501385450363159, 'learning_rate': 1.9283895906288092e-05, 'epoch': 0.75}
{'loss': 0.4503, 'grad_norm': 0.7652587294578552, 'learning_rate': 2.4228484600208115e-05, 'epoch': 0.94}
{'eval_loss': 1.2348519563674927, 'eval_runtime': 19.9326, 'eval_samples_per_second': 2.358, 'eval_steps_per_second': 1.204, 'epoch': 1.0}
{'loss': 0.4021, 'grad_norm': 0.285442978143692, 'learning_rate': 2.470625066227278e-05, 'epoch': 1.11}
{'loss': 0.2222, 'grad_norm': 0.1900002807378769, 'learning_rate': 2.4648605008923736e-05, 'epoch': 1.3}
{'loss': 0.203, 'grad_norm': 0.17259596288204193, 'learning_rate': 2.454999257721885e-05, 'epoch': 1.49}
{'loss': 0.2022, 'grad_norm': 0.1367536038160324, 'learning_rate': 2.441074215285148e-05, 'epoch': 1.68}
{'loss': 0.1716, 'grad_norm': 0.13298232853412628, 'learning_rate': 2.4231318013464235e-05, 'epoch': 1.86}
{'eval_loss': 0.7251255512237549, 'eval_runtime': 19.4365, 'eval_samples_per_second': 2.418, 'eval_steps_per_second': 1.235, 'epoch': 2.0}
{'loss': 0.229, 'grad_norm': 0.17545071244239807, 'learning_rate': 2.401231838069156e-05, 'epoch': 2.04}
{'loss': 0.1713, 'grad_norm': 0.17237839102745056, 'learning_rate': 2.3754473425616963e-05, 'epoch': 2.23}
{'loss': 0.1692, 'grad_norm': 0.14689159393310547, 'learning_rate': 2.3458642834294867e-05, 'epoch': 2.41}
{'loss': 0.1568, 'grad_norm': 0.1515122652053833, 'learning_rate': 2.3125812941454066e-05, 'epoch': 2.6}
{'loss': 0.1719, 'grad_norm': 0.15679045021533966, 'learning_rate': 2.275709344193924e-05, 'epoch': 2.79}
{'loss': 0.1591, 'grad_norm': 0.1589277684688568, 'learning_rate': 2.235371369085505e-05, 'epoch': 2.98}
{'eval_loss': 0.6859586834907532, 'eval_runtime': 19.6326, 'eval_samples_per_second': 2.394, 'eval_steps_per_second': 1.222, 'epoch': 3.0}
{'loss': 0.2226, 'grad_norm': 0.15558600425720215, 'learning_rate': 2.191701860474851e-05, 'epoch': 3.15}
{'loss': 0.1542, 'grad_norm': 0.16171136498451233, 'learning_rate': 2.1448464177495705e-05, 'epoch': 3.34}
{'loss': 0.1679, 'grad_norm': 0.15718288719654083, 'learning_rate': 2.094961262584326e-05, 'epoch': 3.53}
{'loss': 0.1462, 'grad_norm': 0.15798842906951904, 'learning_rate': 2.0422127180790058e-05, 'epoch': 3.71}
{'loss': 0.1475, 'grad_norm': 0.1864246279001236, 'learning_rate': 1.986776654217531e-05, 'epoch': 3.9}
{'eval_loss': 0.6696658730506897, 'eval_runtime': 19.5536, 'eval_samples_per_second': 2.404, 'eval_steps_per_second': 1.227, 'epoch': 4.0}
{'loss': 0.1842, 'grad_norm': 0.2072475701570511, 'learning_rate': 1.928837901496199e-05, 'epoch': 4.08}
{'loss': 0.144, 'grad_norm': 0.16520647704601288, 'learning_rate': 1.8685896346766072e-05, 'epoch': 4.26}
{'loss': 0.1497, 'grad_norm': 0.17993539571762085, 'learning_rate': 1.8062327287177927e-05, 'epoch': 4.45}
{'loss': 0.1347, 'grad_norm': 0.19002537429332733, 'learning_rate': 1.741975089034988e-05, 'epoch': 4.64}
{'loss': 0.1376, 'grad_norm': 0.18500743806362152, 'learning_rate': 1.6760309583179908e-05, 'epoch': 4.83}
{'loss': 0.1799, 'grad_norm': 1.6408313512802124, 'learning_rate': 1.608620202220301e-05, 'epoch': 5.0}
{'eval_loss': 0.6637346744537354, 'eval_runtime': 16.9738, 'eval_samples_per_second': 2.769, 'eval_steps_per_second': 1.414, 'epoch': 5.0}
{'loss': 0.1438, 'grad_norm': 0.2281835973262787, 'learning_rate': 1.5399675763006187e-05, 'epoch': 5.19}
{'loss': 0.1299, 'grad_norm': 0.25125330686569214, 'learning_rate': 1.470301976660814e-05, 'epoch': 5.38}
{'loss': 0.128, 'grad_norm': 0.21904821693897247, 'learning_rate': 1.3998556767788243e-05, 'epoch': 5.56}
{'loss': 0.1252, 'grad_norm': 0.2156105786561966, 'learning_rate': 1.3288635530809794e-05, 'epoch': 5.75}
{'loss': 0.1261, 'grad_norm': 0.2432326078414917, 'learning_rate': 1.2575623018357777e-05, 'epoch': 5.94}
{'eval_loss': 0.6675758361816406, 'eval_runtime': 19.122, 'eval_samples_per_second': 2.458, 'eval_steps_per_second': 1.255, 'epoch': 6.0}
{'loss': 0.1883, 'grad_norm': 0.23810376226902008, 'learning_rate': 1.186189649980097e-05, 'epoch': 6.11}
{'loss': 0.1304, 'grad_norm': 0.2558850646018982, 'learning_rate': 1.1149835625090264e-05, 'epoch': 6.3}
{'loss': 0.1154, 'grad_norm': 0.24747388064861298, 'learning_rate': 1.0441814490719884e-05, 'epoch': 6.49}
{'loss': 0.1138, 'grad_norm': 0.2833395302295685, 'learning_rate': 9.740193724204472e-06, 'epoch': 6.68}
{'loss': 0.1148, 'grad_norm': 0.27392578125, 'learning_rate': 9.047312613463382e-06, 'epoch': 6.86}
{'eval_loss': 0.6758325695991516, 'eval_runtime': 19.6006, 'eval_samples_per_second': 2.398, 'eval_steps_per_second': 1.224, 'epoch': 7.0}
{'loss': 0.1537, 'grad_norm': 0.26535728573799133, 'learning_rate': 8.365481307353756e-06, 'epoch': 7.04}
{'loss': 0.1203, 'grad_norm': 0.3018375039100647, 'learning_rate': 7.696973113356697e-06, 'epoch': 7.23}
{'loss': 0.1159, 'grad_norm': 0.3123643696308136, 'learning_rate': 7.044016918097065e-06, 'epoch': 7.41}
{'loss': 0.1101, 'grad_norm': 0.29435983300209045, 'learning_rate': 6.408789755967714e-06, 'epoch': 7.6}
{'loss': 0.1103, 'grad_norm': 0.28796887397766113, 'learning_rate': 5.793409550635285e-06, 'epoch': 7.79}
{'loss': 0.1057, 'grad_norm': 0.29169514775276184, 'learning_rate': 5.199928053628316e-06, 'epoch': 7.98}
{'eval_loss': 0.69355309009552, 'eval_runtime': 17.068, 'eval_samples_per_second': 2.754, 'eval_steps_per_second': 1.406, 'epoch': 8.0}
{'train_runtime': 3243.5371, 'train_samples_per_second': 1.445, 'train_steps_per_second': 0.183, 'train_loss': 0.21423707184968172, 'epoch': 8.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 54.06 min
   Peak memory: 8.605 GB
   Training memory: 5.011 GB
================================================================================


================================================================================
‚úÖ TRIAL #0 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6637
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_njyjxthg
[I 2025-11-02 19:08:06,858] Trial 0 finished with value: 0.6637346744537354 and parameters: {'num_epochs': 11, 'learning_rate': 2.472294346960012e-05, 'weight_decay': 0.030615359409776968, 'batch_size': 2}. Best is trial 0 with value: 0.6637346744537354.

================================================================================
üî¨ OPTUNA TRIAL #1 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #1:
   ‚Ä¢ num_epochs:    6
   ‚Ä¢ learning_rate: 1.32e-04
   ‚Ä¢ weight_decay:  0.0316
   ‚Ä¢ batch_size:    2

‚è≥ Loading model for Trial #1...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_4fpw9n3m
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #1...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 8.605 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 2, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.7493, 'grad_norm': 0.5571714639663696, 'learning_rate': 2.3778386634444758e-05, 'epoch': 0.19}
{'loss': 0.5834, 'grad_norm': 0.3305518329143524, 'learning_rate': 5.019881622827227e-05, 'epoch': 0.38}
{'loss': 0.3844, 'grad_norm': 0.41025131940841675, 'learning_rate': 7.661924582209978e-05, 'epoch': 0.56}
{'loss': 0.2259, 'grad_norm': 0.22041773796081543, 'learning_rate': 0.0001030396754159273, 'epoch': 0.75}
{'loss': 0.1687, 'grad_norm': 0.15709762275218964, 'learning_rate': 0.0001294601050097548, 'epoch': 0.94}
{'eval_loss': 0.7020929455757141, 'eval_runtime': 19.7126, 'eval_samples_per_second': 2.384, 'eval_steps_per_second': 1.217, 'epoch': 1.0}
{'loss': 0.2039, 'grad_norm': 0.1467761993408203, 'learning_rate': 0.00013175079137021803, 'epoch': 1.11}
{'loss': 0.1554, 'grad_norm': 0.14480942487716675, 'learning_rate': 0.00013054102367659952, 'epoch': 1.3}
{'loss': 0.1568, 'grad_norm': 0.14437562227249146, 'learning_rate': 0.00012848438972257943, 'epoch': 1.49}
{'loss': 0.1603, 'grad_norm': 0.14965319633483887, 'learning_rate': 0.00012560789672267682, 'epoch': 1.68}
{'loss': 0.1336, 'grad_norm': 0.1516212671995163, 'learning_rate': 0.00012194931808005816, 'epoch': 1.86}
{'eval_loss': 0.6570558547973633, 'eval_runtime': 19.8729, 'eval_samples_per_second': 2.365, 'eval_steps_per_second': 1.208, 'epoch': 2.0}
{'loss': 0.172, 'grad_norm': 0.16782522201538086, 'learning_rate': 0.00011755669735543723, 'epoch': 2.04}
{'loss': 0.1147, 'grad_norm': 0.20925191044807434, 'learning_rate': 0.00011248771737077596, 'epoch': 2.23}
{'loss': 0.1143, 'grad_norm': 0.21689647436141968, 'learning_rate': 0.00010680894273256211, 'epoch': 2.41}
{'loss': 0.1013, 'grad_norm': 0.22737860679626465, 'learning_rate': 0.00010059494572166254, 'epoch': 2.6}
{'loss': 0.1125, 'grad_norm': 0.25449681282043457, 'learning_rate': 9.392732702835375e-05, 'epoch': 2.79}
{'loss': 0.0987, 'grad_norm': 0.2504062354564667, 'learning_rate': 8.689364419199738e-05, 'epoch': 2.98}
{'eval_loss': 0.7104684710502625, 'eval_runtime': 18.6585, 'eval_samples_per_second': 2.519, 'eval_steps_per_second': 1.286, 'epoch': 3.0}
{'loss': 0.1185, 'grad_norm': 0.25445133447647095, 'learning_rate': 7.958626181682891e-05, 'epoch': 3.15}
{'loss': 0.0732, 'grad_norm': 0.2888566851615906, 'learning_rate': 7.210113866254562e-05, 'epoch': 3.34}
{'loss': 0.0755, 'grad_norm': 0.25771522521972656, 'learning_rate': 6.453656753732275e-05, 'epoch': 3.53}
{'loss': 0.0624, 'grad_norm': 0.2579280138015747, 'learning_rate': 5.699188454067591e-05, 'epoch': 3.71}
{'loss': 0.0623, 'grad_norm': 0.3159084618091583, 'learning_rate': 4.956616460607597e-05, 'epoch': 3.9}
{'eval_loss': 0.7771133184432983, 'eval_runtime': 19.8993, 'eval_samples_per_second': 2.362, 'eval_steps_per_second': 1.206, 'epoch': 4.0}
{'loss': 0.0704, 'grad_norm': 0.2718701660633087, 'learning_rate': 4.235692047313339e-05, 'epoch': 4.08}
{'loss': 0.0376, 'grad_norm': 0.21677663922309875, 'learning_rate': 3.5458822174129754e-05, 'epoch': 4.26}
{'loss': 0.0404, 'grad_norm': 0.301512748003006, 'learning_rate': 2.8962453850288024e-05, 'epoch': 4.45}
{'loss': 0.0351, 'grad_norm': 0.2511029839515686, 'learning_rate': 2.2953124222965124e-05, 'epoch': 4.64}
{'loss': 0.0342, 'grad_norm': 0.2805975079536438, 'learning_rate': 1.7509746340369523e-05, 'epoch': 4.83}
{'loss': 0.0412, 'grad_norm': 2.3617801666259766, 'learning_rate': 1.2703801310695688e-05, 'epoch': 5.0}
{'eval_loss': 0.849442183971405, 'eval_runtime': 19.7418, 'eval_samples_per_second': 2.381, 'eval_steps_per_second': 1.216, 'epoch': 5.0}
{'train_runtime': 2029.773, 'train_samples_per_second': 1.259, 'train_steps_per_second': 0.16, 'train_loss': 0.15875363559634598, 'epoch': 5.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 33.83 min
   Peak memory: 9.211 GB
   Training memory: 0.606 GB
================================================================================


================================================================================
‚úÖ TRIAL #1 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6571
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_4fpw9n3m
[I 2025-11-02 19:43:43,360] Trial 1 finished with value: 0.6570558547973633 and parameters: {'num_epochs': 6, 'learning_rate': 0.00013210214796913756, 'weight_decay': 0.03156157456524973, 'batch_size': 2}. Best is trial 1 with value: 0.6570558547973633.

================================================================================
üî¨ OPTUNA TRIAL #2 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #2:
   ‚Ä¢ num_epochs:    6
   ‚Ä¢ learning_rate: 1.14e-04
   ‚Ä¢ weight_decay:  0.0682
   ‚Ä¢ batch_size:    1

‚è≥ Loading model for Trial #2...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_33tej3ay
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #2...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 9.211 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 1, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.7716, 'grad_norm': 0.6281408071517944, 'learning_rate': 2.05073121571307e-05, 'epoch': 0.09}
{'loss': 0.5882, 'grad_norm': 0.36483946442604065, 'learning_rate': 4.3293214553942586e-05, 'epoch': 0.19}
{'loss': 0.4315, 'grad_norm': 0.5028033256530762, 'learning_rate': 6.607911695075446e-05, 'epoch': 0.28}
{'loss': 0.2165, 'grad_norm': 0.23569241166114807, 'learning_rate': 8.886501934756637e-05, 'epoch': 0.38}
{'loss': 0.1896, 'grad_norm': 0.21724273264408112, 'learning_rate': 0.00011165092174437824, 'epoch': 0.47}
{'loss': 0.1834, 'grad_norm': 0.19279639422893524, 'learning_rate': 0.00011386455362584667, 'epoch': 0.56}
{'loss': 0.1755, 'grad_norm': 0.19359619915485382, 'learning_rate': 0.00011364019640693942, 'epoch': 0.66}
{'loss': 0.1795, 'grad_norm': 0.18914535641670227, 'learning_rate': 0.00011325626989783684, 'epoch': 0.75}
{'loss': 0.1432, 'grad_norm': 0.23716634511947632, 'learning_rate': 0.00011271385504083238, 'epoch': 0.85}
{'loss': 0.1494, 'grad_norm': 0.20408672094345093, 'learning_rate': 0.00011201447900101007, 'epoch': 0.94}
{'eval_loss': 0.6447261571884155, 'eval_runtime': 26.4778, 'eval_samples_per_second': 1.775, 'eval_steps_per_second': 1.775, 'epoch': 1.0}
{'loss': 0.1565, 'grad_norm': 0.1733415126800537, 'learning_rate': 0.00011116011086652229, 'epoch': 1.03}
{'loss': 0.113, 'grad_norm': 0.23984482884407043, 'learning_rate': 0.00011015315610463653, 'epoch': 1.12}
{'loss': 0.124, 'grad_norm': 0.24392448365688324, 'learning_rate': 0.00010899644978915964, 'epoch': 1.22}
{'loss': 0.1318, 'grad_norm': 0.2741709053516388, 'learning_rate': 0.00010769324861830822, 'epoch': 1.31}
{'loss': 0.1306, 'grad_norm': 0.22287751734256744, 'learning_rate': 0.0001062472217454985, 'epoch': 1.4}
{'loss': 0.1221, 'grad_norm': 0.2172899842262268, 'learning_rate': 0.00010466244044887157, 'epoch': 1.5}
{'loss': 0.132, 'grad_norm': 0.30937907099723816, 'learning_rate': 0.0001029433666686394, 'epoch': 1.59}
{'loss': 0.1328, 'grad_norm': 0.2777368128299713, 'learning_rate': 0.0001010948404445246, 'epoch': 1.69}
{'loss': 0.1134, 'grad_norm': 0.2854763865470886, 'learning_rate': 9.912206628866381e-05, 'epoch': 1.78}
{'loss': 0.0998, 'grad_norm': 0.31512314081192017, 'learning_rate': 9.703059853234166e-05, 'epoch': 1.87}
{'loss': 0.1089, 'grad_norm': 0.3181873857975006, 'learning_rate': 9.482632568781143e-05, 'epoch': 1.97}
{'eval_loss': 0.6572635173797607, 'eval_runtime': 27.1413, 'eval_samples_per_second': 1.732, 'eval_steps_per_second': 1.732, 'epoch': 2.0}
{'loss': 0.1046, 'grad_norm': 0.2676759362220764, 'learning_rate': 9.251545386923162e-05, 'epoch': 2.06}
{'loss': 0.0734, 'grad_norm': 0.33088570833206177, 'learning_rate': 9.01044893193967e-05, 'epoch': 2.15}
{'loss': 0.0762, 'grad_norm': 0.3121129274368286, 'learning_rate': 8.760022009145789e-05, 'epoch': 2.24}
{'loss': 0.0731, 'grad_norm': 0.3379207253456116, 'learning_rate': 8.500969693720878e-05, 'epoch': 2.34}
{'loss': 0.0706, 'grad_norm': 0.32296061515808105, 'learning_rate': 8.234021345574506e-05, 'epoch': 2.43}
{'loss': 0.0672, 'grad_norm': 0.3562764525413513, 'learning_rate': 7.959928555838931e-05, 'epoch': 2.53}
{'loss': 0.0575, 'grad_norm': 0.340315580368042, 'learning_rate': 7.67946303076973e-05, 'epoch': 2.62}
{'loss': 0.071, 'grad_norm': 0.3050309121608734, 'learning_rate': 7.393414419012452e-05, 'epoch': 2.71}
{'loss': 0.0758, 'grad_norm': 0.40000656247138977, 'learning_rate': 7.102588088352601e-05, 'epoch': 2.81}
{'loss': 0.0598, 'grad_norm': 0.3383096158504486, 'learning_rate': 6.807802858208498e-05, 'epoch': 2.9}
{'loss': 0.0528, 'grad_norm': 0.3563501536846161, 'learning_rate': 6.509888694251157e-05, 'epoch': 3.0}
{'eval_loss': 0.7799245119094849, 'eval_runtime': 26.8739, 'eval_samples_per_second': 1.749, 'eval_steps_per_second': 1.749, 'epoch': 3.0}
{'loss': 0.0412, 'grad_norm': 0.33195170760154724, 'learning_rate': 6.209684371641989e-05, 'epoch': 3.08}
{'loss': 0.0315, 'grad_norm': 0.28566500544548035, 'learning_rate': 5.908035113467421e-05, 'epoch': 3.18}
{'loss': 0.0293, 'grad_norm': 0.30652809143066406, 'learning_rate': 5.60579021101946e-05, 'epoch': 3.27}
{'loss': 0.0333, 'grad_norm': 0.33023348450660706, 'learning_rate': 5.303800632622226e-05, 'epoch': 3.37}
{'loss': 0.0299, 'grad_norm': 0.3647613227367401, 'learning_rate': 5.002916627736836e-05, 'epoch': 3.46}
{'loss': 0.0286, 'grad_norm': 0.3455866873264313, 'learning_rate': 4.7039853330902225e-05, 'epoch': 3.55}
{'loss': 0.0244, 'grad_norm': 0.3015243411064148, 'learning_rate': 4.407848387567852e-05, 'epoch': 3.65}
{'loss': 0.0257, 'grad_norm': 0.40215370059013367, 'learning_rate': 4.115339562585555e-05, 'epoch': 3.74}
{'loss': 0.0254, 'grad_norm': 0.2860596477985382, 'learning_rate': 3.8272824146121724e-05, 'epoch': 3.84}
{'loss': 0.0233, 'grad_norm': 0.40987691283226013, 'learning_rate': 3.544487966452319e-05, 'epoch': 3.93}
{'eval_loss': 0.8494458198547363, 'eval_runtime': 26.8562, 'eval_samples_per_second': 1.75, 'eval_steps_per_second': 1.75, 'epoch': 4.0}
{'train_runtime': 2438.2796, 'train_samples_per_second': 1.048, 'train_steps_per_second': 0.263, 'train_loss': 0.12824916843081188, 'epoch': 4.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 40.64 min
   Peak memory: 9.211 GB
   Training memory: 0.0 GB
================================================================================


================================================================================
‚úÖ TRIAL #2 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6447
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_33tej3ay
[I 2025-11-02 20:27:18,389] Trial 2 finished with value: 0.6447261571884155 and parameters: {'num_epochs': 6, 'learning_rate': 0.00011392951198405944, 'weight_decay': 0.06821601568873868, 'batch_size': 1}. Best is trial 2 with value: 0.6447261571884155.

================================================================================
üî¨ OPTUNA TRIAL #3 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #3:
   ‚Ä¢ num_epochs:    13
   ‚Ä¢ learning_rate: 7.97e-05
   ‚Ä¢ weight_decay:  0.0355
   ‚Ä¢ batch_size:    1

‚è≥ Loading model for Trial #3...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_odt7dq2m
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #3...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 9.211 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 1, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.7835, 'grad_norm': 0.7785889506340027, 'learning_rate': 1.4339036480115997e-05, 'epoch': 0.09}
{'loss': 0.6201, 'grad_norm': 0.400742769241333, 'learning_rate': 3.027129923580044e-05, 'epoch': 0.19}
{'loss': 0.5027, 'grad_norm': 0.44147518277168274, 'learning_rate': 4.620356199148488e-05, 'epoch': 0.28}
{'loss': 0.2944, 'grad_norm': 0.2765260636806488, 'learning_rate': 6.213582474716932e-05, 'epoch': 0.38}
{'loss': 0.2048, 'grad_norm': 0.2211741805076599, 'learning_rate': 7.806808750285377e-05, 'epoch': 0.47}
{'loss': 0.1899, 'grad_norm': 0.1821649670600891, 'learning_rate': 7.965246061272394e-05, 'epoch': 0.56}
{'loss': 0.1814, 'grad_norm': 0.19234241545200348, 'learning_rate': 7.962186212964437e-05, 'epoch': 0.66}
{'loss': 0.1857, 'grad_norm': 0.2714829742908478, 'learning_rate': 7.956942581960783e-05, 'epoch': 0.75}
{'loss': 0.1494, 'grad_norm': 0.22885802388191223, 'learning_rate': 7.949518046020621e-05, 'epoch': 0.85}
{'loss': 0.1547, 'grad_norm': 0.2092157006263733, 'learning_rate': 7.939916679806432e-05, 'epoch': 0.94}
{'eval_loss': 0.6540547013282776, 'eval_runtime': 28.2238, 'eval_samples_per_second': 1.665, 'eval_steps_per_second': 1.665, 'epoch': 1.0}
{'loss': 0.165, 'grad_norm': 0.1817016452550888, 'learning_rate': 7.928143752647775e-05, 'epoch': 1.03}
{'loss': 0.1212, 'grad_norm': 0.22077983617782593, 'learning_rate': 7.914205725649422e-05, 'epoch': 1.12}
{'loss': 0.1346, 'grad_norm': 0.23559951782226562, 'learning_rate': 7.898110248145436e-05, 'epoch': 1.22}
{'loss': 0.1432, 'grad_norm': 0.27180254459381104, 'learning_rate': 7.879866153501141e-05, 'epoch': 1.31}
{'loss': 0.141, 'grad_norm': 0.2201731950044632, 'learning_rate': 7.859483454265276e-05, 'epoch': 1.4}
{'loss': 0.1314, 'grad_norm': 0.22666621208190918, 'learning_rate': 7.836973336675004e-05, 'epoch': 1.5}
{'loss': 0.1426, 'grad_norm': 0.3109807074069977, 'learning_rate': 7.812348154516789e-05, 'epoch': 1.59}
{'loss': 0.1443, 'grad_norm': 0.2824645936489105, 'learning_rate': 7.78562142234651e-05, 'epoch': 1.69}
{'loss': 0.1233, 'grad_norm': 0.27713578939437866, 'learning_rate': 7.756807808072537e-05, 'epoch': 1.78}
{'loss': 0.1114, 'grad_norm': 0.31510356068611145, 'learning_rate': 7.725923124905819e-05, 'epoch': 1.87}
{'loss': 0.1187, 'grad_norm': 0.3416127562522888, 'learning_rate': 7.692984322681442e-05, 'epoch': 1.97}
{'eval_loss': 0.647055447101593, 'eval_runtime': 27.2674, 'eval_samples_per_second': 1.724, 'eval_steps_per_second': 1.724, 'epoch': 2.0}
{'loss': 0.1195, 'grad_norm': 0.2950219213962555, 'learning_rate': 7.658009478556375e-05, 'epoch': 2.06}
{'loss': 0.089, 'grad_norm': 0.34390172362327576, 'learning_rate': 7.62101778708854e-05, 'epoch': 2.15}
{'loss': 0.0924, 'grad_norm': 0.3383060395717621, 'learning_rate': 7.582029549702647e-05, 'epoch': 2.24}
{'loss': 0.0893, 'grad_norm': 0.35791367292404175, 'learning_rate': 7.541066163548544e-05, 'epoch': 2.34}
{'loss': 0.0863, 'grad_norm': 0.3524503707885742, 'learning_rate': 7.49815010975826e-05, 'epoch': 2.43}
{'loss': 0.0825, 'grad_norm': 0.39477288722991943, 'learning_rate': 7.453304941108106e-05, 'epoch': 2.53}
{'loss': 0.0723, 'grad_norm': 0.38909095525741577, 'learning_rate': 7.406555269092684e-05, 'epoch': 2.62}
{'loss': 0.0867, 'grad_norm': 0.32371601462364197, 'learning_rate': 7.357926750417831e-05, 'epoch': 2.71}
{'loss': 0.0955, 'grad_norm': 0.4763658940792084, 'learning_rate': 7.307446072919954e-05, 'epoch': 2.81}
{'loss': 0.076, 'grad_norm': 0.376950740814209, 'learning_rate': 7.255140940919476e-05, 'epoch': 2.9}
{'loss': 0.07, 'grad_norm': 0.39620348811149597, 'learning_rate': 7.201040060016404e-05, 'epoch': 3.0}
{'eval_loss': 0.7509958744049072, 'eval_runtime': 26.8838, 'eval_samples_per_second': 1.748, 'eval_steps_per_second': 1.748, 'epoch': 3.0}
{'loss': 0.0578, 'grad_norm': 0.33600425720214844, 'learning_rate': 7.145173121336413e-05, 'epoch': 3.08}
{'loss': 0.0449, 'grad_norm': 0.37134283781051636, 'learning_rate': 7.087570785236032e-05, 'epoch': 3.18}
{'loss': 0.0434, 'grad_norm': 0.39936885237693787, 'learning_rate': 7.028264664475933e-05, 'epoch': 3.27}
{'loss': 0.0513, 'grad_norm': 0.382000595331192, 'learning_rate': 6.967287306871515e-05, 'epoch': 3.37}
{'loss': 0.0449, 'grad_norm': 0.4350852370262146, 'learning_rate': 6.904672177430322e-05, 'epoch': 3.46}
{'loss': 0.0437, 'grad_norm': 0.46045443415641785, 'learning_rate': 6.84045363998611e-05, 'epoch': 3.55}
{'loss': 0.0382, 'grad_norm': 0.3948688805103302, 'learning_rate': 6.774666938339599e-05, 'epoch': 3.65}
{'loss': 0.0421, 'grad_norm': 0.4645027220249176, 'learning_rate': 6.707348176916329e-05, 'epoch': 3.74}
{'loss': 0.0399, 'grad_norm': 0.39945849776268005, 'learning_rate': 6.638534300952163e-05, 'epoch': 3.84}
{'loss': 0.0375, 'grad_norm': 0.547105073928833, 'learning_rate': 6.568263076217365e-05, 'epoch': 3.93}
{'eval_loss': 0.8177995681762695, 'eval_runtime': 27.2832, 'eval_samples_per_second': 1.723, 'eval_steps_per_second': 1.723, 'epoch': 4.0}
{'loss': 0.037, 'grad_norm': 0.19212256371974945, 'learning_rate': 6.496573068290344e-05, 'epoch': 4.02}
{'loss': 0.0189, 'grad_norm': 0.28280410170555115, 'learning_rate': 6.423503621392475e-05, 'epoch': 4.11}
{'loss': 0.0175, 'grad_norm': 0.3662487864494324, 'learning_rate': 6.349094836795569e-05, 'epoch': 4.21}
{'loss': 0.0174, 'grad_norm': 0.3073638677597046, 'learning_rate': 6.273387550813892e-05, 'epoch': 4.3}
{'loss': 0.0176, 'grad_norm': 0.3474836051464081, 'learning_rate': 6.196423312392764e-05, 'epoch': 4.39}
{'loss': 0.0176, 'grad_norm': 0.2890109717845917, 'learning_rate': 6.118244360306059e-05, 'epoch': 4.49}
{'loss': 0.0151, 'grad_norm': 0.1912553310394287, 'learning_rate': 6.0388935999751405e-05, 'epoch': 4.58}
{'loss': 0.0139, 'grad_norm': 0.274200975894928, 'learning_rate': 5.958414579921915e-05, 'epoch': 4.68}
{'loss': 0.0155, 'grad_norm': 0.47171637415885925, 'learning_rate': 5.876851467868945e-05, 'epoch': 4.77}
{'loss': 0.0155, 'grad_norm': 0.3621402978897095, 'learning_rate': 5.794249026499752e-05, 'epoch': 4.86}
{'loss': 0.0142, 'grad_norm': 0.3629331588745117, 'learning_rate': 5.710652588892588e-05, 'epoch': 4.96}
{'eval_loss': 0.9020577073097229, 'eval_runtime': 26.9588, 'eval_samples_per_second': 1.743, 'eval_steps_per_second': 1.743, 'epoch': 5.0}
{'train_runtime': 3035.8536, 'train_samples_per_second': 1.824, 'train_steps_per_second': 0.458, 'train_loss': 0.11877816908548926, 'epoch': 5.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 50.6 min
   Peak memory: 9.211 GB
   Training memory: 0.0 GB
================================================================================


================================================================================
‚úÖ TRIAL #3 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6471
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_odt7dq2m
[I 2025-11-02 21:21:03,185] Trial 3 finished with value: 0.647055447101593 and parameters: {'num_epochs': 13, 'learning_rate': 7.966131377842221e-05, 'weight_decay': 0.035549407833380745, 'batch_size': 1}. Best is trial 2 with value: 0.6447261571884155.

================================================================================
üî¨ OPTUNA TRIAL #4 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #4:
   ‚Ä¢ num_epochs:    15
   ‚Ä¢ learning_rate: 2.19e-05
   ‚Ä¢ weight_decay:  0.0243
   ‚Ä¢ batch_size:    1

‚è≥ Loading model for Trial #4...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory__b_mf9p9
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #4...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 9.211 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 1, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.8081, 'grad_norm': 1.4025628566741943, 'learning_rate': 3.946569343861394e-06, 'epoch': 0.09}
{'loss': 0.7099, 'grad_norm': 0.6268600225448608, 'learning_rate': 8.331646392596277e-06, 'epoch': 0.19}
{'loss': 0.6573, 'grad_norm': 0.461885005235672, 'learning_rate': 1.2716723441331158e-05, 'epoch': 0.28}
{'loss': 0.5719, 'grad_norm': 1.1366180181503296, 'learning_rate': 1.7101800490066042e-05, 'epoch': 0.38}
{'loss': 0.4689, 'grad_norm': 0.41170603036880493, 'learning_rate': 2.1486877538800924e-05, 'epoch': 0.47}
{'loss': 0.3672, 'grad_norm': 0.41528624296188354, 'learning_rate': 2.1923573072350682e-05, 'epoch': 0.56}
{'loss': 0.2625, 'grad_norm': 0.25911879539489746, 'learning_rate': 2.1917309545588022e-05, 'epoch': 0.66}
{'loss': 0.2318, 'grad_norm': 0.2336418181657791, 'learning_rate': 2.190657484677643e-05, 'epoch': 0.75}
{'loss': 0.1817, 'grad_norm': 0.24139124155044556, 'learning_rate': 2.1891373357327467e-05, 'epoch': 0.85}
{'loss': 0.178, 'grad_norm': 0.2382129728794098, 'learning_rate': 2.187171128179171e-05, 'epoch': 0.94}
{'eval_loss': 0.7164856195449829, 'eval_runtime': 28.5755, 'eval_samples_per_second': 1.645, 'eval_steps_per_second': 1.645, 'epoch': 1.0}
{'loss': 0.1949, 'grad_norm': 0.18894590437412262, 'learning_rate': 2.1847596645326328e-05, 'epoch': 1.03}
{'loss': 0.1469, 'grad_norm': 0.19757071137428284, 'learning_rate': 2.1819039290419594e-05, 'epoch': 1.12}
{'loss': 0.1641, 'grad_norm': 0.19750630855560303, 'learning_rate': 2.1786050872873606e-05, 'epoch': 1.22}
{'loss': 0.1782, 'grad_norm': 0.21373143792152405, 'learning_rate': 2.174864485704696e-05, 'epoch': 1.31}
{'loss': 0.1731, 'grad_norm': 0.16855061054229736, 'learning_rate': 2.1706836510359193e-05, 'epoch': 1.4}
{'loss': 0.1634, 'grad_norm': 0.18938018381595612, 'learning_rate': 2.166064289705933e-05, 'epoch': 1.5}
{'loss': 0.1787, 'grad_norm': 0.2524729073047638, 'learning_rate': 2.161008287126102e-05, 'epoch': 1.59}
{'loss': 0.1833, 'grad_norm': 0.21766971051692963, 'learning_rate': 2.15551770692472e-05, 'epoch': 1.69}
{'loss': 0.1576, 'grad_norm': 0.20783865451812744, 'learning_rate': 2.149594790104726e-05, 'epoch': 1.78}
{'loss': 0.1472, 'grad_norm': 0.21654891967773438, 'learning_rate': 2.1432419541290327e-05, 'epoch': 1.87}
{'loss': 0.1534, 'grad_norm': 0.24230486154556274, 'learning_rate': 2.1364617919338277e-05, 'epoch': 1.97}
{'eval_loss': 0.6601902842521667, 'eval_runtime': 27.1078, 'eval_samples_per_second': 1.734, 'eval_steps_per_second': 1.734, 'epoch': 2.0}
{'loss': 0.1756, 'grad_norm': 0.254677414894104, 'learning_rate': 2.129257070870257e-05, 'epoch': 2.06}
{'loss': 0.1439, 'grad_norm': 0.2504604160785675, 'learning_rate': 2.1216307315749185e-05, 'epoch': 2.15}
{'loss': 0.1548, 'grad_norm': 0.2428499460220337, 'learning_rate': 2.1135858867696283e-05, 'epoch': 2.24}
{'loss': 0.144, 'grad_norm': 0.2562887668609619, 'learning_rate': 2.1051258199909525e-05, 'epoch': 2.34}
{'loss': 0.1493, 'grad_norm': 0.2566235065460205, 'learning_rate': 2.0962539842500164e-05, 'epoch': 2.43}
{'loss': 0.1374, 'grad_norm': 0.2539384663105011, 'learning_rate': 2.0869740006231446e-05, 'epoch': 2.53}
{'loss': 0.1285, 'grad_norm': 0.27573680877685547, 'learning_rate': 2.0772896567739037e-05, 'epoch': 2.62}
{'loss': 0.142, 'grad_norm': 0.2468559890985489, 'learning_rate': 2.0672049054071516e-05, 'epoch': 2.71}
{'loss': 0.1635, 'grad_norm': 0.3153478801250458, 'learning_rate': 2.0567238626557246e-05, 'epoch': 2.81}
{'loss': 0.1331, 'grad_norm': 0.2676565647125244, 'learning_rate': 2.0458508064004214e-05, 'epoch': 2.9}
{'loss': 0.1324, 'grad_norm': 0.3128940761089325, 'learning_rate': 2.0345901745239686e-05, 'epoch': 3.0}
{'eval_loss': 0.6417544484138489, 'eval_runtime': 26.9636, 'eval_samples_per_second': 1.743, 'eval_steps_per_second': 1.743, 'epoch': 3.0}
{'loss': 0.1407, 'grad_norm': 0.28975287079811096, 'learning_rate': 2.0229465630996778e-05, 'epoch': 3.08}
{'loss': 0.1238, 'grad_norm': 0.30416038632392883, 'learning_rate': 2.010924724515545e-05, 'epoch': 3.18}
{'loss': 0.1163, 'grad_norm': 0.3358760476112366, 'learning_rate': 1.9985295655345373e-05, 'epoch': 3.27}
{'loss': 0.1375, 'grad_norm': 0.3488914668560028, 'learning_rate': 1.985766145291882e-05, 'epoch': 3.37}
{'loss': 0.1309, 'grad_norm': 0.36981263756752014, 'learning_rate': 1.9726396732301583e-05, 'epoch': 3.46}
{'loss': 0.1285, 'grad_norm': 0.38109156489372253, 'learning_rate': 1.9591555069730413e-05, 'epoch': 3.55}
{'loss': 0.1127, 'grad_norm': 0.3594878613948822, 'learning_rate': 1.945319150138566e-05, 'epoch': 3.65}
{'loss': 0.1227, 'grad_norm': 0.4328509569168091, 'learning_rate': 1.9311362500928043e-05, 'epoch': 3.74}
{'loss': 0.1175, 'grad_norm': 0.4220094680786133, 'learning_rate': 1.9166125956448666e-05, 'epoch': 3.84}
{'loss': 0.1107, 'grad_norm': 0.4855831563472748, 'learning_rate': 1.9017541146841782e-05, 'epoch': 3.93}
{'eval_loss': 0.656970739364624, 'eval_runtime': 27.9141, 'eval_samples_per_second': 1.684, 'eval_steps_per_second': 1.684, 'epoch': 4.0}
{'loss': 0.1158, 'grad_norm': 0.3235594630241394, 'learning_rate': 1.8865668717609847e-05, 'epoch': 4.02}
{'loss': 0.1036, 'grad_norm': 0.4039174020290375, 'learning_rate': 1.871057065611083e-05, 'epoch': 4.11}
{'loss': 0.0994, 'grad_norm': 0.5038416981697083, 'learning_rate': 1.8552310266257793e-05, 'epoch': 4.21}
{'loss': 0.1007, 'grad_norm': 0.4633300006389618, 'learning_rate': 1.839095214268115e-05, 'epoch': 4.3}
{'loss': 0.1032, 'grad_norm': 0.5859509110450745, 'learning_rate': 1.8226562144364123e-05, 'epoch': 4.39}
{'loss': 0.0982, 'grad_norm': 0.47930118441581726, 'learning_rate': 1.805920736776207e-05, 'epoch': 4.49}
{'loss': 0.085, 'grad_norm': 0.4085589647293091, 'learning_rate': 1.7888956119416857e-05, 'epoch': 4.58}
{'loss': 0.089, 'grad_norm': 0.5334996581077576, 'learning_rate': 1.7715877888077214e-05, 'epoch': 4.68}
{'loss': 0.0963, 'grad_norm': 0.5657307505607605, 'learning_rate': 1.7540043316336634e-05, 'epoch': 4.77}
{'loss': 0.0873, 'grad_norm': 0.598823606967926, 'learning_rate': 1.7361524171800313e-05, 'epoch': 4.86}
{'loss': 0.0881, 'grad_norm': 0.7310191988945007, 'learning_rate': 1.7180393317792894e-05, 'epoch': 4.96}
{'eval_loss': 0.7105461359024048, 'eval_runtime': 27.9577, 'eval_samples_per_second': 1.681, 'eval_steps_per_second': 1.681, 'epoch': 5.0}
{'loss': 0.0897, 'grad_norm': 0.6266847848892212, 'learning_rate': 1.6996724683619002e-05, 'epoch': 5.05}
{'loss': 0.0758, 'grad_norm': 0.4856516420841217, 'learning_rate': 1.68105932343887e-05, 'epoch': 5.14}
{'loss': 0.0672, 'grad_norm': 0.6375163197517395, 'learning_rate': 1.662207494042017e-05, 'epoch': 5.23}
{'loss': 0.0637, 'grad_norm': 0.5984933376312256, 'learning_rate': 1.6431246746232102e-05, 'epoch': 5.33}
{'loss': 0.0676, 'grad_norm': 0.553132951259613, 'learning_rate': 1.6238186539138495e-05, 'epoch': 5.42}
{'loss': 0.0668, 'grad_norm': 0.7307390570640564, 'learning_rate': 1.6042973117458602e-05, 'epoch': 5.52}
{'loss': 0.0731, 'grad_norm': 0.7387450933456421, 'learning_rate': 1.5845686158355098e-05, 'epoch': 5.61}
{'loss': 0.058, 'grad_norm': 0.572128176689148, 'learning_rate': 1.564640618531349e-05, 'epoch': 5.7}
{'loss': 0.0596, 'grad_norm': 0.7352206110954285, 'learning_rate': 1.5445214535276146e-05, 'epoch': 5.8}
{'loss': 0.0655, 'grad_norm': 0.6339651346206665, 'learning_rate': 1.5242193325444282e-05, 'epoch': 5.89}
{'loss': 0.0622, 'grad_norm': 0.6451094150543213, 'learning_rate': 1.5037425419761474e-05, 'epoch': 5.99}
{'eval_loss': 0.7767049074172974, 'eval_runtime': 26.786, 'eval_samples_per_second': 1.755, 'eval_steps_per_second': 1.755, 'epoch': 6.0}
{'train_runtime': 3680.8912, 'train_samples_per_second': 1.736, 'train_steps_per_second': 0.436, 'train_loss': 0.17080339733685287, 'epoch': 6.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 61.35 min
   Peak memory: 9.211 GB
   Training memory: 0.0 GB
================================================================================


================================================================================
‚úÖ TRIAL #4 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6418
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory__b_mf9p9
[I 2025-11-02 22:25:22,595] Trial 4 finished with value: 0.6417544484138489 and parameters: {'num_epochs': 15, 'learning_rate': 2.1925385243674412e-05, 'weight_decay': 0.0242986452687914, 'batch_size': 1}. Best is trial 4 with value: 0.6417544484138489.

================================================================================
üî¨ OPTUNA TRIAL #5 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #5:
   ‚Ä¢ num_epochs:    7
   ‚Ä¢ learning_rate: 2.31e-04
   ‚Ä¢ weight_decay:  0.0163
   ‚Ä¢ batch_size:    1

‚è≥ Loading model for Trial #5...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_e4bzk01m
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #5...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 9.211 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 1, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.7441, 'grad_norm': 0.48622748255729675, 'learning_rate': 4.15254291752412e-05, 'epoch': 0.09}
{'loss': 0.5099, 'grad_norm': 0.352418452501297, 'learning_rate': 8.766479492550921e-05, 'epoch': 0.19}
{'loss': 0.2681, 'grad_norm': 0.26135122776031494, 'learning_rate': 0.00013380416067577722, 'epoch': 0.28}
{'loss': 0.1597, 'grad_norm': 0.20985326170921326, 'learning_rate': 0.00017994352642604523, 'epoch': 0.38}
{'loss': 0.1731, 'grad_norm': 0.19524511694908142, 'learning_rate': 0.00022608289217631322, 'epoch': 0.47}
{'loss': 0.1742, 'grad_norm': 0.20820319652557373, 'learning_rate': 0.00023060247637776118, 'epoch': 0.56}
{'loss': 0.1662, 'grad_norm': 0.19286465644836426, 'learning_rate': 0.00023027651818974257, 'epoch': 0.66}
{'loss': 0.1696, 'grad_norm': 0.18983303010463715, 'learning_rate': 0.00022971844750194393, 'epoch': 0.75}
{'loss': 0.1329, 'grad_norm': 0.2324983775615692, 'learning_rate': 0.00022892939141189923, 'epoch': 0.85}
{'loss': 0.1408, 'grad_norm': 0.20255713164806366, 'learning_rate': 0.00022791094352269986, 'epoch': 0.94}
{'eval_loss': 0.6425659656524658, 'eval_runtime': 27.0904, 'eval_samples_per_second': 1.735, 'eval_steps_per_second': 1.735, 'epoch': 1.0}
{'loss': 0.1398, 'grad_norm': 0.16995559632778168, 'learning_rate': 0.0002266651607245025, 'epoch': 1.03}
{'loss': 0.097, 'grad_norm': 0.24870292842388153, 'learning_rate': 0.00022519455904036745, 'epoch': 1.12}
{'loss': 0.1041, 'grad_norm': 0.2219887375831604, 'learning_rate': 0.0002235021085448174, 'epoch': 1.22}
{'loss': 0.1108, 'grad_norm': 0.23879139125347137, 'learning_rate': 0.0002215912273653795, 'epoch': 1.31}
{'loss': 0.1115, 'grad_norm': 0.17791102826595306, 'learning_rate': 0.00021946577477922451, 'epoch': 1.4}
{'loss': 0.1036, 'grad_norm': 0.18007820844650269, 'learning_rate': 0.00021713004341884675, 'epoch': 1.5}
{'loss': 0.1111, 'grad_norm': 0.25127360224723816, 'learning_rate': 0.00021458875060252503, 'epoch': 1.59}
{'loss': 0.109, 'grad_norm': 0.2410760372877121, 'learning_rate': 0.0002118470288070748, 'epoch': 1.69}
{'loss': 0.0937, 'grad_norm': 0.2042577564716339, 'learning_rate': 0.0002089104153021326, 'epoch': 1.78}
{'loss': 0.0773, 'grad_norm': 0.290558785200119, 'learning_rate': 0.00020578484096690831, 'epoch': 1.87}
{'loss': 0.0876, 'grad_norm': 0.2407999485731125, 'learning_rate': 0.00020247661831198984, 'epoch': 1.97}
{'eval_loss': 0.6959259510040283, 'eval_runtime': 27.2663, 'eval_samples_per_second': 1.724, 'eval_steps_per_second': 1.724, 'epoch': 2.0}
{'loss': 0.0751, 'grad_norm': 0.20166729390621185, 'learning_rate': 0.00019899242873039414, 'epoch': 2.06}
{'loss': 0.0465, 'grad_norm': 0.23801064491271973, 'learning_rate': 0.00019533930900361024, 'epoch': 2.15}
{'loss': 0.0454, 'grad_norm': 0.22355301678180695, 'learning_rate': 0.0001915246370898889, 'epoch': 2.24}
{'loss': 0.0449, 'grad_norm': 0.23387634754180908, 'learning_rate': 0.0001875561172234805, 'epoch': 2.34}
{'loss': 0.0414, 'grad_norm': 0.24998578429222107, 'learning_rate': 0.00018344176435491541, 'epoch': 2.43}
{'loss': 0.0404, 'grad_norm': 0.23351295292377472, 'learning_rate': 0.0001791898879637518, 'epoch': 2.53}
{'loss': 0.034, 'grad_norm': 0.3233320415019989, 'learning_rate': 0.00017525270848156135, 'epoch': 2.62}
{'loss': 0.0441, 'grad_norm': 0.23245619237422943, 'learning_rate': 0.00017121752830526432, 'epoch': 2.71}
{'loss': 0.0429, 'grad_norm': 0.21940244734287262, 'learning_rate': 0.00016662708991015853, 'epoch': 2.81}
{'loss': 0.0333, 'grad_norm': 0.18948912620544434, 'learning_rate': 0.00016193308745048783, 'epoch': 2.9}
{'loss': 0.029, 'grad_norm': 0.2055535614490509, 'learning_rate': 0.00015714500108479255, 'epoch': 3.0}
{'eval_loss': 0.847832441329956, 'eval_runtime': 27.2545, 'eval_samples_per_second': 1.724, 'eval_steps_per_second': 1.724, 'epoch': 3.0}
{'loss': 0.0192, 'grad_norm': 0.17570547759532928, 'learning_rate': 0.00015227250098649945, 'epoch': 3.08}
{'loss': 0.0137, 'grad_norm': 0.1294640153646469, 'learning_rate': 0.00014732542781372842, 'epoch': 3.18}
{'loss': 0.0121, 'grad_norm': 0.1538408398628235, 'learning_rate': 0.00014231377283478212, 'epoch': 3.27}
{'loss': 0.0128, 'grad_norm': 0.1410418599843979, 'learning_rate': 0.00013724765774945894, 'epoch': 3.37}
{'loss': 0.0119, 'grad_norm': 0.13348011672496796, 'learning_rate': 0.00013213731424694194, 'epoch': 3.46}
{'loss': 0.0109, 'grad_norm': 0.1307329684495926, 'learning_rate': 0.00012699306334155002, 'epoch': 3.55}
{'loss': 0.0099, 'grad_norm': 0.1037130057811737, 'learning_rate': 0.0001218252945280848, 'epoch': 3.65}
{'loss': 0.0102, 'grad_norm': 0.15970486402511597, 'learning_rate': 0.00011664444479887264, 'epoch': 3.74}
{'loss': 0.011, 'grad_norm': 0.11326831579208374, 'learning_rate': 0.00011146097756487847, 'epoch': 3.84}
{'loss': 0.0102, 'grad_norm': 0.18897613883018494, 'learning_rate': 0.0001062853615234642, 'epoch': 3.93}
{'eval_loss': 0.896361231803894, 'eval_runtime': 27.3808, 'eval_samples_per_second': 1.717, 'eval_steps_per_second': 1.717, 'epoch': 4.0}
{'train_runtime': 2433.4336, 'train_samples_per_second': 1.225, 'train_steps_per_second': 0.308, 'train_loss': 0.10258916103951285, 'epoch': 4.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 40.56 min
   Peak memory: 9.211 GB
   Training memory: 0.0 GB
================================================================================


================================================================================
‚úÖ TRIAL #5 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6426
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_e4bzk01m
[I 2025-11-02 23:08:56,585] Trial 5 finished with value: 0.6425659656524658 and parameters: {'num_epochs': 7, 'learning_rate': 0.00023069682875134003, 'weight_decay': 0.01633302370484486, 'batch_size': 1}. Best is trial 4 with value: 0.6417544484138489.

================================================================================
üî¨ OPTUNA TRIAL #6 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #6:
   ‚Ä¢ num_epochs:    4
   ‚Ä¢ learning_rate: 3.64e-05
   ‚Ä¢ weight_decay:  0.0365
   ‚Ä¢ batch_size:    2

‚è≥ Loading model for Trial #6...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_4dzq4qlj
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #6...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 9.211 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 2, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.7837, 'grad_norm': 1.2553200721740723, 'learning_rate': 6.5539792145328215e-06, 'epoch': 0.19}
{'loss': 0.7021, 'grad_norm': 0.5009912252426147, 'learning_rate': 1.3836178341791512e-05, 'epoch': 0.38}
{'loss': 0.5891, 'grad_norm': 0.41760140657424927, 'learning_rate': 2.11183774690502e-05, 'epoch': 0.56}
{'loss': 0.4964, 'grad_norm': 0.3836301267147064, 'learning_rate': 2.8400576596308896e-05, 'epoch': 0.75}
{'loss': 0.3432, 'grad_norm': 0.4254988729953766, 'learning_rate': 3.568277572356758e-05, 'epoch': 0.94}
{'eval_loss': 0.8790171146392822, 'eval_runtime': 19.3196, 'eval_samples_per_second': 2.433, 'eval_steps_per_second': 1.242, 'epoch': 1.0}
{'loss': 0.2875, 'grad_norm': 0.18646936118602753, 'learning_rate': 3.614755004194704e-05, 'epoch': 1.11}
{'loss': 0.1915, 'grad_norm': 0.16826964914798737, 'learning_rate': 3.5246658250112195e-05, 'epoch': 1.3}
{'loss': 0.1871, 'grad_norm': 0.13982193171977997, 'learning_rate': 3.373723069904891e-05, 'epoch': 1.49}
{'loss': 0.1921, 'grad_norm': 0.13718070089817047, 'learning_rate': 3.1673168685236006e-05, 'epoch': 1.68}
{'loss': 0.1636, 'grad_norm': 0.12744887173175812, 'learning_rate': 2.912817936903295e-05, 'epoch': 1.86}
{'eval_loss': 0.7042647004127502, 'eval_runtime': 18.5681, 'eval_samples_per_second': 2.531, 'eval_steps_per_second': 1.293, 'epoch': 2.0}
{'loss': 0.2197, 'grad_norm': 0.1799772083759308, 'learning_rate': 2.6193143709629525e-05, 'epoch': 2.04}
{'loss': 0.163, 'grad_norm': 0.17740067839622498, 'learning_rate': 2.297287112775081e-05, 'epoch': 2.23}
{'loss': 0.1619, 'grad_norm': 0.1530611366033554, 'learning_rate': 1.958235678633538e-05, 'epoch': 2.41}
{'loss': 0.1507, 'grad_norm': 0.16559050977230072, 'learning_rate': 1.6142675140797535e-05, 'epoch': 2.6}
{'loss': 0.1659, 'grad_norm': 0.16475403308868408, 'learning_rate': 1.277665639921075e-05, 'epoch': 2.79}
{'loss': 0.1541, 'grad_norm': 0.1720799058675766, 'learning_rate': 9.6045002849839e-06, 'epoch': 2.98}
{'eval_loss': 0.6794357895851135, 'eval_runtime': 18.7969, 'eval_samples_per_second': 2.5, 'eval_steps_per_second': 1.277, 'epoch': 3.0}
{'loss': 0.2172, 'grad_norm': 0.14925339818000793, 'learning_rate': 6.739483733515181e-06, 'epoch': 3.15}
{'loss': 0.1515, 'grad_norm': 0.15961933135986328, 'learning_rate': 4.28391579994852e-06, 'epoch': 3.34}
{'loss': 0.1668, 'grad_norm': 0.15425950288772583, 'learning_rate': 2.3254842273079592e-06, 'epoch': 3.53}
{'loss': 0.1465, 'grad_norm': 0.14156459271907806, 'learning_rate': 9.341241381875225e-07, 'epoch': 3.71}
{'loss': 0.1493, 'grad_norm': 0.16678930819034576, 'learning_rate': 1.595206682663957e-07, 'epoch': 3.9}
{'eval_loss': 0.6757690906524658, 'eval_runtime': 19.593, 'eval_samples_per_second': 2.399, 'eval_steps_per_second': 1.225, 'epoch': 4.0}
{'train_runtime': 1594.5979, 'train_samples_per_second': 1.069, 'train_steps_per_second': 0.135, 'train_loss': 0.27350236089141283, 'epoch': 4.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 26.58 min
   Peak memory: 12.57 GB
   Training memory: 3.359 GB
================================================================================


================================================================================
‚úÖ TRIAL #6 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6758
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_4dzq4qlj
[I 2025-11-02 23:38:28,098] Trial 6 finished with value: 0.6757690906524658 and parameters: {'num_epochs': 4, 'learning_rate': 3.6410995636293454e-05, 'weight_decay': 0.03649280392826826, 'batch_size': 2}. Best is trial 4 with value: 0.6417544484138489.

================================================================================
üî¨ OPTUNA TRIAL #7 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #7:
   ‚Ä¢ num_epochs:    13
   ‚Ä¢ learning_rate: 1.58e-04
   ‚Ä¢ weight_decay:  0.0571
   ‚Ä¢ batch_size:    1

‚è≥ Loading model for Trial #7...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_up1ofhma
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #7...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 12.57 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 1, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.7617, 'grad_norm': 0.706712007522583, 'learning_rate': 2.8379868654085315e-05, 'epoch': 0.09}
{'loss': 0.5578, 'grad_norm': 0.3682031035423279, 'learning_rate': 5.9913056047513446e-05, 'epoch': 0.19}
{'loss': 0.3551, 'grad_norm': 0.33157873153686523, 'learning_rate': 9.144624344094156e-05, 'epoch': 0.28}
{'loss': 0.181, 'grad_norm': 0.25556689500808716, 'learning_rate': 0.0001229794308343697, 'epoch': 0.38}
{'loss': 0.1812, 'grad_norm': 0.19256378710269928, 'learning_rate': 0.00015451261822779783, 'epoch': 0.47}
{'loss': 0.1796, 'grad_norm': 0.19250643253326416, 'learning_rate': 0.00015764841475216908, 'epoch': 0.56}
{'loss': 0.1719, 'grad_norm': 0.1923946589231491, 'learning_rate': 0.00015758785413277066, 'epoch': 0.66}
{'loss': 0.1753, 'grad_norm': 0.18597647547721863, 'learning_rate': 0.00015748407201368578, 'epoch': 0.75}
{'loss': 0.1389, 'grad_norm': 0.22098888456821442, 'learning_rate': 0.00015733712535161991, 'epoch': 0.85}
{'loss': 0.1457, 'grad_norm': 0.2391338348388672, 'learning_rate': 0.0001571470947924284, 'epoch': 0.94}
{'eval_loss': 0.6424023509025574, 'eval_runtime': 28.6441, 'eval_samples_per_second': 1.641, 'eval_steps_per_second': 1.641, 'epoch': 1.0}
{'loss': 0.1492, 'grad_norm': 0.16744017601013184, 'learning_rate': 0.00015691408462685684, 'epoch': 1.03}
{'loss': 0.1066, 'grad_norm': 0.24307695031166077, 'learning_rate': 0.00015663822273330572, 'epoch': 1.12}
{'loss': 0.1157, 'grad_norm': 0.2381921410560608, 'learning_rate': 0.00015631966050764896, 'epoch': 1.22}
{'loss': 0.1226, 'grad_norm': 0.262175589799881, 'learning_rate': 0.00015595857278014665, 'epoch': 1.31}
{'loss': 0.1223, 'grad_norm': 0.2108643800020218, 'learning_rate': 0.00015555515771949614, 'epoch': 1.4}
{'loss': 0.1144, 'grad_norm': 0.2018807828426361, 'learning_rate': 0.00015510963672407514, 'epoch': 1.5}
{'loss': 0.1232, 'grad_norm': 0.2855815887451172, 'learning_rate': 0.00015462225430043586, 'epoch': 1.59}
{'loss': 0.1221, 'grad_norm': 0.27189356088638306, 'learning_rate': 0.00015409327792911747, 'epoch': 1.69}
{'loss': 0.1044, 'grad_norm': 0.2396233230829239, 'learning_rate': 0.00015352299791784977, 'epoch': 1.78}
{'loss': 0.0895, 'grad_norm': 0.3180048167705536, 'learning_rate': 0.00015291172724222945, 'epoch': 1.87}
{'loss': 0.1001, 'grad_norm': 0.2923429608345032, 'learning_rate': 0.00015225980137395577, 'epoch': 1.97}
{'eval_loss': 0.6818482279777527, 'eval_runtime': 28.6893, 'eval_samples_per_second': 1.638, 'eval_steps_per_second': 1.638, 'epoch': 2.0}
{'loss': 0.0915, 'grad_norm': 0.2637132704257965, 'learning_rate': 0.00015156757809672028, 'epoch': 2.06}
{'loss': 0.0614, 'grad_norm': 0.2861536741256714, 'learning_rate': 0.00015083543730985127, 'epoch': 2.15}
{'loss': 0.0626, 'grad_norm': 0.2649397850036621, 'learning_rate': 0.00015006378081982118, 'epoch': 2.24}
{'loss': 0.0613, 'grad_norm': 0.2642052173614502, 'learning_rate': 0.00014925303211973096, 'epoch': 2.34}
{'loss': 0.0565, 'grad_norm': 0.26970601081848145, 'learning_rate': 0.00014840363615689284, 'epoch': 2.43}
{'loss': 0.0555, 'grad_norm': 0.2954225540161133, 'learning_rate': 0.0001475160590886383, 'epoch': 2.53}
{'loss': 0.0467, 'grad_norm': 0.3131024241447449, 'learning_rate': 0.00014659078802648634, 'epoch': 2.62}
{'loss': 0.0575, 'grad_norm': 0.2466863989830017, 'learning_rate': 0.0001456283307688116, 'epoch': 2.71}
{'loss': 0.0608, 'grad_norm': 0.29566672444343567, 'learning_rate': 0.00014462921552215913, 'epoch': 2.81}
{'loss': 0.0483, 'grad_norm': 0.2457638680934906, 'learning_rate': 0.0001435939906113594, 'epoch': 2.9}
{'loss': 0.041, 'grad_norm': 0.2683897614479065, 'learning_rate': 0.00014252322417860182, 'epoch': 3.0}
{'eval_loss': 0.8115807175636292, 'eval_runtime': 28.2282, 'eval_samples_per_second': 1.665, 'eval_steps_per_second': 1.665, 'epoch': 3.0}
{'loss': 0.0314, 'grad_norm': 0.19457891583442688, 'learning_rate': 0.00014141750387163237, 'epoch': 3.08}
{'loss': 0.0227, 'grad_norm': 0.17937859892845154, 'learning_rate': 0.00014027743652124646, 'epoch': 3.18}
{'loss': 0.0202, 'grad_norm': 0.20860818028450012, 'learning_rate': 0.00013910364780825386, 'epoch': 3.27}
{'loss': 0.0236, 'grad_norm': 0.26019713282585144, 'learning_rate': 0.0001378967819200986, 'epoch': 3.37}
{'loss': 0.019, 'grad_norm': 0.23591454327106476, 'learning_rate': 0.00013665750119732216, 'epoch': 3.46}
{'loss': 0.0185, 'grad_norm': 0.2190760374069214, 'learning_rate': 0.00013538648577006418, 'epoch': 3.55}
{'loss': 0.0174, 'grad_norm': 0.15214936435222626, 'learning_rate': 0.00013408443318479985, 'epoch': 3.65}
{'loss': 0.0175, 'grad_norm': 0.2425067126750946, 'learning_rate': 0.00013275205802151926, 'epoch': 3.74}
{'loss': 0.017, 'grad_norm': 0.19332969188690186, 'learning_rate': 0.0001313900915015584, 'epoch': 3.84}
{'loss': 0.0155, 'grad_norm': 0.2515680193901062, 'learning_rate': 0.00012999928108629739, 'epoch': 3.93}
{'eval_loss': 0.879554271697998, 'eval_runtime': 28.957, 'eval_samples_per_second': 1.623, 'eval_steps_per_second': 1.623, 'epoch': 4.0}
{'train_runtime': 2428.0488, 'train_samples_per_second': 2.281, 'train_steps_per_second': 0.573, 'train_loss': 0.1163303603148349, 'epoch': 4.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 40.47 min
   Peak memory: 12.57 GB
   Training memory: 0.0 GB
================================================================================


================================================================================
‚úÖ TRIAL #7 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6424
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_up1ofhma
[I 2025-11-03 00:19:35,449] Trial 7 finished with value: 0.6424023509025574 and parameters: {'num_epochs': 13, 'learning_rate': 0.00015766593696714065, 'weight_decay': 0.057085416051088966, 'batch_size': 1}. Best is trial 4 with value: 0.6417544484138489.

================================================================================
üî¨ OPTUNA TRIAL #8 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #8:
   ‚Ä¢ num_epochs:    9
   ‚Ä¢ learning_rate: 5.65e-05
   ‚Ä¢ weight_decay:  0.0676
   ‚Ä¢ batch_size:    1

‚è≥ Loading model for Trial #8...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_os9uj2uc
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #8...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 12.57 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 1, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.7946, 'grad_norm': 0.9879534840583801, 'learning_rate': 1.0163711493333341e-05, 'epoch': 0.09}
{'loss': 0.6495, 'grad_norm': 0.4320738911628723, 'learning_rate': 2.145672426370372e-05, 'epoch': 0.19}
{'loss': 0.5578, 'grad_norm': 0.3920043706893921, 'learning_rate': 3.27497370340741e-05, 'epoch': 0.28}
{'loss': 0.3946, 'grad_norm': 0.5307081341743469, 'learning_rate': 4.404274980444448e-05, 'epoch': 0.38}
{'loss': 0.2416, 'grad_norm': 0.23029090464115143, 'learning_rate': 5.5335762574814856e-05, 'epoch': 0.47}
{'loss': 0.2027, 'grad_norm': 0.20802974700927734, 'learning_rate': 5.645152666785568e-05, 'epoch': 0.56}
{'loss': 0.1878, 'grad_norm': 0.19482876360416412, 'learning_rate': 5.6404748130419415e-05, 'epoch': 0.66}
{'loss': 0.1923, 'grad_norm': 0.1989700198173523, 'learning_rate': 5.6324616481773174e-05, 'epoch': 0.75}
{'loss': 0.1556, 'grad_norm': 0.22211062908172607, 'learning_rate': 5.621122658984533e-05, 'epoch': 0.85}
{'loss': 0.16, 'grad_norm': 0.21428227424621582, 'learning_rate': 5.606471269702733e-05, 'epoch': 0.94}
{'eval_loss': 0.6661150455474854, 'eval_runtime': 27.2686, 'eval_samples_per_second': 1.724, 'eval_steps_per_second': 1.724, 'epoch': 1.0}
{'loss': 0.1732, 'grad_norm': 0.1818586140871048, 'learning_rate': 5.5885248261244e-05, 'epoch': 1.03}
{'loss': 0.1286, 'grad_norm': 0.20934250950813293, 'learning_rate': 5.56730457505966e-05, 'epoch': 1.12}
{'loss': 0.1438, 'grad_norm': 0.23086713254451752, 'learning_rate': 5.5428356391821625e-05, 'epoch': 1.22}
{'loss': 0.1538, 'grad_norm': 0.2574981153011322, 'learning_rate': 5.515146987286323e-05, 'epoch': 1.31}
{'loss': 0.1509, 'grad_norm': 0.2101302295923233, 'learning_rate': 5.4842713999911476e-05, 'epoch': 1.4}
{'loss': 0.1405, 'grad_norm': 0.2269618660211563, 'learning_rate': 5.4502454309312264e-05, 'epoch': 1.5}
{'loss': 0.1534, 'grad_norm': 0.2839761972427368, 'learning_rate': 5.4131093634808546e-05, 'epoch': 1.59}
{'loss': 0.1562, 'grad_norm': 0.2706601023674011, 'learning_rate': 5.3729071630625104e-05, 'epoch': 1.69}
{'loss': 0.1339, 'grad_norm': 0.2726955711841583, 'learning_rate': 5.3296864250961527e-05, 'epoch': 1.78}
{'loss': 0.1226, 'grad_norm': 0.28268882632255554, 'learning_rate': 5.283498318650962e-05, 'epoch': 1.87}
{'loss': 0.129, 'grad_norm': 0.3363840878009796, 'learning_rate': 5.234397525866239e-05, 'epoch': 1.97}
{'eval_loss': 0.6408839821815491, 'eval_runtime': 28.4153, 'eval_samples_per_second': 1.654, 'eval_steps_per_second': 1.654, 'epoch': 2.0}
{'loss': 0.1367, 'grad_norm': 0.3004164397716522, 'learning_rate': 5.182442177213166e-05, 'epoch': 2.06}
{'loss': 0.105, 'grad_norm': 0.3448525369167328, 'learning_rate': 5.1276937826740957e-05, 'epoch': 2.15}
{'loss': 0.1104, 'grad_norm': 0.32591140270233154, 'learning_rate': 5.070217158920829e-05, 'epoch': 2.24}
{'loss': 0.1054, 'grad_norm': 0.3468407988548279, 'learning_rate': 5.010080352578101e-05, 'epoch': 2.34}
{'loss': 0.1052, 'grad_norm': 0.3859231770038605, 'learning_rate': 4.9473545596631234e-05, 'epoch': 2.43}
{'loss': 0.0982, 'grad_norm': 0.3913458287715912, 'learning_rate': 4.882114041296555e-05, 'epoch': 2.53}
{'loss': 0.0881, 'grad_norm': 0.4207739531993866, 'learning_rate': 4.8144360357847e-05, 'epoch': 2.62}
{'loss': 0.103, 'grad_norm': 0.342422217130661, 'learning_rate': 4.7444006671770106e-05, 'epoch': 2.71}
{'loss': 0.1149, 'grad_norm': 0.4670952260494232, 'learning_rate': 4.672090850407151e-05, 'epoch': 2.81}
{'loss': 0.0917, 'grad_norm': 0.40774935483932495, 'learning_rate': 4.5975921931299395e-05, 'epoch': 2.9}
{'loss': 0.0876, 'grad_norm': 0.43139520287513733, 'learning_rate': 4.5209928943703705e-05, 'epoch': 3.0}
{'eval_loss': 0.7109392285346985, 'eval_runtime': 29.4648, 'eval_samples_per_second': 1.595, 'eval_steps_per_second': 1.595, 'epoch': 3.0}
{'loss': 0.0783, 'grad_norm': 0.4306413233280182, 'learning_rate': 4.4423836401047114e-05, 'epoch': 3.08}
{'loss': 0.0634, 'grad_norm': 0.39275050163269043, 'learning_rate': 4.361857495897299e-05, 'epoch': 3.18}
{'loss': 0.06, 'grad_norm': 0.4526404142379761, 'learning_rate': 4.279509796720133e-05, 'epoch': 3.27}
{'loss': 0.0715, 'grad_norm': 0.6607418060302734, 'learning_rate': 4.1954380340857244e-05, 'epoch': 3.37}
{'loss': 0.0657, 'grad_norm': 0.5284548997879028, 'learning_rate': 4.1097417406268054e-05, 'epoch': 3.46}
{'loss': 0.063, 'grad_norm': 0.49019089341163635, 'learning_rate': 4.0225223722595634e-05, 'epoch': 3.55}
{'loss': 0.0542, 'grad_norm': 0.4160376489162445, 'learning_rate': 3.933883188069888e-05, 'epoch': 3.65}
{'loss': 0.0597, 'grad_norm': 0.5555095076560974, 'learning_rate': 3.843929128064858e-05, 'epoch': 3.74}
{'loss': 0.0566, 'grad_norm': 0.47873467206954956, 'learning_rate': 3.752766688934166e-05, 'epoch': 3.84}
{'loss': 0.0527, 'grad_norm': 0.6581891179084778, 'learning_rate': 3.6605037979686005e-05, 'epoch': 3.93}
{'eval_loss': 0.7718732953071594, 'eval_runtime': 28.6768, 'eval_samples_per_second': 1.639, 'eval_steps_per_second': 1.639, 'epoch': 4.0}
{'loss': 0.0545, 'grad_norm': 0.2907063961029053, 'learning_rate': 3.567249685284836e-05, 'epoch': 4.02}
{'loss': 0.0328, 'grad_norm': 0.4254831075668335, 'learning_rate': 3.473114754507796e-05, 'epoch': 4.11}
{'loss': 0.0289, 'grad_norm': 0.5009350776672363, 'learning_rate': 3.378210452063709e-05, 'epoch': 4.21}
{'loss': 0.0305, 'grad_norm': 0.46452242136001587, 'learning_rate': 3.28264913523859e-05, 'epoch': 4.3}
{'loss': 0.0303, 'grad_norm': 0.5433377027511597, 'learning_rate': 3.186543939158347e-05, 'epoch': 4.39}
{'loss': 0.0302, 'grad_norm': 0.4885834753513336, 'learning_rate': 3.0900086428480115e-05, 'epoch': 4.49}
{'loss': 0.0259, 'grad_norm': 0.33305126428604126, 'learning_rate': 2.993157534528651e-05, 'epoch': 4.58}
{'loss': 0.0244, 'grad_norm': 0.40338385105133057, 'learning_rate': 2.8961052763114437e-05, 'epoch': 4.68}
{'loss': 0.0285, 'grad_norm': 0.615599513053894, 'learning_rate': 2.7989667684491076e-05, 'epoch': 4.77}
{'loss': 0.0267, 'grad_norm': 0.5648674964904785, 'learning_rate': 2.701857013305388e-05, 'epoch': 4.86}
{'loss': 0.0259, 'grad_norm': 0.5869942307472229, 'learning_rate': 2.6048909792036635e-05, 'epoch': 4.96}
{'eval_loss': 0.8516623377799988, 'eval_runtime': 28.4484, 'eval_samples_per_second': 1.652, 'eval_steps_per_second': 1.652, 'epoch': 5.0}
{'train_runtime': 3042.3638, 'train_samples_per_second': 1.26, 'train_steps_per_second': 0.317, 'train_loss': 0.13545991095984095, 'epoch': 5.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 50.71 min
   Peak memory: 12.57 GB
   Training memory: 0.0 GB
================================================================================


================================================================================
‚úÖ TRIAL #8 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6409
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_os9uj2uc
[I 2025-11-03 01:11:17,869] Trial 8 finished with value: 0.6408839821815491 and parameters: {'num_epochs': 9, 'learning_rate': 5.6465063851851895e-05, 'weight_decay': 0.06764932872032975, 'batch_size': 1}. Best is trial 8 with value: 0.6408839821815491.

================================================================================
üî¨ OPTUNA TRIAL #9 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #9:
   ‚Ä¢ num_epochs:    10
   ‚Ä¢ learning_rate: 1.68e-05
   ‚Ä¢ weight_decay:  0.0263
   ‚Ä¢ batch_size:    1

‚è≥ Loading model for Trial #9...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_hezewk4k
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #9...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 12.57 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 1, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.8122, 'grad_norm': 1.4787390232086182, 'learning_rate': 3.021353397673689e-06, 'epoch': 0.09}
{'loss': 0.7272, 'grad_norm': 0.7318193912506104, 'learning_rate': 6.378412728422233e-06, 'epoch': 0.19}
{'loss': 0.6829, 'grad_norm': 0.5436781048774719, 'learning_rate': 9.735472059170776e-06, 'epoch': 0.28}
{'loss': 0.6055, 'grad_norm': 0.3840767741203308, 'learning_rate': 1.309253138991932e-05, 'epoch': 0.38}
{'loss': 0.5148, 'grad_norm': 0.36544811725616455, 'learning_rate': 1.6449590720667865e-05, 'epoch': 0.47}
{'loss': 0.4445, 'grad_norm': 0.4784599542617798, 'learning_rate': 1.678207242651448e-05, 'epoch': 0.56}
{'loss': 0.3303, 'grad_norm': 0.4039131999015808, 'learning_rate': 1.6770930130144794e-05, 'epoch': 0.66}
{'loss': 0.2663, 'grad_norm': 0.2661787271499634, 'learning_rate': 1.6751840525984794e-05, 'epoch': 0.75}
{'loss': 0.2019, 'grad_norm': 0.27318423986434937, 'learning_rate': 1.672482172168034e-05, 'epoch': 0.85}
{'loss': 0.1894, 'grad_norm': 0.2882389426231384, 'learning_rate': 1.6689899346203936e-05, 'epoch': 0.94}
{'eval_loss': 0.7381391525268555, 'eval_runtime': 30.0577, 'eval_samples_per_second': 1.564, 'eval_steps_per_second': 1.564, 'epoch': 1.0}
{'loss': 0.2041, 'grad_norm': 0.2057986855506897, 'learning_rate': 1.6647106525544084e-05, 'epoch': 1.03}
{'loss': 0.1536, 'grad_norm': 0.20002387464046478, 'learning_rate': 1.659648385128328e-05, 'epoch': 1.12}
{'loss': 0.1703, 'grad_norm': 0.1890883594751358, 'learning_rate': 1.653807934209444e-05, 'epoch': 1.22}
{'loss': 0.1855, 'grad_norm': 0.21110467612743378, 'learning_rate': 1.6471948398192288e-05, 'epoch': 1.31}
{'loss': 0.1795, 'grad_norm': 0.16525886952877045, 'learning_rate': 1.639815374878287e-05, 'epoch': 1.4}
{'loss': 0.17, 'grad_norm': 0.19724297523498535, 'learning_rate': 1.631676539256115e-05, 'epoch': 1.5}
{'loss': 0.1856, 'grad_norm': 0.24055226147174835, 'learning_rate': 1.6227860531312948e-05, 'epoch': 1.59}
{'loss': 0.1907, 'grad_norm': 0.2094842493534088, 'learning_rate': 1.6131523496684426e-05, 'epoch': 1.69}
{'loss': 0.1639, 'grad_norm': 0.1993134468793869, 'learning_rate': 1.6027845670188374e-05, 'epoch': 1.78}
{'loss': 0.1537, 'grad_norm': 0.2023211568593979, 'learning_rate': 1.5916925396523328e-05, 'epoch': 1.87}
{'loss': 0.1601, 'grad_norm': 0.22144219279289246, 'learning_rate': 1.5798867890287666e-05, 'epoch': 1.97}
{'eval_loss': 0.6744033098220825, 'eval_runtime': 30.3134, 'eval_samples_per_second': 1.55, 'eval_steps_per_second': 1.55, 'epoch': 2.0}
{'loss': 0.1848, 'grad_norm': 0.24889236688613892, 'learning_rate': 1.5673785136177176e-05, 'epoch': 2.06}
{'loss': 0.153, 'grad_norm': 0.22073803842067719, 'learning_rate': 1.554179578276081e-05, 'epoch': 2.15}
{'loss': 0.1649, 'grad_norm': 0.2306034415960312, 'learning_rate': 1.5403025029935303e-05, 'epoch': 2.24}
{'loss': 0.153, 'grad_norm': 0.2304731011390686, 'learning_rate': 1.525760451016551e-05, 'epoch': 2.34}
{'loss': 0.159, 'grad_norm': 0.23511053621768951, 'learning_rate': 1.5105672163623033e-05, 'epoch': 2.43}
{'loss': 0.1465, 'grad_norm': 0.22600284218788147, 'learning_rate': 1.4947372107341604e-05, 'epoch': 2.53}
{'loss': 0.1378, 'grad_norm': 0.24567513167858124, 'learning_rate': 1.4782854498513355e-05, 'epoch': 2.62}
{'loss': 0.1512, 'grad_norm': 0.2174035608768463, 'learning_rate': 1.4612275392055633e-05, 'epoch': 2.71}
{'loss': 0.1746, 'grad_norm': 0.3075684607028961, 'learning_rate': 1.4435796592583444e-05, 'epoch': 2.81}
{'loss': 0.1432, 'grad_norm': 0.23856984078884125, 'learning_rate': 1.4253585500927984e-05, 'epoch': 2.9}
{'loss': 0.1437, 'grad_norm': 0.27784842252731323, 'learning_rate': 1.4065814955346814e-05, 'epoch': 3.0}
{'eval_loss': 0.6490647196769714, 'eval_runtime': 30.8012, 'eval_samples_per_second': 1.526, 'eval_steps_per_second': 1.526, 'epoch': 3.0}
{'loss': 0.1555, 'grad_norm': 0.24759633839130402, 'learning_rate': 1.3872663067576291e-05, 'epoch': 3.08}
{'loss': 0.1387, 'grad_norm': 0.25060293078422546, 'learning_rate': 1.3674313053881807e-05, 'epoch': 3.18}
{'loss': 0.1302, 'grad_norm': 0.2853025197982788, 'learning_rate': 1.3470953061266059e-05, 'epoch': 3.27}
{'loss': 0.1538, 'grad_norm': 0.29298242926597595, 'learning_rate': 1.326277598900022e-05, 'epoch': 3.37}
{'loss': 0.1483, 'grad_norm': 0.29197561740875244, 'learning_rate': 1.3049979305647305e-05, 'epoch': 3.46}
{'loss': 0.1455, 'grad_norm': 0.30710598826408386, 'learning_rate': 1.2832764861751263e-05, 'epoch': 3.55}
{'loss': 0.1284, 'grad_norm': 0.2859470546245575, 'learning_rate': 1.2611338698369517e-05, 'epoch': 3.65}
{'loss': 0.1398, 'grad_norm': 0.32050424814224243, 'learning_rate': 1.238591085163054e-05, 'epoch': 3.74}
{'loss': 0.1353, 'grad_norm': 0.31957605481147766, 'learning_rate': 1.2156695153501868e-05, 'epoch': 3.84}
{'loss': 0.1285, 'grad_norm': 0.36172908544540405, 'learning_rate': 1.192390902895752e-05, 'epoch': 3.93}
{'eval_loss': 0.6442682147026062, 'eval_runtime': 29.5457, 'eval_samples_per_second': 1.591, 'eval_steps_per_second': 1.591, 'epoch': 4.0}
{'loss': 0.1343, 'grad_norm': 0.27263277769088745, 'learning_rate': 1.1687773289737238e-05, 'epoch': 4.02}
{'loss': 0.1297, 'grad_norm': 0.3062472641468048, 'learning_rate': 1.1448511924893192e-05, 'epoch': 4.11}
{'loss': 0.1264, 'grad_norm': 0.38351908326148987, 'learning_rate': 1.1206351888322777e-05, 'epoch': 4.21}
{'loss': 0.1284, 'grad_norm': 0.357981413602829, 'learning_rate': 1.0961522883489105e-05, 'epoch': 4.3}
{'loss': 0.1332, 'grad_norm': 0.4349915683269501, 'learning_rate': 1.0714257145533351e-05, 'epoch': 4.39}
{'loss': 0.1243, 'grad_norm': 0.3480428457260132, 'learning_rate': 1.0464789220985663e-05, 'epoch': 4.49}
{'loss': 0.1077, 'grad_norm': 0.3193868398666382, 'learning_rate': 1.0213355745283563e-05, 'epoch': 4.58}
{'loss': 0.1158, 'grad_norm': 0.3920804560184479, 'learning_rate': 9.960195218308901e-06, 'epoch': 4.68}
{'loss': 0.1223, 'grad_norm': 0.4099523723125458, 'learning_rate': 9.705547778156269e-06, 'epoch': 4.77}
{'loss': 0.1122, 'grad_norm': 0.4218929708003998, 'learning_rate': 9.449654973347485e-06, 'epoch': 4.86}
{'loss': 0.1138, 'grad_norm': 0.5354731678962708, 'learning_rate': 9.192759533708168e-06, 'epoch': 4.96}
{'eval_loss': 0.661765992641449, 'eval_runtime': 29.1178, 'eval_samples_per_second': 1.614, 'eval_steps_per_second': 1.614, 'epoch': 5.0}
{'loss': 0.1245, 'grad_norm': 0.4455402195453644, 'learning_rate': 8.935105140123819e-06, 'epoch': 5.05}
{'loss': 0.1173, 'grad_norm': 0.3955250382423401, 'learning_rate': 8.676936193393717e-06, 'epoch': 5.14}
{'loss': 0.1049, 'grad_norm': 0.46938422322273254, 'learning_rate': 8.418497582401973e-06, 'epoch': 5.23}
{'loss': 0.0994, 'grad_norm': 0.46443846821784973, 'learning_rate': 8.160034451825585e-06, 'epoch': 5.33}
{'loss': 0.105, 'grad_norm': 0.4252263307571411, 'learning_rate': 7.90179196959986e-06, 'epoch': 5.42}
{'loss': 0.104, 'grad_norm': 0.5159476399421692, 'learning_rate': 7.64401509436178e-06, 'epoch': 5.52}
{'loss': 0.1102, 'grad_norm': 0.5284518599510193, 'learning_rate': 7.386948343091901e-06, 'epoch': 5.61}
{'loss': 0.095, 'grad_norm': 0.4445333480834961, 'learning_rate': 7.130835559175164e-06, 'epoch': 5.7}
{'loss': 0.0944, 'grad_norm': 0.547606885433197, 'learning_rate': 6.875919681100716e-06, 'epoch': 5.8}
{'loss': 0.1043, 'grad_norm': 0.4903775751590729, 'learning_rate': 6.622442512019994e-06, 'epoch': 5.89}
{'loss': 0.1012, 'grad_norm': 0.48032039403915405, 'learning_rate': 6.370644490381808e-06, 'epoch': 5.99}
{'eval_loss': 0.6829661726951599, 'eval_runtime': 29.773, 'eval_samples_per_second': 1.579, 'eval_steps_per_second': 1.579, 'epoch': 6.0}
{'loss': 0.1111, 'grad_norm': 0.4472014904022217, 'learning_rate': 6.12076446186191e-06, 'epoch': 6.08}
{'loss': 0.0961, 'grad_norm': 0.5247427225112915, 'learning_rate': 5.873039452803407e-06, 'epoch': 6.17}
{'loss': 0.0977, 'grad_norm': 0.5328755974769592, 'learning_rate': 5.627704445382903e-06, 'epoch': 6.26}
{'loss': 0.0931, 'grad_norm': 0.5589967966079712, 'learning_rate': 5.384992154715675e-06, 'epoch': 6.36}
{'loss': 0.0809, 'grad_norm': 0.5071005821228027, 'learning_rate': 5.145132808111303e-06, 'epoch': 6.45}
{'loss': 0.0877, 'grad_norm': 0.523612916469574, 'learning_rate': 4.908353926689105e-06, 'epoch': 6.54}
{'loss': 0.0801, 'grad_norm': 0.5241611003875732, 'learning_rate': 4.674880109560575e-06, 'epoch': 6.64}
{'loss': 0.0825, 'grad_norm': 0.501555860042572, 'learning_rate': 4.44493282078354e-06, 'epoch': 6.73}
{'loss': 0.0851, 'grad_norm': 0.5544514060020447, 'learning_rate': 4.218730179290058e-06, 'epoch': 6.83}
{'loss': 0.0977, 'grad_norm': 0.6094195246696472, 'learning_rate': 3.996486751987417e-06, 'epoch': 6.92}
{'eval_loss': 0.7189768552780151, 'eval_runtime': 27.7833, 'eval_samples_per_second': 1.692, 'eval_steps_per_second': 1.692, 'epoch': 7.0}
{'train_runtime': 4422.0183, 'train_samples_per_second': 0.963, 'train_steps_per_second': 0.242, 'train_loss': 0.17787241720866775, 'epoch': 7.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 73.7 min
   Peak memory: 12.57 GB
   Training memory: 0.0 GB
================================================================================


================================================================================
‚úÖ TRIAL #9 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6443
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_hezewk4k
[I 2025-11-03 02:28:02,378] Trial 9 finished with value: 0.6442682147026062 and parameters: {'num_epochs': 10, 'learning_rate': 1.6785296653742718e-05, 'weight_decay': 0.02626130870190896, 'batch_size': 1}. Best is trial 8 with value: 0.6408839821815491.

================================================================================
üî¨ OPTUNA TRIAL #10 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #10:
   ‚Ä¢ num_epochs:    8
   ‚Ä¢ learning_rate: 4.55e-04
   ‚Ä¢ weight_decay:  0.1000
   ‚Ä¢ batch_size:    2

‚è≥ Loading model for Trial #10...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_i3lyvbv2
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #10...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 12.57 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 2, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.6956, 'grad_norm': 0.7520927786827087, 'learning_rate': 8.183916346138806e-05, 'epoch': 0.19}
{'loss': 0.384, 'grad_norm': 0.4841931462287903, 'learning_rate': 0.0001727715673073748, 'epoch': 0.38}
{'loss': 0.1996, 'grad_norm': 0.15147466957569122, 'learning_rate': 0.0002637039711533615, 'epoch': 0.56}
{'loss': 0.1796, 'grad_norm': 0.13229438662528992, 'learning_rate': 0.0003546363749993483, 'epoch': 0.75}
{'loss': 0.1477, 'grad_norm': 0.1308716982603073, 'learning_rate': 0.000445568778845335, 'epoch': 0.94}
{'eval_loss': 0.6823521256446838, 'eval_runtime': 20.0979, 'eval_samples_per_second': 2.339, 'eval_steps_per_second': 1.194, 'epoch': 1.0}
{'loss': 0.1788, 'grad_norm': 0.1607615351676941, 'learning_rate': 0.0004540395922025565, 'epoch': 1.11}
{'loss': 0.1286, 'grad_norm': 0.14778099954128265, 'learning_rate': 0.0004518923680839424, 'epoch': 1.3}
{'loss': 0.1295, 'grad_norm': 0.1381024271249771, 'learning_rate': 0.0004482271737417368, 'epoch': 1.49}
{'loss': 0.1313, 'grad_norm': 0.22179196774959564, 'learning_rate': 0.00044306878483597797, 'epoch': 1.68}
{'loss': 0.1029, 'grad_norm': 0.13872748613357544, 'learning_rate': 0.00043645207059267167, 'epoch': 1.86}
{'eval_loss': 0.7005982995033264, 'eval_runtime': 20.1292, 'eval_samples_per_second': 2.335, 'eval_steps_per_second': 1.192, 'epoch': 2.0}
{'loss': 0.1276, 'grad_norm': inf, 'learning_rate': 0.0004284217580978484, 'epoch': 2.04}
{'loss': 0.0781, 'grad_norm': 0.1833474487066269, 'learning_rate': 0.00042003052320646606, 'epoch': 2.23}
{'loss': 0.0683, 'grad_norm': 0.1627514511346817, 'learning_rate': 0.00040947152556214465, 'epoch': 2.41}
{'loss': 0.0569, 'grad_norm': 1.7991148233413696, 'learning_rate': 0.000397681310394014, 'epoch': 2.6}
{'loss': 0.0619, 'grad_norm': 0.421506404876709, 'learning_rate': 0.0003847395761670147, 'epoch': 2.79}
{'loss': 0.0514, 'grad_norm': 0.17707747220993042, 'learning_rate': 0.0003707338052838725, 'epoch': 2.98}
{'eval_loss': 0.8054243922233582, 'eval_runtime': 20.679, 'eval_samples_per_second': 2.273, 'eval_steps_per_second': 1.161, 'epoch': 3.0}
{'loss': 0.0578, 'grad_norm': 0.19671010971069336, 'learning_rate': 0.00035575867272920645, 'epoch': 3.15}
{'loss': 0.0296, 'grad_norm': 0.1359146535396576, 'learning_rate': 0.00033991540609385075, 'epoch': 3.34}
{'loss': 0.028, 'grad_norm': 0.11241531372070312, 'learning_rate': 0.0003233111013054436, 'epoch': 3.53}
{'loss': 0.0195, 'grad_norm': 0.11943332850933075, 'learning_rate': 0.000306057998690745, 'epoch': 3.71}
{'loss': 0.0196, 'grad_norm': 0.12183243781328201, 'learning_rate': 0.0002882727242632963, 'epoch': 3.9}
{'eval_loss': 0.9041528105735779, 'eval_runtime': 20.2491, 'eval_samples_per_second': 2.321, 'eval_steps_per_second': 1.185, 'epoch': 4.0}
{'train_runtime': 1656.9041, 'train_samples_per_second': 2.057, 'train_steps_per_second': 0.261, 'train_loss': 0.13386311202689452, 'epoch': 4.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 27.62 min
   Peak memory: 14.895 GB
   Training memory: 2.325 GB
================================================================================


================================================================================
‚úÖ TRIAL #10 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6824
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_i3lyvbv2
[I 2025-11-03 02:56:17,683] Trial 10 finished with value: 0.6823521256446838 and parameters: {'num_epochs': 8, 'learning_rate': 0.00045466201922993366, 'weight_decay': 0.0999988879224753, 'batch_size': 2}. Best is trial 8 with value: 0.6408839821815491.

================================================================================
üî¨ OPTUNA TRIAL #11 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #11:
   ‚Ä¢ num_epochs:    15
   ‚Ä¢ learning_rate: 4.30e-05
   ‚Ä¢ weight_decay:  0.0792
   ‚Ä¢ batch_size:    1

‚è≥ Loading model for Trial #11...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_55nf7qhj
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #11...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 14.895 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 1, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.7989, 'grad_norm': 1.1373209953308105, 'learning_rate': 7.743709994237478e-06, 'epoch': 0.09}
{'loss': 0.6677, 'grad_norm': 0.5141511559486389, 'learning_rate': 1.6347832210056897e-05, 'epoch': 0.19}
{'loss': 0.5909, 'grad_norm': 0.4613579213619232, 'learning_rate': 2.4951954425876316e-05, 'epoch': 0.28}
{'loss': 0.4588, 'grad_norm': 0.4397149980068207, 'learning_rate': 3.355607664169574e-05, 'epoch': 0.38}
{'loss': 0.2984, 'grad_norm': 0.29505643248558044, 'learning_rate': 4.2160198857515154e-05, 'epoch': 0.47}
{'loss': 0.2255, 'grad_norm': 0.2638419568538666, 'learning_rate': 4.3017055350572356e-05, 'epoch': 0.56}
{'loss': 0.1974, 'grad_norm': 0.20820297300815582, 'learning_rate': 4.30047654525457e-05, 'epoch': 0.66}
{'loss': 0.1974, 'grad_norm': 0.21027064323425293, 'learning_rate': 4.298370250211212e-05, 'epoch': 0.75}
{'loss': 0.1602, 'grad_norm': 0.23156292736530304, 'learning_rate': 4.295387509620163e-05, 'epoch': 0.85}
{'loss': 0.164, 'grad_norm': 0.21468059718608856, 'learning_rate': 4.291529540899291e-05, 'epoch': 0.94}
{'eval_loss': 0.6774226427078247, 'eval_runtime': 29.5815, 'eval_samples_per_second': 1.589, 'eval_steps_per_second': 1.589, 'epoch': 1.0}
{'loss': 0.1786, 'grad_norm': 0.18279585242271423, 'learning_rate': 4.2867979186944304e-05, 'epoch': 1.03}
{'loss': 0.1334, 'grad_norm': 0.21455179154872894, 'learning_rate': 4.281194574236686e-05, 'epoch': 1.12}
{'loss': 0.1497, 'grad_norm': 0.2244277000427246, 'learning_rate': 4.274721794554194e-05, 'epoch': 1.22}
{'loss': 0.1608, 'grad_norm': 0.24564288556575775, 'learning_rate': 4.26738222153866e-05, 'epoch': 1.31}
{'loss': 0.1573, 'grad_norm': 0.19476674497127533, 'learning_rate': 4.2591788508670615e-05, 'epoch': 1.4}
{'loss': 0.147, 'grad_norm': 0.2242008000612259, 'learning_rate': 4.250115030778951e-05, 'epoch': 1.5}
{'loss': 0.1606, 'grad_norm': 0.2676037549972534, 'learning_rate': 4.2401944607098544e-05, 'epoch': 1.59}
{'loss': 0.1641, 'grad_norm': 0.25293096899986267, 'learning_rate': 4.229421189781336e-05, 'epoch': 1.69}
{'loss': 0.1409, 'grad_norm': 0.25751248002052307, 'learning_rate': 4.217799615148329e-05, 'epoch': 1.78}
{'loss': 0.1299, 'grad_norm': 0.25804775953292847, 'learning_rate': 4.205334480204419e-05, 'epoch': 1.87}
{'loss': 0.136, 'grad_norm': 0.31387656927108765, 'learning_rate': 4.192030872645813e-05, 'epoch': 1.97}
{'eval_loss': 0.6387742757797241, 'eval_runtime': 27.6674, 'eval_samples_per_second': 1.699, 'eval_steps_per_second': 1.699, 'epoch': 2.0}
{'loss': 0.1484, 'grad_norm': 0.28006044030189514, 'learning_rate': 4.1778942223947673e-05, 'epoch': 2.06}
{'loss': 0.1167, 'grad_norm': 0.32435357570648193, 'learning_rate': 4.1629302993833505e-05, 'epoch': 2.15}
{'loss': 0.1235, 'grad_norm': 0.3087911903858185, 'learning_rate': 4.147145211198415e-05, 'epoch': 2.24}
{'loss': 0.117, 'grad_norm': 0.33149757981300354, 'learning_rate': 4.130545400588765e-05, 'epoch': 2.34}
{'loss': 0.1182, 'grad_norm': 0.34973350167274475, 'learning_rate': 4.1131376428355205e-05, 'epoch': 2.43}
{'loss': 0.1095, 'grad_norm': 0.3608192503452301, 'learning_rate': 4.094929042986758e-05, 'epoch': 2.53}
{'loss': 0.0996, 'grad_norm': 0.40408840775489807, 'learning_rate': 4.075927032957555e-05, 'epoch': 2.62}
{'loss': 0.1142, 'grad_norm': 0.33025074005126953, 'learning_rate': 4.056139368496626e-05, 'epoch': 2.71}
{'loss': 0.1283, 'grad_norm': 0.4379863142967224, 'learning_rate': 4.0355741260207786e-05, 'epoch': 2.81}
{'loss': 0.1031, 'grad_norm': 0.38940346240997314, 'learning_rate': 4.014239699318494e-05, 'epoch': 2.9}
{'loss': 0.1007, 'grad_norm': 0.42170917987823486, 'learning_rate': 3.9921447961239635e-05, 'epoch': 3.0}
{'eval_loss': 0.6793698668479919, 'eval_runtime': 31.0386, 'eval_samples_per_second': 1.514, 'eval_steps_per_second': 1.514, 'epoch': 3.0}
{'loss': 0.095, 'grad_norm': 0.4410380423069, 'learning_rate': 3.9692984345629935e-05, 'epoch': 3.08}
{'loss': 0.0778, 'grad_norm': 0.399893581867218, 'learning_rate': 3.945709939472223e-05, 'epoch': 3.18}
{'loss': 0.0736, 'grad_norm': 0.44850432872772217, 'learning_rate': 3.921388938593146e-05, 'epoch': 3.27}
{'loss': 0.0881, 'grad_norm': 0.5017901659011841, 'learning_rate': 3.896345358642515e-05, 'epoch': 3.37}
{'loss': 0.0815, 'grad_norm': 0.5068407654762268, 'learning_rate': 3.8705894212607094e-05, 'epoch': 3.46}
{'loss': 0.079, 'grad_norm': 0.5225793123245239, 'learning_rate': 3.8441316388397286e-05, 'epoch': 3.55}
{'loss': 0.068, 'grad_norm': 0.4591776728630066, 'learning_rate': 3.816982810232518e-05, 'epoch': 3.65}
{'loss': 0.0757, 'grad_norm': 0.5617632269859314, 'learning_rate': 3.7891540163453754e-05, 'epoch': 3.74}
{'loss': 0.0709, 'grad_norm': 0.5492004156112671, 'learning_rate': 3.760656615615224e-05, 'epoch': 3.84}
{'loss': 0.0665, 'grad_norm': 0.639356791973114, 'learning_rate': 3.731502239373632e-05, 'epoch': 3.93}
{'eval_loss': 0.757108747959137, 'eval_runtime': 28.6532, 'eval_samples_per_second': 1.64, 'eval_steps_per_second': 1.64, 'epoch': 4.0}
{'loss': 0.0684, 'grad_norm': 0.3310796320438385, 'learning_rate': 3.701702787099425e-05, 'epoch': 4.02}
{'loss': 0.0457, 'grad_norm': 0.44226956367492676, 'learning_rate': 3.6712704215618745e-05, 'epoch': 4.11}
{'loss': 0.0413, 'grad_norm': 0.5790231823921204, 'learning_rate': 3.640217563856407e-05, 'epoch': 4.21}
{'loss': 0.0436, 'grad_norm': 0.6038821935653687, 'learning_rate': 3.6085568883348846e-05, 'epoch': 4.3}
{'loss': 0.0429, 'grad_norm': 0.6153940558433533, 'learning_rate': 3.576301317432518e-05, 'epoch': 4.39}
{'loss': 0.0427, 'grad_norm': 0.5374663472175598, 'learning_rate': 3.543464016393517e-05, 'epoch': 4.49}
{'loss': 0.0363, 'grad_norm': 0.36317679286003113, 'learning_rate': 3.510058387897647e-05, 'epoch': 4.58}
{'loss': 0.0356, 'grad_norm': 0.5503093600273132, 'learning_rate': 3.476098066589865e-05, 'epoch': 4.68}
{'loss': 0.0412, 'grad_norm': 0.669579803943634, 'learning_rate': 3.4415969135152874e-05, 'epoch': 4.77}
{'loss': 0.0378, 'grad_norm': 0.6567225456237793, 'learning_rate': 3.406569010461744e-05, 'epoch': 4.86}
{'loss': 0.0371, 'grad_norm': 0.7043602466583252, 'learning_rate': 3.371028654212241e-05, 'epoch': 4.96}
{'eval_loss': 0.8374965786933899, 'eval_runtime': 28.8979, 'eval_samples_per_second': 1.626, 'eval_steps_per_second': 1.626, 'epoch': 5.0}
{'train_runtime': 3183.2636, 'train_samples_per_second': 2.007, 'train_steps_per_second': 0.504, 'train_loss': 0.14891915644440695, 'epoch': 5.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 53.05 min
   Peak memory: 14.895 GB
   Training memory: 0.0 GB
================================================================================


================================================================================
‚úÖ TRIAL #11 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6388
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_55nf7qhj
[I 2025-11-03 03:52:23,316] Trial 11 finished with value: 0.6387742757797241 and parameters: {'num_epochs': 15, 'learning_rate': 4.30206110790971e-05, 'weight_decay': 0.07920173174912956, 'batch_size': 1}. Best is trial 11 with value: 0.6387742757797241.

================================================================================
üî¨ OPTUNA TRIAL #12 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #12:
   ‚Ä¢ num_epochs:    12
   ‚Ä¢ learning_rate: 4.94e-05
   ‚Ä¢ weight_decay:  0.0800
   ‚Ä¢ batch_size:    1

‚è≥ Loading model for Trial #12...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_uvhbxj26
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #12...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 14.895 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 1, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.7965, 'grad_norm': 1.0642492771148682, 'learning_rate': 8.890537009979717e-06, 'epoch': 0.09}
{'loss': 0.6581, 'grad_norm': 0.4820621609687805, 'learning_rate': 1.8768911465512736e-05, 'epoch': 0.19}
{'loss': 0.5744, 'grad_norm': 0.4006158113479614, 'learning_rate': 2.8647285921045753e-05, 'epoch': 0.28}
{'loss': 0.4293, 'grad_norm': 0.5735623240470886, 'learning_rate': 3.852566037657877e-05, 'epoch': 0.38}
{'loss': 0.2671, 'grad_norm': 0.23837611079216003, 'learning_rate': 4.840403483211179e-05, 'epoch': 0.47}
{'loss': 0.2119, 'grad_norm': 0.21390049159526825, 'learning_rate': 4.9385389950557314e-05, 'epoch': 0.56}
{'loss': 0.1918, 'grad_norm': 0.20776015520095825, 'learning_rate': 4.936298627518202e-05, 'epoch': 0.66}
{'loss': 0.1946, 'grad_norm': 0.2024097442626953, 'learning_rate': 4.9324595739305384e-05, 'epoch': 0.75}
{'loss': 0.158, 'grad_norm': 0.22275933623313904, 'learning_rate': 4.927024322405987e-05, 'epoch': 0.85}
{'loss': 0.162, 'grad_norm': 0.2213195413351059, 'learning_rate': 4.919996395563078e-05, 'epoch': 0.94}
{'eval_loss': 0.6708458065986633, 'eval_runtime': 29.0206, 'eval_samples_per_second': 1.62, 'eval_steps_per_second': 1.62, 'epoch': 1.0}
{'loss': 0.176, 'grad_norm': 0.18250615894794464, 'learning_rate': 4.911380348242597e-05, 'epoch': 1.03}
{'loss': 0.131, 'grad_norm': 0.20151777565479279, 'learning_rate': 4.9011817645555695e-05, 'epoch': 1.12}
{'loss': 0.1469, 'grad_norm': 0.22978127002716064, 'learning_rate': 4.889407254264159e-05, 'epoch': 1.22}
{'loss': 0.1573, 'grad_norm': 0.24809153378009796, 'learning_rate': 4.8760644484978474e-05, 'epoch': 1.31}
{'loss': 0.1544, 'grad_norm': 0.20138472318649292, 'learning_rate': 4.86116199480765e-05, 'epoch': 1.4}
{'loss': 0.1437, 'grad_norm': 0.22692658007144928, 'learning_rate': 4.844709551561592e-05, 'epoch': 1.5}
{'loss': 0.157, 'grad_norm': 0.2759266197681427, 'learning_rate': 4.826717781685059e-05, 'epoch': 1.59}
{'loss': 0.1603, 'grad_norm': 0.2636856436729431, 'learning_rate': 4.8071983457500916e-05, 'epoch': 1.69}
{'loss': 0.1375, 'grad_norm': 0.260863333940506, 'learning_rate': 4.786163894418104e-05, 'epoch': 1.78}
{'loss': 0.1265, 'grad_norm': 0.3228808343410492, 'learning_rate': 4.7636280602409156e-05, 'epoch': 1.87}
{'loss': 0.1325, 'grad_norm': 0.3251489996910095, 'learning_rate': 4.7396054488254076e-05, 'epoch': 1.97}
{'eval_loss': 0.6393419504165649, 'eval_runtime': 29.6994, 'eval_samples_per_second': 1.583, 'eval_steps_per_second': 1.583, 'epoch': 2.0}
{'loss': 0.1426, 'grad_norm': 0.2905083894729614, 'learning_rate': 4.714111629367552e-05, 'epoch': 2.06}
{'loss': 0.1108, 'grad_norm': 0.3469387888908386, 'learning_rate': 4.6871631245619157e-05, 'epoch': 2.15}
{'loss': 0.1169, 'grad_norm': 0.3169088363647461, 'learning_rate': 4.658777399893214e-05, 'epoch': 2.24}
{'loss': 0.1112, 'grad_norm': 0.34574005007743835, 'learning_rate': 4.628972852316815e-05, 'epoch': 2.34}
{'loss': 0.1114, 'grad_norm': 0.37017884850502014, 'learning_rate': 4.597768798335577e-05, 'epoch': 2.43}
{'loss': 0.1035, 'grad_norm': 0.37580767273902893, 'learning_rate': 4.565185461480701e-05, 'epoch': 2.53}
{'loss': 0.0938, 'grad_norm': 0.4163001775741577, 'learning_rate': 4.5312439592047424e-05, 'epoch': 2.62}
{'loss': 0.1087, 'grad_norm': 0.33835646510124207, 'learning_rate': 4.495966289195268e-05, 'epoch': 2.71}
{'loss': 0.1215, 'grad_norm': 0.44442299008369446, 'learning_rate': 4.459375315118025e-05, 'epoch': 2.81}
{'loss': 0.0974, 'grad_norm': 0.404263436794281, 'learning_rate': 4.421494751798862e-05, 'epoch': 2.9}
{'loss': 0.0941, 'grad_norm': 0.4376879334449768, 'learning_rate': 4.3823491498540106e-05, 'epoch': 3.0}
{'eval_loss': 0.6962074041366577, 'eval_runtime': 27.6604, 'eval_samples_per_second': 1.699, 'eval_steps_per_second': 1.699, 'epoch': 3.0}
{'loss': 0.0858, 'grad_norm': 0.4718564450740814, 'learning_rate': 4.3419638797786896e-05, 'epoch': 3.08}
{'loss': 0.07, 'grad_norm': 0.3996463716030121, 'learning_rate': 4.300365115504335e-05, 'epoch': 3.18}
{'loss': 0.0662, 'grad_norm': 0.4534688889980316, 'learning_rate': 4.257579817435122e-05, 'epoch': 3.27}
{'loss': 0.079, 'grad_norm': 0.5899076461791992, 'learning_rate': 4.2136357149747694e-05, 'epoch': 3.37}
{'loss': 0.073, 'grad_norm': 0.5240399241447449, 'learning_rate': 4.168561288554943e-05, 'epoch': 3.46}
{'loss': 0.0706, 'grad_norm': 0.5342909097671509, 'learning_rate': 4.122385751176932e-05, 'epoch': 3.55}
{'loss': 0.0606, 'grad_norm': 0.4518638849258423, 'learning_rate': 4.075139029478518e-05, 'epoch': 3.65}
{'loss': 0.0677, 'grad_norm': 0.5405936241149902, 'learning_rate': 4.026851744338356e-05, 'epoch': 3.74}
{'loss': 0.0634, 'grad_norm': 0.5183346271514893, 'learning_rate': 3.977555191030392e-05, 'epoch': 3.84}
{'loss': 0.0589, 'grad_norm': 0.6218778491020203, 'learning_rate': 3.927281318941222e-05, 'epoch': 3.93}
{'eval_loss': 0.7662429809570312, 'eval_runtime': 29.3535, 'eval_samples_per_second': 1.601, 'eval_steps_per_second': 1.601, 'epoch': 4.0}
{'loss': 0.0613, 'grad_norm': 0.309793084859848, 'learning_rate': 3.8760627108634974e-05, 'epoch': 4.02}
{'loss': 0.0381, 'grad_norm': 0.4137108027935028, 'learning_rate': 3.8239325618788305e-05, 'epoch': 4.11}
{'loss': 0.0344, 'grad_norm': 0.48687028884887695, 'learning_rate': 3.7709246578438665e-05, 'epoch': 4.21}
{'loss': 0.0354, 'grad_norm': 0.5371612906455994, 'learning_rate': 3.717073353493467e-05, 'epoch': 4.3}
{'loss': 0.0358, 'grad_norm': 0.5938701033592224, 'learning_rate': 3.662413550175207e-05, 'epoch': 4.39}
{'loss': 0.0362, 'grad_norm': 0.4819298982620239, 'learning_rate': 3.6069806732296054e-05, 'epoch': 4.49}
{'loss': 0.0306, 'grad_norm': 0.3795563280582428, 'learning_rate': 3.5508106490307545e-05, 'epoch': 4.58}
{'loss': 0.0294, 'grad_norm': 0.4533652663230896, 'learning_rate': 3.493939881702221e-05, 'epoch': 4.68}
{'loss': 0.0339, 'grad_norm': 0.5998337864875793, 'learning_rate': 3.436405229523323e-05, 'epoch': 4.77}
{'loss': 0.0316, 'grad_norm': 0.6000509858131409, 'learning_rate': 3.3782439810410634e-05, 'epoch': 4.86}
{'loss': 0.0304, 'grad_norm': 0.6324051022529602, 'learning_rate': 3.319493830903195e-05, 'epoch': 4.96}
{'eval_loss': 0.8461368083953857, 'eval_runtime': 29.5187, 'eval_samples_per_second': 1.592, 'eval_steps_per_second': 1.592, 'epoch': 5.0}
{'train_runtime': 3189.2655, 'train_samples_per_second': 1.603, 'train_steps_per_second': 0.403, 'train_loss': 0.14183658236098068, 'epoch': 5.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 53.15 min
   Peak memory: 14.895 GB
   Training memory: 0.0 GB
================================================================================


================================================================================
‚úÖ TRIAL #12 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6393
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_uvhbxj26
[I 2025-11-03 04:48:38,079] Trial 12 finished with value: 0.6393419504165649 and parameters: {'num_epochs': 12, 'learning_rate': 4.939187227766509e-05, 'weight_decay': 0.07999998866924543, 'batch_size': 1}. Best is trial 11 with value: 0.6387742757797241.

================================================================================
üî¨ OPTUNA TRIAL #13 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #13:
   ‚Ä¢ num_epochs:    15
   ‚Ä¢ learning_rate: 4.31e-05
   ‚Ä¢ weight_decay:  0.0938
   ‚Ä¢ batch_size:    1

‚è≥ Loading model for Trial #13...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_bju1kgxg
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #13...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 14.895 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 1, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.7994, 'grad_norm': 1.1362452507019043, 'learning_rate': 7.766712847469951e-06, 'epoch': 0.09}
{'loss': 0.6679, 'grad_norm': 0.5120853185653687, 'learning_rate': 1.639639378910323e-05, 'epoch': 0.19}
{'loss': 0.5906, 'grad_norm': 0.4643290042877197, 'learning_rate': 2.5026074730736506e-05, 'epoch': 0.28}
{'loss': 0.4574, 'grad_norm': 0.4435419738292694, 'learning_rate': 3.365575567236979e-05, 'epoch': 0.38}
{'loss': 0.2964, 'grad_norm': 0.3064138889312744, 'learning_rate': 4.228543661400307e-05, 'epoch': 0.47}
{'loss': 0.2212, 'grad_norm': 0.2465038150548935, 'learning_rate': 4.314483841727536e-05, 'epoch': 0.56}
{'loss': 0.1951, 'grad_norm': 0.22009961307048798, 'learning_rate': 4.313251201184841e-05, 'epoch': 0.66}
{'loss': 0.1973, 'grad_norm': 0.20780989527702332, 'learning_rate': 4.311138649347803e-05, 'epoch': 0.75}
{'loss': 0.1605, 'grad_norm': 0.23252710700035095, 'learning_rate': 4.308147048463162e-05, 'epoch': 0.85}
{'loss': 0.1642, 'grad_norm': 0.2109088897705078, 'learning_rate': 4.304277619565149e-05, 'epoch': 0.94}
{'eval_loss': 0.6760186553001404, 'eval_runtime': 28.8023, 'eval_samples_per_second': 1.632, 'eval_steps_per_second': 1.632, 'epoch': 1.0}
{'loss': 0.179, 'grad_norm': 0.18292184174060822, 'learning_rate': 4.299531941977118e-05, 'epoch': 1.03}
{'loss': 0.1338, 'grad_norm': 0.19531770050525665, 'learning_rate': 4.293911952666936e-05, 'epoch': 1.12}
{'loss': 0.15, 'grad_norm': 0.22471602261066437, 'learning_rate': 4.287419945456405e-05, 'epoch': 1.22}
{'loss': 0.161, 'grad_norm': 0.24203908443450928, 'learning_rate': 4.280058570085024e-05, 'epoch': 1.31}
{'loss': 0.1576, 'grad_norm': 0.19346486032009125, 'learning_rate': 4.2718308311284936e-05, 'epoch': 1.4}
{'loss': 0.1472, 'grad_norm': 0.22228391468524933, 'learning_rate': 4.262740086772382e-05, 'epoch': 1.5}
{'loss': 0.1609, 'grad_norm': 0.26619455218315125, 'learning_rate': 4.2527900474414646e-05, 'epoch': 1.59}
{'loss': 0.1644, 'grad_norm': 0.25232213735580444, 'learning_rate': 4.241984774285308e-05, 'epoch': 1.69}
{'loss': 0.1412, 'grad_norm': 0.25903117656707764, 'learning_rate': 4.230328677520685e-05, 'epoch': 1.78}
{'loss': 0.1302, 'grad_norm': 0.2564232051372528, 'learning_rate': 4.217826514631533e-05, 'epoch': 1.87}
{'loss': 0.1361, 'grad_norm': 0.3116309940814972, 'learning_rate': 4.2044833884271665e-05, 'epoch': 1.97}
{'eval_loss': 0.6387943625450134, 'eval_runtime': 29.263, 'eval_samples_per_second': 1.606, 'eval_steps_per_second': 1.606, 'epoch': 2.0}
{'loss': 0.1486, 'grad_norm': 0.299193799495697, 'learning_rate': 4.190304744959541e-05, 'epoch': 2.06}
{'loss': 0.117, 'grad_norm': 0.33103838562965393, 'learning_rate': 4.175296371300428e-05, 'epoch': 2.15}
{'loss': 0.1236, 'grad_norm': 0.306710809469223, 'learning_rate': 4.1594643931793956e-05, 'epoch': 2.24}
{'loss': 0.117, 'grad_norm': 0.3283334970474243, 'learning_rate': 4.14281527248357e-05, 'epoch': 2.34}
{'loss': 0.1185, 'grad_norm': 0.3478241562843323, 'learning_rate': 4.125355804620184e-05, 'epoch': 2.43}
{'loss': 0.1097, 'grad_norm': 0.37700098752975464, 'learning_rate': 4.10709311574301e-05, 'epoch': 2.53}
{'loss': 0.0998, 'grad_norm': 0.4006405770778656, 'learning_rate': 4.0880346598437845e-05, 'epoch': 2.62}
{'loss': 0.1145, 'grad_norm': 0.3277304768562317, 'learning_rate': 4.068188215709837e-05, 'epoch': 2.71}
{'loss': 0.1284, 'grad_norm': 0.43333253264427185, 'learning_rate': 4.047561883749142e-05, 'epoch': 2.81}
{'loss': 0.1036, 'grad_norm': 0.38745009899139404, 'learning_rate': 4.0261640826841034e-05, 'epoch': 2.9}
{'loss': 0.1008, 'grad_norm': 0.4156542122364044, 'learning_rate': 4.004003546115422e-05, 'epoch': 3.0}
{'eval_loss': 0.6808770895004272, 'eval_runtime': 29.3679, 'eval_samples_per_second': 1.6, 'eval_steps_per_second': 1.6, 'epoch': 3.0}
{'loss': 0.0954, 'grad_norm': 0.4311348795890808, 'learning_rate': 3.981089318957435e-05, 'epoch': 3.08}
{'loss': 0.0784, 'grad_norm': 0.4073355793952942, 'learning_rate': 3.957430753746406e-05, 'epoch': 3.18}
{'loss': 0.0742, 'grad_norm': 0.44279745221138, 'learning_rate': 3.9330375068232357e-05, 'epoch': 3.27}
{'loss': 0.0885, 'grad_norm': 0.4988958239555359, 'learning_rate': 3.9079195343921983e-05, 'epoch': 3.37}
{'loss': 0.0817, 'grad_norm': 0.5015830397605896, 'learning_rate': 3.88208708845727e-05, 'epoch': 3.46}
{'loss': 0.0792, 'grad_norm': 0.5446687936782837, 'learning_rate': 3.855550712637732e-05, 'epoch': 3.55}
{'loss': 0.0682, 'grad_norm': 0.4457383155822754, 'learning_rate': 3.8283212378647504e-05, 'epoch': 3.65}
{'loss': 0.0758, 'grad_norm': 0.5522155165672302, 'learning_rate': 3.800409777960685e-05, 'epoch': 3.74}
{'loss': 0.0715, 'grad_norm': 0.5505671501159668, 'learning_rate': 3.771827725102937e-05, 'epoch': 3.84}
{'loss': 0.0667, 'grad_norm': 0.6313579678535461, 'learning_rate': 3.742586745174189e-05, 'epoch': 3.93}
{'eval_loss': 0.7567417025566101, 'eval_runtime': 30.4301, 'eval_samples_per_second': 1.545, 'eval_steps_per_second': 1.545, 'epoch': 4.0}
{'loss': 0.0691, 'grad_norm': 0.3221883177757263, 'learning_rate': 3.7126987730009176e-05, 'epoch': 4.02}
{'loss': 0.0459, 'grad_norm': 0.4355784058570862, 'learning_rate': 3.6821760074821576e-05, 'epoch': 4.11}
{'loss': 0.0412, 'grad_norm': 0.5759081244468689, 'learning_rate': 3.651030906610458e-05, 'epoch': 4.21}
{'loss': 0.0437, 'grad_norm': 0.6234626770019531, 'learning_rate': 3.619276182387111e-05, 'epoch': 4.3}
{'loss': 0.0431, 'grad_norm': 0.5890129208564758, 'learning_rate': 3.586924795633693e-05, 'epoch': 4.39}
{'loss': 0.0431, 'grad_norm': 0.5352630615234375, 'learning_rate': 3.553989950702047e-05, 'epoch': 4.49}
{'loss': 0.0366, 'grad_norm': 0.408562034368515, 'learning_rate': 3.520485090084881e-05, 'epoch': 4.58}
{'loss': 0.0366, 'grad_norm': 0.5204676389694214, 'learning_rate': 3.486423888929152e-05, 'epoch': 4.68}
{'loss': 0.0418, 'grad_norm': 0.6428789496421814, 'learning_rate': 3.4518202494544994e-05, 'epoch': 4.77}
{'loss': 0.0381, 'grad_norm': 0.7229369878768921, 'learning_rate': 3.416688295279003e-05, 'epoch': 4.86}
{'loss': 0.0379, 'grad_norm': 0.6848399043083191, 'learning_rate': 3.381042365654561e-05, 'epoch': 4.96}
{'eval_loss': 0.8437545299530029, 'eval_runtime': 26.9455, 'eval_samples_per_second': 1.744, 'eval_steps_per_second': 1.744, 'epoch': 5.0}
{'train_runtime': 3142.057, 'train_samples_per_second': 2.034, 'train_steps_per_second': 0.511, 'train_loss': 0.1489918096043239, 'epoch': 5.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 52.37 min
   Peak memory: 14.895 GB
   Training memory: 0.0 GB
================================================================================


================================================================================
‚úÖ TRIAL #13 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6388
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_bju1kgxg
[I 2025-11-03 05:41:36,029] Trial 13 finished with value: 0.6387943625450134 and parameters: {'num_epochs': 15, 'learning_rate': 4.3148404708166394e-05, 'weight_decay': 0.09384976079797068, 'batch_size': 1}. Best is trial 11 with value: 0.6387742757797241.

================================================================================
üî¨ OPTUNA TRIAL #14 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #14:
   ‚Ä¢ num_epochs:    15
   ‚Ä¢ learning_rate: 1.15e-05
   ‚Ä¢ weight_decay:  0.0943
   ‚Ä¢ batch_size:    1

‚è≥ Loading model for Trial #14...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_pd1wev5s
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #14...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 14.895 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 1, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.8134, 'grad_norm': 1.549511432647705, 'learning_rate': 2.0735881109413782e-06, 'epoch': 0.09}
{'loss': 0.7443, 'grad_norm': 0.9412777423858643, 'learning_rate': 4.377574900876243e-06, 'epoch': 0.19}
{'loss': 0.7118, 'grad_norm': 0.6361998319625854, 'learning_rate': 6.681561690811108e-06, 'epoch': 0.28}
{'loss': 0.6438, 'grad_norm': 0.4322910010814667, 'learning_rate': 8.985548480745974e-06, 'epoch': 0.38}
{'loss': 0.5651, 'grad_norm': 0.3470984101295471, 'learning_rate': 1.1289535270680837e-05, 'epoch': 0.47}
{'loss': 0.5258, 'grad_norm': 0.4402032196521759, 'learning_rate': 1.1518981807045e-05, 'epoch': 0.56}
{'loss': 0.4434, 'grad_norm': 0.4627718925476074, 'learning_rate': 1.1515690853942195e-05, 'epoch': 0.66}
{'loss': 0.3667, 'grad_norm': 0.44012579321861267, 'learning_rate': 1.151005067841484e-05, 'epoch': 0.75}
{'loss': 0.2738, 'grad_norm': 0.37962278723716736, 'learning_rate': 1.1502063582523823e-05, 'epoch': 0.85}
{'loss': 0.2353, 'grad_norm': 0.3268546164035797, 'learning_rate': 1.1491732826235252e-05, 'epoch': 0.94}
{'eval_loss': 0.8182870745658875, 'eval_runtime': 29.7453, 'eval_samples_per_second': 1.58, 'eval_steps_per_second': 1.58, 'epoch': 1.0}
{'loss': 0.2378, 'grad_norm': 0.25276580452919006, 'learning_rate': 1.1479062626089888e-05, 'epoch': 1.03}
{'loss': 0.1723, 'grad_norm': 0.19972674548625946, 'learning_rate': 1.146405815348214e-05, 'epoch': 1.12}
{'loss': 0.1816, 'grad_norm': 0.20465143024921417, 'learning_rate': 1.1446725532549348e-05, 'epoch': 1.22}
{'loss': 0.1953, 'grad_norm': 0.21187534928321838, 'learning_rate': 1.1427071837672185e-05, 'epoch': 1.31}
{'loss': 0.187, 'grad_norm': 0.17467312514781952, 'learning_rate': 1.1405105090587223e-05, 'epoch': 1.4}
{'loss': 0.1775, 'grad_norm': 0.18934045732021332, 'learning_rate': 1.1380834257112824e-05, 'epoch': 1.5}
{'loss': 0.1932, 'grad_norm': 0.2280646413564682, 'learning_rate': 1.1354269243489706e-05, 'epoch': 1.59}
{'loss': 0.1997, 'grad_norm': 0.2165517508983612, 'learning_rate': 1.1325420892337675e-05, 'epoch': 1.69}
{'loss': 0.1715, 'grad_norm': 0.1906638741493225, 'learning_rate': 1.1294300978230153e-05, 'epoch': 1.78}
{'loss': 0.1614, 'grad_norm': 0.1857125610113144, 'learning_rate': 1.1260922202888353e-05, 'epoch': 1.87}
{'loss': 0.1677, 'grad_norm': 0.21155782043933868, 'learning_rate': 1.1225298189997005e-05, 'epoch': 1.97}
{'eval_loss': 0.6974442005157471, 'eval_runtime': 25.8352, 'eval_samples_per_second': 1.819, 'eval_steps_per_second': 1.819, 'epoch': 2.0}
{'loss': 0.1943, 'grad_norm': 0.23615515232086182, 'learning_rate': 1.1187443479643807e-05, 'epoch': 2.06}
{'loss': 0.1628, 'grad_norm': 0.2057100534439087, 'learning_rate': 1.114737352238481e-05, 'epoch': 2.15}
{'loss': 0.1757, 'grad_norm': 0.2197769582271576, 'learning_rate': 1.1105104672938224e-05, 'epoch': 2.24}
{'loss': 0.1627, 'grad_norm': 0.21062630414962769, 'learning_rate': 1.1060654183509176e-05, 'epoch': 2.34}
{'loss': 0.1695, 'grad_norm': 0.21116484701633453, 'learning_rate': 1.1014040196748131e-05, 'epoch': 2.43}
{'loss': 0.1557, 'grad_norm': 0.1990984082221985, 'learning_rate': 1.0965281738345918e-05, 'epoch': 2.53}
{'loss': 0.1477, 'grad_norm': 0.22688502073287964, 'learning_rate': 1.0914398709268296e-05, 'epoch': 2.62}
{'loss': 0.1605, 'grad_norm': 0.18680907785892487, 'learning_rate': 1.0861411877633314e-05, 'epoch': 2.71}
{'loss': 0.1859, 'grad_norm': 0.2565450370311737, 'learning_rate': 1.0806342870234694e-05, 'epoch': 2.81}
{'loss': 0.1532, 'grad_norm': 0.20940500497817993, 'learning_rate': 1.0749214163714782e-05, 'epoch': 2.9}
{'loss': 0.154, 'grad_norm': 0.24992850422859192, 'learning_rate': 1.0690049075390616e-05, 'epoch': 3.0}
{'eval_loss': 0.6634402871131897, 'eval_runtime': 29.8975, 'eval_samples_per_second': 1.572, 'eval_steps_per_second': 1.572, 'epoch': 3.0}
{'loss': 0.1688, 'grad_norm': 0.22568048536777496, 'learning_rate': 1.062887175373685e-05, 'epoch': 3.08}
{'loss': 0.1511, 'grad_norm': 0.2257561832666397, 'learning_rate': 1.0565707168529477e-05, 'epoch': 3.18}
{'loss': 0.1422, 'grad_norm': 0.24702297151088715, 'learning_rate': 1.0500581100654288e-05, 'epoch': 3.27}
{'loss': 0.1679, 'grad_norm': 0.25538504123687744, 'learning_rate': 1.0433520131584318e-05, 'epoch': 3.37}
{'loss': 0.1623, 'grad_norm': 0.24897369742393494, 'learning_rate': 1.0364551632530496e-05, 'epoch': 3.46}
{'loss': 0.1589, 'grad_norm': 0.2403545379638672, 'learning_rate': 1.0293703753269979e-05, 'epoch': 3.55}
{'loss': 0.1412, 'grad_norm': 0.24315457046031952, 'learning_rate': 1.0221005410656699e-05, 'epoch': 3.65}
{'loss': 0.1535, 'grad_norm': 0.2632933259010315, 'learning_rate': 1.0146486276818836e-05, 'epoch': 3.74}
{'loss': 0.1492, 'grad_norm': 0.2619139552116394, 'learning_rate': 1.0070176767048007e-05, 'epoch': 3.84}
{'loss': 0.1422, 'grad_norm': 0.29473698139190674, 'learning_rate': 9.99210802738515e-06, 'epoch': 3.93}
{'eval_loss': 0.6482176184654236, 'eval_runtime': 26.2617, 'eval_samples_per_second': 1.79, 'eval_steps_per_second': 1.79, 'epoch': 4.0}
{'loss': 0.1491, 'grad_norm': 0.2221473753452301, 'learning_rate': 9.912311921908134e-06, 'epoch': 4.02}
{'loss': 0.1476, 'grad_norm': 0.25401777029037476, 'learning_rate': 9.830821019726305e-06, 'epoch': 4.11}
{'loss': 0.1442, 'grad_norm': 0.30230116844177246, 'learning_rate': 9.747668581687265e-06, 'epoch': 4.21}
{'loss': 0.1477, 'grad_norm': 0.30590593814849854, 'learning_rate': 9.66288854680133e-06, 'epoch': 4.3}
{'loss': 0.1525, 'grad_norm': 0.33202165365219116, 'learning_rate': 9.576515518389178e-06, 'epoch': 4.39}
{'loss': 0.1414, 'grad_norm': 0.28359878063201904, 'learning_rate': 9.488584749958354e-06, 'epoch': 4.49}
{'loss': 0.1234, 'grad_norm': 0.29530835151672363, 'learning_rate': 9.399132130814419e-06, 'epoch': 4.58}
{'loss': 0.133, 'grad_norm': 0.31886404752731323, 'learning_rate': 9.30819417141257e-06, 'epoch': 4.68}
{'loss': 0.1403, 'grad_norm': 0.3144283890724182, 'learning_rate': 9.215807988455757e-06, 'epoch': 4.77}
{'loss': 0.129, 'grad_norm': 0.32781147956848145, 'learning_rate': 9.122011289745338e-06, 'epoch': 4.86}
{'loss': 0.1312, 'grad_norm': 0.41446515917778015, 'learning_rate': 9.026842358790496e-06, 'epoch': 4.96}
{'eval_loss': 0.646587073802948, 'eval_runtime': 30.7282, 'eval_samples_per_second': 1.53, 'eval_steps_per_second': 1.53, 'epoch': 5.0}
{'loss': 0.1464, 'grad_norm': 0.3182426989078522, 'learning_rate': 8.930340039182654e-06, 'epoch': 5.05}
{'loss': 0.1409, 'grad_norm': 0.2950153648853302, 'learning_rate': 8.832543718741313e-06, 'epoch': 5.14}
{'loss': 0.1264, 'grad_norm': 0.36900264024734497, 'learning_rate': 8.733493313437747e-06, 'epoch': 5.23}
{'loss': 0.1205, 'grad_norm': 0.3474596440792084, 'learning_rate': 8.633229251103134e-06, 'epoch': 5.33}
{'loss': 0.126, 'grad_norm': 0.3341073989868164, 'learning_rate': 8.531792454927777e-06, 'epoch': 5.42}
{'loss': 0.1251, 'grad_norm': 0.3943842947483063, 'learning_rate': 8.42922432675812e-06, 'epoch': 5.52}
{'loss': 0.1313, 'grad_norm': 0.4148213565349579, 'learning_rate': 8.325566730198436e-06, 'epoch': 5.61}
{'loss': 0.1161, 'grad_norm': 0.35379576683044434, 'learning_rate': 8.220861973524e-06, 'epoch': 5.7}
{'loss': 0.1143, 'grad_norm': 0.4071404039859772, 'learning_rate': 8.11515279241281e-06, 'epoch': 5.8}
{'loss': 0.1258, 'grad_norm': 0.39412906765937805, 'learning_rate': 8.008482332502838e-06, 'epoch': 5.89}
{'loss': 0.1227, 'grad_norm': 0.36849290132522583, 'learning_rate': 7.900894131781958e-06, 'epoch': 5.99}
{'eval_loss': 0.6534728407859802, 'eval_runtime': 30.849, 'eval_samples_per_second': 1.524, 'eval_steps_per_second': 1.524, 'epoch': 6.0}
{'loss': 0.1378, 'grad_norm': 0.368111252784729, 'learning_rate': 7.792432102817737e-06, 'epoch': 6.08}
{'loss': 0.1206, 'grad_norm': 0.424292653799057, 'learning_rate': 7.683140514834346e-06, 'epoch': 6.17}
{'loss': 0.1213, 'grad_norm': 0.4393274188041687, 'learning_rate': 7.573063975643885e-06, 'epoch': 6.26}
{'loss': 0.1154, 'grad_norm': 0.46690335869789124, 'learning_rate': 7.4622474134395265e-06, 'epoch': 6.36}
{'loss': 0.103, 'grad_norm': 0.4221613109111786, 'learning_rate': 7.350736058457883e-06, 'epoch': 6.45}
{'loss': 0.1091, 'grad_norm': 0.4254143536090851, 'learning_rate': 7.23857542451811e-06, 'epoch': 6.54}
{'loss': 0.1012, 'grad_norm': 0.45218542218208313, 'learning_rate': 7.1258112904452375e-06, 'epoch': 6.64}
{'loss': 0.1051, 'grad_norm': 0.4373929798603058, 'learning_rate': 7.012489681385363e-06, 'epoch': 6.73}
{'loss': 0.1056, 'grad_norm': 0.44718626141548157, 'learning_rate': 6.898656850020307e-06, 'epoch': 6.83}
{'loss': 0.1196, 'grad_norm': 0.4958881735801697, 'learning_rate': 6.784359257689371e-06, 'epoch': 6.92}
{'eval_loss': 0.6761955618858337, 'eval_runtime': 30.2642, 'eval_samples_per_second': 1.553, 'eval_steps_per_second': 1.553, 'epoch': 7.0}
{'loss': 0.1232, 'grad_norm': 0.4011343717575073, 'learning_rate': 6.669643555425965e-06, 'epoch': 7.01}
{'loss': 0.0982, 'grad_norm': 0.5096284747123718, 'learning_rate': 6.554556564916788e-06, 'epoch': 7.1}
{'loss': 0.1123, 'grad_norm': 0.5341840386390686, 'learning_rate': 6.439145259391371e-06, 'epoch': 7.2}
{'loss': 0.095, 'grad_norm': 0.4971146583557129, 'learning_rate': 6.323456744449751e-06, 'epoch': 7.29}
{'loss': 0.1015, 'grad_norm': 0.5571047067642212, 'learning_rate': 6.207538238836136e-06, 'epoch': 7.38}
{'loss': 0.1068, 'grad_norm': 0.5027419328689575, 'learning_rate': 6.091437055166372e-06, 'epoch': 7.48}
{'loss': 0.0919, 'grad_norm': 0.49719300866127014, 'learning_rate': 5.975200580617105e-06, 'epoch': 7.57}
{'loss': 0.1001, 'grad_norm': 0.5121229887008667, 'learning_rate': 5.858876257584514e-06, 'epoch': 7.67}
{'loss': 0.0922, 'grad_norm': 0.5298234820365906, 'learning_rate': 5.742511564320496e-06, 'epoch': 7.76}
{'loss': 0.0946, 'grad_norm': 0.5318470597267151, 'learning_rate': 5.626153995554226e-06, 'epoch': 7.85}
{'loss': 0.0855, 'grad_norm': 0.6127946972846985, 'learning_rate': 5.509851043106985e-06, 'epoch': 7.95}
{'eval_loss': 0.7064788341522217, 'eval_runtime': 30.4515, 'eval_samples_per_second': 1.543, 'eval_steps_per_second': 1.543, 'epoch': 8.0}
{'train_runtime': 5053.9522, 'train_samples_per_second': 1.264, 'train_steps_per_second': 0.318, 'train_loss': 0.186534096565202, 'epoch': 8.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 84.23 min
   Peak memory: 14.895 GB
   Training memory: 0.0 GB
================================================================================


================================================================================
‚úÖ TRIAL #14 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6466
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_pd1wev5s
[I 2025-11-03 07:08:58,497] Trial 14 finished with value: 0.646587073802948 and parameters: {'num_epochs': 15, 'learning_rate': 1.1519933949674324e-05, 'weight_decay': 0.0942753698420735, 'batch_size': 1}. Best is trial 11 with value: 0.6387742757797241.

================================================================================
üî¨ OPTUNA TRIAL #15 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #15:
   ‚Ä¢ num_epochs:    14
   ‚Ä¢ learning_rate: 3.23e-05
   ‚Ä¢ weight_decay:  0.0867
   ‚Ä¢ batch_size:    1

‚è≥ Loading model for Trial #15...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_wvcwfdzv
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #15...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 14.895 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 1, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.8048, 'grad_norm': 1.266374945640564, 'learning_rate': 5.810982271185819e-06, 'epoch': 0.09}
{'loss': 0.6882, 'grad_norm': 0.533470630645752, 'learning_rate': 1.2267629239170065e-05, 'epoch': 0.19}
{'loss': 0.6224, 'grad_norm': 0.4804515540599823, 'learning_rate': 1.8724276207154305e-05, 'epoch': 0.28}
{'loss': 0.5141, 'grad_norm': 0.3796459436416626, 'learning_rate': 2.5180923175138554e-05, 'epoch': 0.38}
{'loss': 0.3768, 'grad_norm': 0.4043276607990265, 'learning_rate': 3.163757014312279e-05, 'epoch': 0.47}
{'loss': 0.2634, 'grad_norm': 0.29765889048576355, 'learning_rate': 3.2280157674132366e-05, 'epoch': 0.56}
{'loss': 0.2149, 'grad_norm': 0.26305636763572693, 'learning_rate': 3.226952206407213e-05, 'epoch': 0.66}
{'loss': 0.2071, 'grad_norm': 0.21030034124851227, 'learning_rate': 3.225129502504486e-05, 'epoch': 0.75}
{'loss': 0.1666, 'grad_norm': 0.2587830126285553, 'learning_rate': 3.222548513654524e-05, 'epoch': 0.85}
{'loss': 0.1689, 'grad_norm': 0.22248081862926483, 'learning_rate': 3.21921045473266e-05, 'epoch': 0.94}
{'eval_loss': 0.691041111946106, 'eval_runtime': 29.3368, 'eval_samples_per_second': 1.602, 'eval_steps_per_second': 1.602, 'epoch': 1.0}
{'loss': 0.1853, 'grad_norm': 0.17280223965644836, 'learning_rate': 3.215116896968246e-05, 'epoch': 1.03}
{'loss': 0.1393, 'grad_norm': 0.21515433490276337, 'learning_rate': 3.210269767205079e-05, 'epoch': 1.12}
{'loss': 0.1564, 'grad_norm': 0.2114560604095459, 'learning_rate': 3.204671346994427e-05, 'epoch': 1.22}
{'loss': 0.1689, 'grad_norm': 0.2268054485321045, 'learning_rate': 3.198324271521101e-05, 'epoch': 1.31}
{'loss': 0.1648, 'grad_norm': 0.1790526658296585, 'learning_rate': 3.191231528363069e-05, 'epoch': 1.4}
{'loss': 0.1547, 'grad_norm': 0.21103878319263458, 'learning_rate': 3.183396456085202e-05, 'epoch': 1.5}
{'loss': 0.1692, 'grad_norm': 0.2654906213283539, 'learning_rate': 3.1748227426678017e-05, 'epoch': 1.59}
{'loss': 0.173, 'grad_norm': 0.23203526437282562, 'learning_rate': 3.1655144237706666e-05, 'epoch': 1.69}
{'loss': 0.1489, 'grad_norm': 0.23656171560287476, 'learning_rate': 3.1554758808334976e-05, 'epoch': 1.78}
{'loss': 0.1382, 'grad_norm': 0.23886042833328247, 'learning_rate': 3.14471183901355e-05, 'epoch': 1.87}
{'loss': 0.1442, 'grad_norm': 0.2778514623641968, 'learning_rate': 3.133227364961495e-05, 'epoch': 1.97}
{'eval_loss': 0.6446331143379211, 'eval_runtime': 29.2415, 'eval_samples_per_second': 1.607, 'eval_steps_per_second': 1.607, 'epoch': 2.0}
{'loss': 0.1617, 'grad_norm': 0.25893348455429077, 'learning_rate': 3.1210278644365354e-05, 'epoch': 2.06}
{'loss': 0.1299, 'grad_norm': 0.2839318513870239, 'learning_rate': 3.108119079761914e-05, 'epoch': 2.15}
{'loss': 0.1385, 'grad_norm': 0.27992790937423706, 'learning_rate': 3.0945070871219886e-05, 'epoch': 2.24}
{'loss': 0.1302, 'grad_norm': 0.29730451107025146, 'learning_rate': 3.0801982937021604e-05, 'epoch': 2.34}
{'loss': 0.1338, 'grad_norm': 0.2982296645641327, 'learning_rate': 3.06519943467301e-05, 'epoch': 2.43}
{'loss': 0.1227, 'grad_norm': 0.31344977021217346, 'learning_rate': 3.0495175700200335e-05, 'epoch': 2.53}
{'loss': 0.1136, 'grad_norm': 0.33496353030204773, 'learning_rate': 3.033160081220506e-05, 'epoch': 2.62}
{'loss': 0.1277, 'grad_norm': 0.30039674043655396, 'learning_rate': 3.016134667769e-05, 'epoch': 2.71}
{'loss': 0.145, 'grad_norm': 0.38202571868896484, 'learning_rate': 2.9984493435532274e-05, 'epoch': 2.81}
{'loss': 0.1171, 'grad_norm': 0.3370072841644287, 'learning_rate': 2.980112433081891e-05, 'epoch': 2.9}
{'loss': 0.1153, 'grad_norm': 0.37571850419044495, 'learning_rate': 2.9611325675663204e-05, 'epoch': 3.0}
{'eval_loss': 0.6553742289543152, 'eval_runtime': 25.7623, 'eval_samples_per_second': 1.824, 'eval_steps_per_second': 1.824, 'epoch': 3.0}
{'loss': 0.1158, 'grad_norm': 0.4163215756416321, 'learning_rate': 2.9415186808577554e-05, 'epoch': 3.08}
{'loss': 0.0987, 'grad_norm': 0.3669576644897461, 'learning_rate': 2.921280005242161e-05, 'epoch': 3.18}
{'loss': 0.0932, 'grad_norm': 0.4276622235774994, 'learning_rate': 2.9004260670945823e-05, 'epoch': 3.27}
{'loss': 0.1103, 'grad_norm': 0.47415396571159363, 'learning_rate': 2.8789666823950625e-05, 'epoch': 3.37}
{'loss': 0.1036, 'grad_norm': 0.49435269832611084, 'learning_rate': 2.856911952108248e-05, 'epoch': 3.46}
{'loss': 0.1018, 'grad_norm': 0.4951464533805847, 'learning_rate': 2.8342722574288473e-05, 'epoch': 3.55}
{'loss': 0.0876, 'grad_norm': 0.4409915506839752, 'learning_rate': 2.8110582548951888e-05, 'epoch': 3.65}
{'loss': 0.097, 'grad_norm': 0.5841251611709595, 'learning_rate': 2.7872808713731717e-05, 'epoch': 3.74}
{'loss': 0.0915, 'grad_norm': 0.572134792804718, 'learning_rate': 2.7629512989129727e-05, 'epoch': 3.84}
{'loss': 0.0854, 'grad_norm': 0.597839891910553, 'learning_rate': 2.7380809894809327e-05, 'epoch': 3.93}
{'eval_loss': 0.7035613656044006, 'eval_runtime': 29.5713, 'eval_samples_per_second': 1.589, 'eval_steps_per_second': 1.589, 'epoch': 4.0}
{'loss': 0.0891, 'grad_norm': 0.3768240809440613, 'learning_rate': 2.7126816495690975e-05, 'epoch': 4.02}
{'loss': 0.0681, 'grad_norm': 0.45149388909339905, 'learning_rate': 2.6867652346849562e-05, 'epoch': 4.11}
{'loss': 0.0635, 'grad_norm': 0.6139970421791077, 'learning_rate': 2.660343943723965e-05, 'epoch': 4.21}
{'loss': 0.0664, 'grad_norm': 0.6271629333496094, 'learning_rate': 2.633430213227508e-05, 'epoch': 4.3}
{'loss': 0.0659, 'grad_norm': 0.6649997234344482, 'learning_rate': 2.6060367115289988e-05, 'epoch': 4.39}
{'loss': 0.0648, 'grad_norm': 0.549643874168396, 'learning_rate': 2.578176332790877e-05, 'epoch': 4.49}
{'loss': 0.0562, 'grad_norm': 0.4521996080875397, 'learning_rate': 2.549862190935309e-05, 'epoch': 4.58}
{'loss': 0.0564, 'grad_norm': 0.601527750492096, 'learning_rate': 2.5211076134714404e-05, 'epoch': 4.68}
{'loss': 0.0641, 'grad_norm': 0.692700982093811, 'learning_rate': 2.4919261352221216e-05, 'epoch': 4.77}
{'loss': 0.0573, 'grad_norm': 0.685766339302063, 'learning_rate': 2.462331491953043e-05, 'epoch': 4.86}
{'loss': 0.057, 'grad_norm': 0.84830641746521, 'learning_rate': 2.4323376139072923e-05, 'epoch': 4.96}
{'eval_loss': 0.7810462117195129, 'eval_runtime': 28.6916, 'eval_samples_per_second': 1.638, 'eval_steps_per_second': 1.638, 'epoch': 5.0}
{'train_runtime': 3152.9588, 'train_samples_per_second': 1.892, 'train_steps_per_second': 0.475, 'train_loss': 0.16697891872619913, 'epoch': 5.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 52.55 min
   Peak memory: 14.895 GB
   Training memory: 0.0 GB
================================================================================


================================================================================
‚úÖ TRIAL #15 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6446
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_wvcwfdzv
[I 2025-11-03 08:02:24,474] Trial 15 finished with value: 0.6446331143379211 and parameters: {'num_epochs': 14, 'learning_rate': 3.228323483992122e-05, 'weight_decay': 0.0867009187641963, 'batch_size': 1}. Best is trial 11 with value: 0.6387742757797241.

================================================================================
üî¨ OPTUNA TRIAL #16 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #16:
   ‚Ä¢ num_epochs:    15
   ‚Ä¢ learning_rate: 7.07e-05
   ‚Ä¢ weight_decay:  0.0802
   ‚Ä¢ batch_size:    1

‚è≥ Loading model for Trial #16...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_nwffm1jp
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #16...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 14.895 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 1, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.7868, 'grad_norm': 0.844560444355011, 'learning_rate': 1.272821404644306e-05, 'epoch': 0.09}
{'loss': 0.6294, 'grad_norm': 0.39806392788887024, 'learning_rate': 2.687067409804646e-05, 'epoch': 0.19}
{'loss': 0.5223, 'grad_norm': 0.43646806478500366, 'learning_rate': 4.101313414964986e-05, 'epoch': 0.28}
{'loss': 0.3282, 'grad_norm': 0.31958073377609253, 'learning_rate': 5.515559420125326e-05, 'epoch': 0.38}
{'loss': 0.2142, 'grad_norm': 0.22484898567199707, 'learning_rate': 6.929805425285666e-05, 'epoch': 0.47}
{'loss': 0.1943, 'grad_norm': 0.18246908485889435, 'learning_rate': 7.070645576309303e-05, 'epoch': 0.56}
{'loss': 0.1833, 'grad_norm': 0.19684633612632751, 'learning_rate': 7.068625505144338e-05, 'epoch': 0.66}
{'loss': 0.1878, 'grad_norm': 0.1949039250612259, 'learning_rate': 7.065163421184997e-05, 'epoch': 0.75}
{'loss': 0.1514, 'grad_norm': 0.21850065886974335, 'learning_rate': 7.060260737495121e-05, 'epoch': 0.85}
{'loss': 0.1565, 'grad_norm': 0.209952250123024, 'learning_rate': 7.053919455125264e-05, 'epoch': 0.94}
{'eval_loss': 0.6565765142440796, 'eval_runtime': 30.228, 'eval_samples_per_second': 1.555, 'eval_steps_per_second': 1.555, 'epoch': 1.0}
{'loss': 0.1675, 'grad_norm': 0.18204079568386078, 'learning_rate': 7.046142162295964e-05, 'epoch': 1.03}
{'loss': 0.1236, 'grad_norm': 0.2188633233308792, 'learning_rate': 7.036932033341342e-05, 'epoch': 1.12}
{'loss': 0.1378, 'grad_norm': 0.23424026370048523, 'learning_rate': 7.026292827413494e-05, 'epoch': 1.22}
{'loss': 0.1468, 'grad_norm': 0.27085253596305847, 'learning_rate': 7.01422888694817e-05, 'epoch': 1.31}
{'loss': 0.1444, 'grad_norm': 0.2186078280210495, 'learning_rate': 7.000745135892395e-05, 'epoch': 1.4}
{'loss': 0.1343, 'grad_norm': 0.22343164682388306, 'learning_rate': 6.985847077694738e-05, 'epoch': 1.5}
{'loss': 0.146, 'grad_norm': 0.30479660630226135, 'learning_rate': 6.969540793059058e-05, 'epoch': 1.59}
{'loss': 0.1482, 'grad_norm': 0.283084899187088, 'learning_rate': 6.951832937462639e-05, 'epoch': 1.69}
{'loss': 0.1269, 'grad_norm': 0.2720310389995575, 'learning_rate': 6.932730738439728e-05, 'epoch': 1.78}
{'loss': 0.115, 'grad_norm': 0.30591121315956116, 'learning_rate': 6.91224199263159e-05, 'epoch': 1.87}
{'loss': 0.122, 'grad_norm': 0.3398323655128479, 'learning_rate': 6.890375062604273e-05, 'epoch': 1.97}
{'eval_loss': 0.6444246768951416, 'eval_runtime': 26.2415, 'eval_samples_per_second': 1.791, 'eval_steps_per_second': 1.791, 'epoch': 2.0}
{'loss': 0.1247, 'grad_norm': 0.3033086955547333, 'learning_rate': 6.867138873435399e-05, 'epoch': 2.06}
{'loss': 0.0938, 'grad_norm': 0.3399101793766022, 'learning_rate': 6.842542909071346e-05, 'epoch': 2.15}
{'loss': 0.0983, 'grad_norm': 0.3439224362373352, 'learning_rate': 6.816597208456351e-05, 'epoch': 2.24}
{'loss': 0.0941, 'grad_norm': 0.3683812916278839, 'learning_rate': 6.789312361435058e-05, 'epoch': 2.34}
{'loss': 0.0922, 'grad_norm': 0.37520909309387207, 'learning_rate': 6.760699504430236e-05, 'epoch': 2.43}
{'loss': 0.0876, 'grad_norm': 0.4008624851703644, 'learning_rate': 6.730770315897407e-05, 'epoch': 2.53}
{'loss': 0.0773, 'grad_norm': 0.4113729000091553, 'learning_rate': 6.699537011558228e-05, 'epoch': 2.62}
{'loss': 0.0921, 'grad_norm': 0.32492393255233765, 'learning_rate': 6.667012339414601e-05, 'epoch': 2.71}
{'loss': 0.1015, 'grad_norm': 0.4720371961593628, 'learning_rate': 6.633209574545517e-05, 'epoch': 2.81}
{'loss': 0.0808, 'grad_norm': 0.38643184304237366, 'learning_rate': 6.598142513688782e-05, 'epoch': 2.9}
{'loss': 0.0757, 'grad_norm': 0.43066152930259705, 'learning_rate': 6.56182546960982e-05, 'epoch': 3.0}
{'eval_loss': 0.7406365275382996, 'eval_runtime': 29.9309, 'eval_samples_per_second': 1.57, 'eval_steps_per_second': 1.57, 'epoch': 3.0}
{'loss': 0.0633, 'grad_norm': 0.3822661340236664, 'learning_rate': 6.524273265259858e-05, 'epoch': 3.08}
{'loss': 0.0501, 'grad_norm': 0.3512381911277771, 'learning_rate': 6.485501227725881e-05, 'epoch': 3.18}
{'loss': 0.048, 'grad_norm': 0.4233730137348175, 'learning_rate': 6.445525181974816e-05, 'epoch': 3.27}
{'loss': 0.0572, 'grad_norm': 0.46091732382774353, 'learning_rate': 6.404361444394503e-05, 'epoch': 3.37}
{'loss': 0.0509, 'grad_norm': 0.4550335705280304, 'learning_rate': 6.3620268161341e-05, 'epoch': 3.46}
{'loss': 0.0498, 'grad_norm': 0.4611856937408447, 'learning_rate': 6.318538576246623e-05, 'epoch': 3.55}
{'loss': 0.0432, 'grad_norm': 0.40832510590553284, 'learning_rate': 6.273914474636424e-05, 'epoch': 3.65}
{'loss': 0.0468, 'grad_norm': 0.5356378555297852, 'learning_rate': 6.228172724814504e-05, 'epoch': 3.74}
{'loss': 0.0452, 'grad_norm': 0.41126692295074463, 'learning_rate': 6.181331996464586e-05, 'epoch': 3.84}
{'loss': 0.0417, 'grad_norm': 0.5823293924331665, 'learning_rate': 6.133411407823009e-05, 'epoch': 3.93}
{'eval_loss': 0.8044417500495911, 'eval_runtime': 29.6422, 'eval_samples_per_second': 1.586, 'eval_steps_per_second': 1.586, 'epoch': 4.0}
{'loss': 0.0419, 'grad_norm': 0.19658589363098145, 'learning_rate': 6.084430517875539e-05, 'epoch': 4.02}
{'loss': 0.0219, 'grad_norm': 0.27763471007347107, 'learning_rate': 6.0344093183742945e-05, 'epoch': 4.11}
{'loss': 0.0203, 'grad_norm': 0.3695202171802521, 'learning_rate': 5.983368225678021e-05, 'epoch': 4.21}
{'loss': 0.0206, 'grad_norm': 0.3784036636352539, 'learning_rate': 5.9313280724190793e-05, 'epoch': 4.3}
{'loss': 0.0204, 'grad_norm': 0.3950432538986206, 'learning_rate': 5.8783100990005166e-05, 'epoch': 4.39}
{'loss': 0.0209, 'grad_norm': 0.3468416929244995, 'learning_rate': 5.824335944926705e-05, 'epoch': 4.49}
{'loss': 0.0179, 'grad_norm': 0.2340746372938156, 'learning_rate': 5.7694276399710947e-05, 'epoch': 4.58}
{'loss': 0.0161, 'grad_norm': 0.3318512439727783, 'learning_rate': 5.7136075951846696e-05, 'epoch': 4.68}
{'loss': 0.0193, 'grad_norm': 0.4605942964553833, 'learning_rate': 5.65689859374878e-05, 'epoch': 4.77}
{'loss': 0.0181, 'grad_norm': 0.42120498418807983, 'learning_rate': 5.5993237816761005e-05, 'epoch': 4.86}
{'loss': 0.0175, 'grad_norm': 0.4537600874900818, 'learning_rate': 5.540906658363483e-05, 'epoch': 4.96}
{'eval_loss': 0.8868401050567627, 'eval_runtime': 30.0371, 'eval_samples_per_second': 1.565, 'eval_steps_per_second': 1.565, 'epoch': 5.0}
{'train_runtime': 3140.1107, 'train_samples_per_second': 2.035, 'train_steps_per_second': 0.511, 'train_loss': 0.12384426990680605, 'epoch': 5.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 52.34 min
   Peak memory: 15.695 GB
   Training memory: 0.8 GB
================================================================================


================================================================================
‚úÖ TRIAL #16 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6444
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_nwffm1jp
[I 2025-11-03 08:56:40,771] Trial 16 finished with value: 0.6444246768951416 and parameters: {'num_epochs': 15, 'learning_rate': 7.0712300258017e-05, 'weight_decay': 0.0802052457175604, 'batch_size': 1}. Best is trial 11 with value: 0.6387742757797241.

================================================================================
üî¨ OPTUNA TRIAL #17 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #17:
   ‚Ä¢ num_epochs:    12
   ‚Ä¢ learning_rate: 4.07e-05
   ‚Ä¢ weight_decay:  0.0595
   ‚Ä¢ batch_size:    1

‚è≥ Loading model for Trial #17...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_ppykzwrn
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #17...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 15.695 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 1, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.8021, 'grad_norm': 1.1680972576141357, 'learning_rate': 7.3232547221547145e-06, 'epoch': 0.09}
{'loss': 0.6739, 'grad_norm': 0.9788693785667419, 'learning_rate': 1.5460204413437733e-05, 'epoch': 0.19}
{'loss': 0.6004, 'grad_norm': 0.5932270288467407, 'learning_rate': 2.3597154104720746e-05, 'epoch': 0.28}
{'loss': 0.4732, 'grad_norm': 0.4265197217464447, 'learning_rate': 3.1734103796003766e-05, 'epoch': 0.38}
{'loss': 0.315, 'grad_norm': 0.3050568997859955, 'learning_rate': 3.987105348728678e-05, 'epoch': 0.47}
{'loss': 0.2286, 'grad_norm': 0.23765034973621368, 'learning_rate': 4.067940887652814e-05, 'epoch': 0.56}
{'loss': 0.198, 'grad_norm': 0.2021387815475464, 'learning_rate': 4.0660954668272603e-05, 'epoch': 0.66}
{'loss': 0.1996, 'grad_norm': 0.20002534985542297, 'learning_rate': 4.062933186834173e-05, 'epoch': 0.75}
{'loss': 0.1618, 'grad_norm': 0.23942552506923676, 'learning_rate': 4.058456097165845e-05, 'epoch': 0.85}
{'loss': 0.1653, 'grad_norm': 0.21613885462284088, 'learning_rate': 4.0526670994504627e-05, 'epoch': 0.94}
{'eval_loss': 0.6800723671913147, 'eval_runtime': 29.4622, 'eval_samples_per_second': 1.595, 'eval_steps_per_second': 1.595, 'epoch': 1.0}
{'loss': 0.1805, 'grad_norm': 0.1812603771686554, 'learning_rate': 4.0455699455715466e-05, 'epoch': 1.03}
{'loss': 0.1351, 'grad_norm': 0.19383735954761505, 'learning_rate': 4.037169235236336e-05, 'epoch': 1.12}
{'loss': 0.1515, 'grad_norm': 0.22016482055187225, 'learning_rate': 4.027470412994683e-05, 'epoch': 1.22}
{'loss': 0.163, 'grad_norm': 0.2394097000360489, 'learning_rate': 4.0164797647104166e-05, 'epoch': 1.31}
{'loss': 0.1595, 'grad_norm': 0.19098453223705292, 'learning_rate': 4.0042044134874345e-05, 'epoch': 1.4}
{'loss': 0.149, 'grad_norm': 0.22095920145511627, 'learning_rate': 3.9906523150531745e-05, 'epoch': 1.5}
{'loss': 0.1629, 'grad_norm': 0.26843830943107605, 'learning_rate': 3.975832252602465e-05, 'epoch': 1.59}
{'loss': 0.1665, 'grad_norm': 0.24598374962806702, 'learning_rate': 3.9597538311050806e-05, 'epoch': 1.69}
{'loss': 0.1431, 'grad_norm': 0.25535300374031067, 'learning_rate': 3.942427471080709e-05, 'epoch': 1.78}
{'loss': 0.1322, 'grad_norm': 0.2523808181285858, 'learning_rate': 3.923864401845348e-05, 'epoch': 1.87}
{'loss': 0.1382, 'grad_norm': 0.3032223880290985, 'learning_rate': 3.904076654233519e-05, 'epoch': 1.97}
{'eval_loss': 0.6394837498664856, 'eval_runtime': 29.59, 'eval_samples_per_second': 1.588, 'eval_steps_per_second': 1.588, 'epoch': 2.0}
{'loss': 0.152, 'grad_norm': 0.27394047379493713, 'learning_rate': 3.883077052801014e-05, 'epoch': 2.06}
{'loss': 0.1201, 'grad_norm': 0.32072553038597107, 'learning_rate': 3.860879207513226e-05, 'epoch': 2.15}
{'loss': 0.1272, 'grad_norm': 0.3062712550163269, 'learning_rate': 3.83749750492445e-05, 'epoch': 2.24}
{'loss': 0.1204, 'grad_norm': 0.32254818081855774, 'learning_rate': 3.812947098853867e-05, 'epoch': 2.34}
{'loss': 0.1224, 'grad_norm': 0.3307148516178131, 'learning_rate': 3.7872439005642744e-05, 'epoch': 2.43}
{'loss': 0.1129, 'grad_norm': 0.42088642716407776, 'learning_rate': 3.7604045684498943e-05, 'epoch': 2.53}
{'loss': 0.1031, 'grad_norm': 0.3815183639526367, 'learning_rate': 3.732446497239975e-05, 'epoch': 2.62}
{'loss': 0.1176, 'grad_norm': 0.3243463635444641, 'learning_rate': 3.7033878067251615e-05, 'epoch': 2.71}
{'loss': 0.1324, 'grad_norm': 0.4243606626987457, 'learning_rate': 3.673247330013955e-05, 'epoch': 2.81}
{'loss': 0.1064, 'grad_norm': 0.3822450041770935, 'learning_rate': 3.6420446013268636e-05, 'epoch': 2.9}
{'loss': 0.1041, 'grad_norm': 0.4157068729400635, 'learning_rate': 3.6097998433361565e-05, 'epoch': 3.0}
{'eval_loss': 0.6744219660758972, 'eval_runtime': 29.5971, 'eval_samples_per_second': 1.588, 'eval_steps_per_second': 1.588, 'epoch': 3.0}
{'loss': 0.0995, 'grad_norm': 0.45693540573120117, 'learning_rate': 3.5765339540594345e-05, 'epoch': 3.08}
{'loss': 0.0825, 'grad_norm': 0.40086629986763, 'learning_rate': 3.542268493315499e-05, 'epoch': 3.18}
{'loss': 0.0783, 'grad_norm': 0.4586373269557953, 'learning_rate': 3.5070256687513084e-05, 'epoch': 3.27}
{'loss': 0.0934, 'grad_norm': 0.4967304468154907, 'learning_rate': 3.4708283214490705e-05, 'epoch': 3.37}
{'loss': 0.0868, 'grad_norm': 0.49220964312553406, 'learning_rate': 3.433699911122802e-05, 'epoch': 3.46}
{'loss': 0.0844, 'grad_norm': 0.5381214022636414, 'learning_rate': 3.39566450091395e-05, 'epoch': 3.55}
{'loss': 0.0725, 'grad_norm': 0.44694095849990845, 'learning_rate': 3.35674674179593e-05, 'epoch': 3.65}
{'loss': 0.081, 'grad_norm': 0.6004320383071899, 'learning_rate': 3.316971856597681e-05, 'epoch': 3.74}
{'loss': 0.0755, 'grad_norm': 0.54863041639328, 'learning_rate': 3.276365623656605e-05, 'epoch': 3.84}
{'loss': 0.0706, 'grad_norm': 0.6424161791801453, 'learning_rate': 3.234954360111472e-05, 'epoch': 3.93}
{'eval_loss': 0.7397021651268005, 'eval_runtime': 29.4694, 'eval_samples_per_second': 1.595, 'eval_steps_per_second': 1.595, 'epoch': 4.0}
{'loss': 0.0732, 'grad_norm': 0.3708529472351074, 'learning_rate': 3.1927649048461326e-05, 'epoch': 4.02}
{'loss': 0.0508, 'grad_norm': 0.4622706174850464, 'learning_rate': 3.149824601095071e-05, 'epoch': 4.11}
{'loss': 0.0461, 'grad_norm': 0.5949918627738953, 'learning_rate': 3.1061612787221e-05, 'epoch': 4.21}
{'loss': 0.049, 'grad_norm': 0.6024739146232605, 'learning_rate': 3.0618032361836596e-05, 'epoch': 4.3}
{'loss': 0.0478, 'grad_norm': 0.6449071764945984, 'learning_rate': 3.0167792221884232e-05, 'epoch': 4.39}
{'loss': 0.0479, 'grad_norm': 0.5218377709388733, 'learning_rate': 2.9711184170650865e-05, 'epoch': 4.49}
{'loss': 0.0404, 'grad_norm': 0.4260753095149994, 'learning_rate': 2.924850413850428e-05, 'epoch': 4.58}
{'loss': 0.0395, 'grad_norm': 0.5326390266418457, 'learning_rate': 2.878005199109885e-05, 'epoch': 4.68}
{'loss': 0.0465, 'grad_norm': 0.7138842344284058, 'learning_rate': 2.830613133503085e-05, 'epoch': 4.77}
{'loss': 0.0417, 'grad_norm': 0.6930046081542969, 'learning_rate': 2.782704932106925e-05, 'epoch': 4.86}
{'loss': 0.0414, 'grad_norm': 0.7288592457771301, 'learning_rate': 2.7343116445089437e-05, 'epoch': 4.96}
{'eval_loss': 0.8240086436271667, 'eval_runtime': 29.009, 'eval_samples_per_second': 1.62, 'eval_steps_per_second': 1.62, 'epoch': 5.0}
{'train_runtime': 3150.1124, 'train_samples_per_second': 1.623, 'train_steps_per_second': 0.408, 'train_loss': 0.15309407839151187, 'epoch': 5.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 52.5 min
   Peak memory: 15.852 GB
   Training memory: 0.157 GB
================================================================================


================================================================================
‚úÖ TRIAL #17 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6395
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_ppykzwrn
[I 2025-11-03 09:52:17,969] Trial 17 finished with value: 0.6394837498664856 and parameters: {'num_epochs': 12, 'learning_rate': 4.068474845641508e-05, 'weight_decay': 0.059471768249325874, 'batch_size': 1}. Best is trial 11 with value: 0.6387742757797241.

================================================================================
üî¨ OPTUNA TRIAL #18 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #18:
   ‚Ä¢ num_epochs:    13
   ‚Ä¢ learning_rate: 1.36e-05
   ‚Ä¢ weight_decay:  0.0020
   ‚Ä¢ batch_size:    2

‚è≥ Loading model for Trial #18...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_tgpl4kkt
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #18...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 15.852 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 2, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.7934, 'grad_norm': 1.500127911567688, 'learning_rate': 2.4492918620994475e-06, 'epoch': 0.19}
{'loss': 0.7664, 'grad_norm': 0.8340839743614197, 'learning_rate': 5.170727264432167e-06, 'epoch': 0.38}
{'loss': 0.6732, 'grad_norm': 0.49035149812698364, 'learning_rate': 7.892162666764886e-06, 'epoch': 0.56}
{'loss': 0.6184, 'grad_norm': 0.4121387004852295, 'learning_rate': 1.0613598069097606e-05, 'epoch': 0.75}
{'loss': 0.5571, 'grad_norm': 0.5676159262657166, 'learning_rate': 1.3335033471430326e-05, 'epoch': 0.94}
{'eval_loss': 1.8865599632263184, 'eval_runtime': 20.6517, 'eval_samples_per_second': 2.276, 'eval_steps_per_second': 1.162, 'epoch': 1.0}
{'loss': 0.6185, 'grad_norm': 0.5281093716621399, 'learning_rate': 1.3600780700914365e-05, 'epoch': 1.11}
{'loss': 0.3696, 'grad_norm': 0.4371922016143799, 'learning_rate': 1.3578685437277721e-05, 'epoch': 1.3}
{'loss': 0.2924, 'grad_norm': 0.33939969539642334, 'learning_rate': 1.3540863530197361e-05, 'epoch': 1.49}
{'loss': 0.2531, 'grad_norm': 0.19813653826713562, 'learning_rate': 1.3487402773494246e-05, 'epoch': 1.68}
{'loss': 0.2067, 'grad_norm': 0.18923264741897583, 'learning_rate': 1.3418427262552906e-05, 'epoch': 1.86}
{'eval_loss': 0.7812379002571106, 'eval_runtime': 19.8705, 'eval_samples_per_second': 2.365, 'eval_steps_per_second': 1.208, 'epoch': 2.0}
{'loss': 0.2561, 'grad_norm': 0.19098688662052155, 'learning_rate': 1.3334097106265935e-05, 'epoch': 2.04}
{'loss': 0.1876, 'grad_norm': 0.17285442352294922, 'learning_rate': 1.323460805538242e-05, 'epoch': 2.23}
{'loss': 0.1836, 'grad_norm': 0.1401473730802536, 'learning_rate': 1.312019104812297e-05, 'epoch': 2.41}
{'loss': 0.17, 'grad_norm': 0.14183135330677032, 'learning_rate': 1.2991111674116087e-05, 'epoch': 2.6}
{'loss': 0.1861, 'grad_norm': 0.14319172501564026, 'learning_rate': 1.2847669557900201e-05, 'epoch': 2.79}
{'loss': 0.1729, 'grad_norm': 0.16145068407058716, 'learning_rate': 1.2690197663422457e-05, 'epoch': 2.98}
{'eval_loss': 0.7262905836105347, 'eval_runtime': 19.4594, 'eval_samples_per_second': 2.415, 'eval_steps_per_second': 1.233, 'epoch': 3.0}
{'loss': 0.2436, 'grad_norm': 0.13898037374019623, 'learning_rate': 1.2519061521148602e-05, 'epoch': 3.15}
{'loss': 0.1697, 'grad_norm': 0.14041636884212494, 'learning_rate': 1.233465837957812e-05, 'epoch': 3.34}
{'loss': 0.1854, 'grad_norm': 0.13589169085025787, 'learning_rate': 1.21374162831341e-05, 'epoch': 3.53}
{'loss': 0.1633, 'grad_norm': 0.1315549910068512, 'learning_rate': 1.1927793078568291e-05, 'epoch': 3.71}
{'loss': 0.1644, 'grad_norm': 0.1526729017496109, 'learning_rate': 1.170627535218774e-05, 'epoch': 3.9}
{'eval_loss': 0.7015796303749084, 'eval_runtime': 19.9603, 'eval_samples_per_second': 2.355, 'eval_steps_per_second': 1.202, 'epoch': 4.0}
{'loss': 0.2066, 'grad_norm': 0.18634851276874542, 'learning_rate': 1.1473377300369926e-05, 'epoch': 4.08}
{'loss': 0.1642, 'grad_norm': 0.1377151757478714, 'learning_rate': 1.1229639535988253e-05, 'epoch': 4.26}
{'loss': 0.1709, 'grad_norm': 0.15532876551151276, 'learning_rate': 1.097562783351842e-05, 'epoch': 4.45}
{'loss': 0.1537, 'grad_norm': 0.1490171253681183, 'learning_rate': 1.0711931815738625e-05, 'epoch': 4.64}
{'loss': 0.1576, 'grad_norm': 0.14344008266925812, 'learning_rate': 1.0439163585072064e-05, 'epoch': 4.83}
{'loss': 0.2069, 'grad_norm': 1.2482539415359497, 'learning_rate': 1.0157956302748738e-05, 'epoch': 5.0}
{'eval_loss': 0.6854684948921204, 'eval_runtime': 19.3648, 'eval_samples_per_second': 2.427, 'eval_steps_per_second': 1.239, 'epoch': 5.0}
{'loss': 0.1687, 'grad_norm': 0.15984955430030823, 'learning_rate': 9.868962719084635e-06, 'epoch': 5.19}
{'loss': 0.1528, 'grad_norm': 0.19613850116729736, 'learning_rate': 9.57285365828992e-06, 'epoch': 5.38}
{'loss': 0.1516, 'grad_norm': 0.1556021124124527, 'learning_rate': 9.270316461323209e-06, 'epoch': 5.56}
{'loss': 0.1497, 'grad_norm': 0.1625441312789917, 'learning_rate': 8.96205339040647e-06, 'epoch': 5.75}
{'loss': 0.1506, 'grad_norm': 0.17228664457798004, 'learning_rate': 8.64877999890407e-06, 'epoch': 5.94}
{'eval_loss': 0.6760815382003784, 'eval_runtime': 20.1596, 'eval_samples_per_second': 2.331, 'eval_steps_per_second': 1.19, 'epoch': 6.0}
{'loss': 0.2261, 'grad_norm': 0.1824207603931427, 'learning_rate': 8.331223470349822e-06, 'epoch': 6.11}
{'loss': 0.1609, 'grad_norm': 0.1770862340927124, 'learning_rate': 8.010120930477623e-06, 'epoch': 6.3}
{'loss': 0.1432, 'grad_norm': 0.18046647310256958, 'learning_rate': 7.686217736173808e-06, 'epoch': 6.49}
{'loss': 0.1414, 'grad_norm': 0.20517170429229736, 'learning_rate': 7.360265745323014e-06, 'epoch': 6.68}
{'loss': 0.1426, 'grad_norm': 0.1939016431570053, 'learning_rate': 7.03302157156365e-06, 'epoch': 6.86}
{'eval_loss': 0.6692813634872437, 'eval_runtime': 19.8305, 'eval_samples_per_second': 2.37, 'eval_steps_per_second': 1.21, 'epoch': 7.0}
{'loss': 0.1928, 'grad_norm': 0.18846753239631653, 'learning_rate': 6.705244828004112e-06, 'epoch': 7.04}
{'loss': 0.1554, 'grad_norm': 0.20305125415325165, 'learning_rate': 6.377696363976479e-06, 'epoch': 7.23}
{'loss': 0.1495, 'grad_norm': 0.20344680547714233, 'learning_rate': 6.051136498920671e-06, 'epoch': 7.41}
{'loss': 0.1427, 'grad_norm': 0.18966548144817352, 'learning_rate': 5.72632325749858e-06, 'epoch': 7.6}
{'loss': 0.1423, 'grad_norm': 0.19945046305656433, 'learning_rate': 5.404010610034966e-06, 'epoch': 7.79}
{'loss': 0.1383, 'grad_norm': 0.19081343710422516, 'learning_rate': 5.084946722369419e-06, 'epoch': 7.98}
{'eval_loss': 0.6690629720687866, 'eval_runtime': 20.0997, 'eval_samples_per_second': 2.338, 'eval_steps_per_second': 1.194, 'epoch': 8.0}
{'loss': 0.1737, 'grad_norm': 0.20254269242286682, 'learning_rate': 4.769872219181979e-06, 'epoch': 8.15}
{'loss': 0.1411, 'grad_norm': 0.18881645798683167, 'learning_rate': 4.459518464823589e-06, 'epoch': 8.34}
{'loss': 0.1425, 'grad_norm': 0.20470336079597473, 'learning_rate': 4.154605865642025e-06, 'epoch': 8.53}
{'loss': 0.1398, 'grad_norm': 0.18507267534732819, 'learning_rate': 3.8558421977440135e-06, 'epoch': 8.71}
{'loss': 0.1388, 'grad_norm': 0.20884385704994202, 'learning_rate': 3.5639209640751938e-06, 'epoch': 8.9}
{'eval_loss': 0.6686953902244568, 'eval_runtime': 20.3887, 'eval_samples_per_second': 2.305, 'eval_steps_per_second': 1.177, 'epoch': 9.0}
{'loss': 0.2036, 'grad_norm': 0.21332994103431702, 'learning_rate': 3.2795197846315637e-06, 'epoch': 9.08}
{'loss': 0.1448, 'grad_norm': 0.20240344107151031, 'learning_rate': 3.003298823539086e-06, 'epoch': 9.26}
{'loss': 0.1329, 'grad_norm': 0.20173843204975128, 'learning_rate': 2.735899256652627e-06, 'epoch': 9.45}
{'loss': 0.1334, 'grad_norm': 0.22023124992847443, 'learning_rate': 2.477941783231248e-06, 'epoch': 9.64}
{'loss': 0.1365, 'grad_norm': 0.2187492400407791, 'learning_rate': 2.2300251851446622e-06, 'epoch': 9.83}
{'loss': 0.1572, 'grad_norm': 1.468213677406311, 'learning_rate': 1.9927249369552836e-06, 'epoch': 10.0}
{'eval_loss': 0.6677312254905701, 'eval_runtime': 20.3732, 'eval_samples_per_second': 2.307, 'eval_steps_per_second': 1.178, 'epoch': 10.0}
{'train_runtime': 4026.0196, 'train_samples_per_second': 1.376, 'train_steps_per_second': 0.174, 'train_loss': 0.23044904161382604, 'epoch': 10.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 67.1 min
   Peak memory: 19.523 GB
   Training memory: 3.671 GB
================================================================================


================================================================================
‚úÖ TRIAL #18 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6677
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_tgpl4kkt
[I 2025-11-03 11:02:29,793] Trial 18 finished with value: 0.6677312254905701 and parameters: {'num_epochs': 13, 'learning_rate': 1.3607177011663597e-05, 'weight_decay': 0.0019552512121033747, 'batch_size': 2}. Best is trial 11 with value: 0.6387742757797241.

================================================================================
üî¨ OPTUNA TRIAL #19 STARTED
================================================================================

üìã HYPERPARAMETERS FOR TRIAL #19:
   ‚Ä¢ num_epochs:    11
   ‚Ä¢ learning_rate: 9.44e-05
   ‚Ä¢ weight_decay:  0.0755
   ‚Ä¢ batch_size:    1

‚è≥ Loading model for Trial #19...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_i3ixtwp6
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================

üöÄ Starting training for Trial #19...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/213 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/213 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/213 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/213 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/213 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/213 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/213 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/213 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/213 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/213 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/213 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/213 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/213 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/213 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/213 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/213 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/213 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/213 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/213 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/213 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/213 (aug 1/1): inventarbuch-134.jpg
‚úÖ Successfully created 213 augmented images
üìä Total training samples: 426 (original: 213, augmented: 213)
üìä Found 47 valid samples out of 47 total
üìä Training: 426 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 19.523 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 1, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.7786, 'grad_norm': 0.6998451948165894, 'learning_rate': 1.6988068888419536e-05, 'epoch': 0.09}
{'loss': 0.606, 'grad_norm': 0.8005141615867615, 'learning_rate': 3.586370098666347e-05, 'epoch': 0.19}
{'loss': 0.4715, 'grad_norm': 0.43126899003982544, 'learning_rate': 5.473933308490739e-05, 'epoch': 0.28}
{'loss': 0.2508, 'grad_norm': 0.2525900602340698, 'learning_rate': 7.361496518315133e-05, 'epoch': 0.38}
{'loss': 0.1965, 'grad_norm': 0.20035715401172638, 'learning_rate': 9.249059728139526e-05, 'epoch': 0.47}
{'loss': 0.1865, 'grad_norm': 0.19513708353042603, 'learning_rate': 9.436331051802304e-05, 'epoch': 0.56}
{'loss': 0.1785, 'grad_norm': 0.1948619782924652, 'learning_rate': 9.43119892764693e-05, 'epoch': 0.66}
{'loss': 0.1825, 'grad_norm': 0.19360783696174622, 'learning_rate': 9.422405330091756e-05, 'epoch': 0.75}
{'loss': 0.1464, 'grad_norm': 0.2371230125427246, 'learning_rate': 9.409957091805691e-05, 'epoch': 0.85}
{'loss': 0.1518, 'grad_norm': 0.1996881365776062, 'learning_rate': 9.393863885131612e-05, 'epoch': 0.94}
{'eval_loss': 0.6467688679695129, 'eval_runtime': 28.5182, 'eval_samples_per_second': 1.648, 'eval_steps_per_second': 1.648, 'epoch': 1.0}
{'loss': 0.1612, 'grad_norm': 0.1835850477218628, 'learning_rate': 9.374138214570912e-05, 'epoch': 1.03}
{'loss': 0.1173, 'grad_norm': 0.2264920175075531, 'learning_rate': 9.350795407067434e-05, 'epoch': 1.12}
{'loss': 0.1295, 'grad_norm': 0.24313190579414368, 'learning_rate': 9.323853600098366e-05, 'epoch': 1.22}
{'loss': 0.1376, 'grad_norm': 0.27418455481529236, 'learning_rate': 9.293333727581326e-05, 'epoch': 1.31}
{'loss': 0.136, 'grad_norm': 0.22468237578868866, 'learning_rate': 9.259259503608606e-05, 'epoch': 1.4}
{'loss': 0.1267, 'grad_norm': 0.21777525544166565, 'learning_rate': 9.221657404021207e-05, 'epoch': 1.5}
{'loss': 0.1374, 'grad_norm': 0.3159960210323334, 'learning_rate': 9.180556645836975e-05, 'epoch': 1.59}
{'loss': 0.1382, 'grad_norm': 0.2817534804344177, 'learning_rate': 9.135989164548838e-05, 'epoch': 1.69}
{'loss': 0.1184, 'grad_norm': 0.2771478295326233, 'learning_rate': 9.087989589310762e-05, 'epoch': 1.78}
{'loss': 0.1054, 'grad_norm': 0.3140099346637726, 'learning_rate': 9.03659521603074e-05, 'epoch': 1.87}
{'loss': 0.1135, 'grad_norm': 0.3304883539676666, 'learning_rate': 8.981845978391672e-05, 'epoch': 1.97}
{'eval_loss': 0.6536282300949097, 'eval_runtime': 26.9452, 'eval_samples_per_second': 1.744, 'eval_steps_per_second': 1.744, 'epoch': 2.0}
{'loss': 0.1118, 'grad_norm': 0.28718987107276917, 'learning_rate': 8.923784416822702e-05, 'epoch': 2.06}
{'loss': 0.0811, 'grad_norm': 0.34348052740097046, 'learning_rate': 8.862455645445097e-05, 'epoch': 2.15}
{'loss': 0.084, 'grad_norm': 0.3249458074569702, 'learning_rate': 8.797907317018342e-05, 'epoch': 2.24}
{'loss': 0.081, 'grad_norm': 0.34771639108657837, 'learning_rate': 8.73018958591372e-05, 'epoch': 2.34}
{'loss': 0.0788, 'grad_norm': 0.3385854661464691, 'learning_rate': 8.659355069144107e-05, 'epoch': 2.43}
{'loss': 0.0749, 'grad_norm': 0.3669763505458832, 'learning_rate': 8.585458805480302e-05, 'epoch': 2.53}
{'loss': 0.0654, 'grad_norm': 0.3637988865375519, 'learning_rate': 8.508558212685618e-05, 'epoch': 2.62}
{'loss': 0.0792, 'grad_norm': 0.30726736783981323, 'learning_rate': 8.428713042902007e-05, 'epoch': 2.71}
{'loss': 0.0857, 'grad_norm': 0.41106244921684265, 'learning_rate': 8.345985336222338e-05, 'epoch': 2.81}
{'loss': 0.0683, 'grad_norm': 0.3373963236808777, 'learning_rate': 8.260439372484947e-05, 'epoch': 2.9}
{'loss': 0.0619, 'grad_norm': 0.37065693736076355, 'learning_rate': 8.172141621327878e-05, 'epoch': 3.0}
{'eval_loss': 0.7701664566993713, 'eval_runtime': 27.4827, 'eval_samples_per_second': 1.71, 'eval_steps_per_second': 1.71, 'epoch': 3.0}
{'loss': 0.049, 'grad_norm': 0.31936606764793396, 'learning_rate': 8.081160690541643e-05, 'epoch': 3.08}
{'loss': 0.0376, 'grad_norm': 0.30974701046943665, 'learning_rate': 7.987567272760637e-05, 'epoch': 3.18}
{'loss': 0.0357, 'grad_norm': 0.34646162390708923, 'learning_rate': 7.891434090534602e-05, 'epoch': 3.27}
{'loss': 0.0418, 'grad_norm': 0.37940073013305664, 'learning_rate': 7.79283583982285e-05, 'epoch': 3.37}
{'loss': 0.0367, 'grad_norm': 0.3901519775390625, 'learning_rate': 7.691849131955127e-05, 'epoch': 3.46}
{'loss': 0.0367, 'grad_norm': 0.3741467595100403, 'learning_rate': 7.58855243410424e-05, 'epoch': 3.55}
{'loss': 0.0314, 'grad_norm': 0.3632039427757263, 'learning_rate': 7.48302600831666e-05, 'epoch': 3.65}
{'loss': 0.0338, 'grad_norm': 0.41180357336997986, 'learning_rate': 7.375351849148528e-05, 'epoch': 3.74}
{'loss': 0.032, 'grad_norm': 0.3386705815792084, 'learning_rate': 7.265613619955472e-05, 'epoch': 3.84}
{'loss': 0.0296, 'grad_norm': 0.4878872334957123, 'learning_rate': 7.15389658788576e-05, 'epoch': 3.93}
{'eval_loss': 0.8466972708702087, 'eval_runtime': 28.7628, 'eval_samples_per_second': 1.634, 'eval_steps_per_second': 1.634, 'epoch': 4.0}
{'train_runtime': 2417.2627, 'train_samples_per_second': 1.939, 'train_steps_per_second': 0.487, 'train_loss': 0.13631321691742568, 'epoch': 4.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 40.29 min
   Peak memory: 19.523 GB
   Training memory: 0.0 GB
================================================================================


================================================================================
‚úÖ TRIAL #19 COMPLETED
================================================================================
   üéØ Best eval_loss: 0.6468
================================================================================

üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_i3ixtwp6
[I 2025-11-03 11:43:35,590] Trial 19 finished with value: 0.6467688679695129 and parameters: {'num_epochs': 11, 'learning_rate': 9.437816049121965e-05, 'weight_decay': 0.07551215485254455, 'batch_size': 1}. Best is trial 11 with value: 0.6387742757797241.

================================================================================
üèÜ OPTUNA OPTIMIZATION COMPLETED
================================================================================
   ‚Ä¢ Best trial: #11
   ‚Ä¢ Best value (eval_loss): 0.6388

   Best hyperparameters:
      ‚Ä¢ num_epochs: 15
      ‚Ä¢ learning_rate: 4.30206110790971e-05
      ‚Ä¢ weight_decay: 0.07920173174912956
      ‚Ä¢ batch_size: 1

üíæ Best params saved to: /home/vault/iwi5/iwi5298h/models_image_text/nanonets/hpo/inven/best_hyperparameters.json

================================================================================
üìä PHASE 2: FINAL MODEL TRAINING
================================================================================

================================================================================
üèÜ TRAINING FINAL MODEL WITH BEST HYPERPARAMETERS
================================================================================

üìã Best Parameters:
   ‚Ä¢ num_epochs: 15
   ‚Ä¢ learning_rate: 4.30206110790971e-05
   ‚Ä¢ weight_decay: 0.07920173174912956
   ‚Ä¢ batch_size: 1

‚è≥ Loading model for final training...
================================================================================
LOADING NANONETS-OCR-S WITH UNSLOTH FOR INVENTORY DATASET
================================================================================
Model path: /home/vault/iwi5/iwi5298h/models/Nanonets-OCR-s
Augmentation factor: 1
Created temporary directory: /tmp/1294984.tinygpu/augmented_inventory_sd1knogk
‚úì Model directory verified
‚è≥ Loading model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.10.7: Fast Qwen2_5_Vl patching. Transformers: 4.56.2.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 7.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to fast eager.
‚úÖ Model loaded successfully!
‚è≥ Applying LoRA adaptors...
Unsloth: Making `model.base_model.model.model` require gradients
‚úÖ LoRA applied successfully!
================================================================================
‚è≥ Combining train and validation datasets...
‚úÖ Combined dataset saved: 260 samples (213 train + 47 val)

üöÄ Starting final model training...

‚è≥ Preparing datasets...
‚è≥ Preparing training data with augmentation factor: 1
   Augmenting image 10/260 (aug 1/1): inventarbuch-094.jpg
   Augmenting image 20/260 (aug 1/1): inventarbuch-144.jpg
   Augmenting image 30/260 (aug 1/1): inventarbuch-050.jpg
   Augmenting image 40/260 (aug 1/1): inventarbuch-085.jpg
   Augmenting image 50/260 (aug 1/1): inventarbuch-228.jpg
   Augmenting image 60/260 (aug 1/1): inventarbuch-246.jpg
   Augmenting image 70/260 (aug 1/1): inventarbuch-126.jpg
   Augmenting image 80/260 (aug 1/1): inventarbuch-308.jpg
   Augmenting image 90/260 (aug 1/1): inventarbuch-080.jpg
   Augmenting image 100/260 (aug 1/1): inventarbuch-218.jpg
   Augmenting image 110/260 (aug 1/1): inventarbuch-156.jpg
   Augmenting image 120/260 (aug 1/1): inventarbuch-186.jpg
   Augmenting image 130/260 (aug 1/1): inventarbuch-052.jpg
   Augmenting image 140/260 (aug 1/1): inventarbuch-163.jpg
   Augmenting image 150/260 (aug 1/1): inventarbuch-066.jpg
   Augmenting image 160/260 (aug 1/1): inventarbuch-030.jpg
   Augmenting image 170/260 (aug 1/1): inventarbuch-113.jpg
   Augmenting image 180/260 (aug 1/1): inventarbuch-170.jpg
   Augmenting image 190/260 (aug 1/1): inventarbuch-224.jpg
   Augmenting image 200/260 (aug 1/1): inventarbuch-293.jpg
   Augmenting image 210/260 (aug 1/1): inventarbuch-134.jpg
   Augmenting image 220/260 (aug 1/1): inventarbuch-020.jpg
   Augmenting image 230/260 (aug 1/1): inventarbuch-096.jpg
   Augmenting image 240/260 (aug 1/1): inventarbuch-266.jpg
   Augmenting image 250/260 (aug 1/1): inventarbuch-095.jpg
   Augmenting image 260/260 (aug 1/1): inventarbuch-253.jpg
‚úÖ Successfully created 260 augmented images
üìä Total training samples: 520 (original: 260, augmented: 260)
üìä Found 47 valid samples out of 47 total
üìä Training: 520 samples, Validation: 47 samples

‚è≥ Initializing trainer...
Unsloth: Model does not have a default image size - using 512

================================================================================
üñ•Ô∏è  GPU INFORMATION
================================================================================
   GPU: Tesla V100-PCIE-32GB
   Max memory: 31.733 GB
   Reserved: 19.523 GB

‚úÖ UNSLOTH OPTIMIZATIONS:
   ‚Ä¢ 4-bit quantization
   ‚Ä¢ LoRA rank 16 (RSLoRA)
   ‚Ä¢ Gradient checkpointing
   ‚Ä¢ Data augmentation: 1x
   ‚Ä¢ Batch size: 1, Grad accum: 4
================================================================================

üöÄ Starting training...
{'loss': 0.78, 'grad_norm': 1.0316883325576782, 'learning_rate': 6.8832977726555355e-06, 'epoch': 0.08}
{'loss': 0.6927, 'grad_norm': 0.5735303163528442, 'learning_rate': 1.5487419988474956e-05, 'epoch': 0.15}
{'loss': 0.5851, 'grad_norm': 0.39813199639320374, 'learning_rate': 2.409154220429438e-05, 'epoch': 0.23}
{'loss': 0.4608, 'grad_norm': 0.3820609450340271, 'learning_rate': 3.2695664420113794e-05, 'epoch': 0.31}
{'loss': 0.3082, 'grad_norm': 0.3361821174621582, 'learning_rate': 4.129978663593321e-05, 'epoch': 0.38}
{'loss': 0.217, 'grad_norm': 0.298687607049942, 'learning_rate': 4.301872923878072e-05, 'epoch': 0.46}
{'loss': 0.1974, 'grad_norm': 0.21801252663135529, 'learning_rate': 4.301108482681281e-05, 'epoch': 0.54}
{'loss': 0.1798, 'grad_norm': 0.22827118635177612, 'learning_rate': 4.299756231647171e-05, 'epoch': 0.62}
{'loss': 0.1775, 'grad_norm': 0.20181035995483398, 'learning_rate': 4.297816540467671e-05, 'epoch': 0.69}
{'loss': 0.1604, 'grad_norm': 0.18949973583221436, 'learning_rate': 4.295289939434985e-05, 'epoch': 0.77}
{'loss': 0.1838, 'grad_norm': 0.22389091551303864, 'learning_rate': 4.2921771192966045e-05, 'epoch': 0.85}
{'loss': 0.1735, 'grad_norm': 0.21063770353794098, 'learning_rate': 4.288478931066476e-05, 'epoch': 0.92}
{'loss': 0.1551, 'grad_norm': 0.20195770263671875, 'learning_rate': 4.284196385792334e-05, 'epoch': 1.0}
{'eval_loss': 0.6176958680152893, 'eval_runtime': 27.9, 'eval_samples_per_second': 1.685, 'eval_steps_per_second': 1.685, 'epoch': 1.0}
{'loss': 0.1626, 'grad_norm': 0.2132326066493988, 'learning_rate': 4.2793306542792955e-05, 'epoch': 1.08}
{'loss': 0.1524, 'grad_norm': 0.26656827330589294, 'learning_rate': 4.2738830667697736e-05, 'epoch': 1.15}
{'loss': 0.1634, 'grad_norm': 0.2504946291446686, 'learning_rate': 4.267855112579799e-05, 'epoch': 1.23}
{'loss': 0.1535, 'grad_norm': 0.24888750910758972, 'learning_rate': 4.2612484396918564e-05, 'epoch': 1.31}
{'loss': 0.1378, 'grad_norm': 0.25183722376823425, 'learning_rate': 4.254064854304349e-05, 'epoch': 1.38}
{'loss': 0.136, 'grad_norm': 0.2525918185710907, 'learning_rate': 4.246306320337793e-05, 'epoch': 1.46}
{'loss': 0.1488, 'grad_norm': 0.29034295678138733, 'learning_rate': 4.2379749588979065e-05, 'epoch': 1.54}
{'loss': 0.1303, 'grad_norm': 0.2393232136964798, 'learning_rate': 4.2290730476957185e-05, 'epoch': 1.62}
{'loss': 0.1389, 'grad_norm': 0.3276911973953247, 'learning_rate': 4.2196030204248676e-05, 'epoch': 1.69}
{'loss': 0.1431, 'grad_norm': 0.312698096036911, 'learning_rate': 4.209567466096251e-05, 'epoch': 1.77}
{'loss': 0.1388, 'grad_norm': 0.30505070090293884, 'learning_rate': 4.198969128330219e-05, 'epoch': 1.85}
{'loss': 0.1385, 'grad_norm': 0.2925034463405609, 'learning_rate': 4.187810904606492e-05, 'epoch': 1.92}
{'loss': 0.1423, 'grad_norm': 0.303240031003952, 'learning_rate': 4.176095845472021e-05, 'epoch': 2.0}
{'eval_loss': 0.4611954391002655, 'eval_runtime': 28.8708, 'eval_samples_per_second': 1.628, 'eval_steps_per_second': 1.628, 'epoch': 2.0}
{'loss': 0.121, 'grad_norm': 0.36403587460517883, 'learning_rate': 4.163827153707002e-05, 'epoch': 2.08}
{'loss': 0.119, 'grad_norm': 0.3602890968322754, 'learning_rate': 4.1510081834492586e-05, 'epoch': 2.15}
{'loss': 0.1039, 'grad_norm': 0.29484108090400696, 'learning_rate': 4.1376424392772645e-05, 'epoch': 2.23}
{'loss': 0.1154, 'grad_norm': 0.3815746009349823, 'learning_rate': 4.12373357525202e-05, 'epoch': 2.31}
{'loss': 0.1215, 'grad_norm': 0.4280426800251007, 'learning_rate': 4.109285393918069e-05, 'epoch': 2.38}
{'loss': 0.1069, 'grad_norm': 0.3803083002567291, 'learning_rate': 4.094301845263926e-05, 'epoch': 2.46}
{'loss': 0.1189, 'grad_norm': 0.5009955167770386, 'learning_rate': 4.0787870256421824e-05, 'epoch': 2.54}
{'loss': 0.1129, 'grad_norm': 0.394534170627594, 'learning_rate': 4.0627451766496075e-05, 'epoch': 2.62}
{'loss': 0.0886, 'grad_norm': 0.3144770562648773, 'learning_rate': 4.04618068396754e-05, 'epoch': 2.69}
{'loss': 0.1114, 'grad_norm': 0.44727998971939087, 'learning_rate': 4.029098076162884e-05, 'epoch': 2.77}
{'loss': 0.1025, 'grad_norm': 0.47071725130081177, 'learning_rate': 4.0115020234500434e-05, 'epoch': 2.85}
{'loss': 0.0922, 'grad_norm': 0.4764235019683838, 'learning_rate': 3.993397336414135e-05, 'epoch': 2.92}
{'loss': 0.0993, 'grad_norm': 0.4555000364780426, 'learning_rate': 3.97478896469582e-05, 'epoch': 3.0}
{'eval_loss': 0.29400351643562317, 'eval_runtime': 28.9547, 'eval_samples_per_second': 1.623, 'eval_steps_per_second': 1.623, 'epoch': 3.0}
{'loss': 0.0686, 'grad_norm': 0.48767372965812683, 'learning_rate': 3.9556819956381234e-05, 'epoch': 3.08}
{'loss': 0.0761, 'grad_norm': 0.5819814801216125, 'learning_rate': 3.936081652895603e-05, 'epoch': 3.15}
{'loss': 0.0698, 'grad_norm': 0.5634027123451233, 'learning_rate': 3.915993295006256e-05, 'epoch': 3.23}
{'loss': 0.0751, 'grad_norm': 0.47253692150115967, 'learning_rate': 3.895422413926549e-05, 'epoch': 3.31}
{'loss': 0.0688, 'grad_norm': 0.44288280606269836, 'learning_rate': 3.874374633529971e-05, 'epoch': 3.38}
{'loss': 0.0762, 'grad_norm': 0.561545729637146, 'learning_rate': 3.85285570806952e-05, 'epoch': 3.46}
{'loss': 0.0713, 'grad_norm': 0.652163565158844, 'learning_rate': 3.830871520604554e-05, 'epoch': 3.54}
{'loss': 0.0734, 'grad_norm': 0.6062174439430237, 'learning_rate': 3.8084280813924126e-05, 'epoch': 3.62}
{'loss': 0.0733, 'grad_norm': 0.5829667448997498, 'learning_rate': 3.785531526245282e-05, 'epoch': 3.69}
{'loss': 0.0618, 'grad_norm': 0.6747885942459106, 'learning_rate': 3.762188114852717e-05, 'epoch': 3.77}
{'loss': 0.0634, 'grad_norm': 0.6075307726860046, 'learning_rate': 3.7384042290703105e-05, 'epoch': 3.85}
{'loss': 0.0675, 'grad_norm': 0.4430621266365051, 'learning_rate': 3.714186371174955e-05, 'epoch': 3.92}
{'loss': 0.0702, 'grad_norm': 0.49394601583480835, 'learning_rate': 3.6895411620871866e-05, 'epoch': 4.0}
{'eval_loss': 0.1567566990852356, 'eval_runtime': 24.3067, 'eval_samples_per_second': 1.934, 'eval_steps_per_second': 1.934, 'epoch': 4.0}
{'loss': 0.0438, 'grad_norm': 0.6418683528900146, 'learning_rate': 3.6644753395610875e-05, 'epoch': 4.08}
{'loss': 0.0393, 'grad_norm': 0.5880268812179565, 'learning_rate': 3.638995756342256e-05, 'epoch': 4.15}
{'loss': 0.033, 'grad_norm': 0.5457616448402405, 'learning_rate': 3.613109378294331e-05, 'epoch': 4.23}
{'loss': 0.0376, 'grad_norm': 0.48758235573768616, 'learning_rate': 3.586823282494598e-05, 'epoch': 4.31}
{'loss': 0.039, 'grad_norm': 0.6195288300514221, 'learning_rate': 3.5601446552991836e-05, 'epoch': 4.38}
{'loss': 0.0411, 'grad_norm': 0.5730080008506775, 'learning_rate': 3.533080790378379e-05, 'epoch': 4.46}
{'loss': 0.0362, 'grad_norm': 0.7550772428512573, 'learning_rate': 3.5056390867226224e-05, 'epoch': 4.54}
{'loss': 0.0409, 'grad_norm': 0.6300506591796875, 'learning_rate': 3.477827046619688e-05, 'epoch': 4.62}
{'loss': 0.0348, 'grad_norm': 0.6906686425209045, 'learning_rate': 3.44965227360364e-05, 'epoch': 4.69}
{'loss': 0.0389, 'grad_norm': 0.5889727473258972, 'learning_rate': 3.421122470376098e-05, 'epoch': 4.77}
{'loss': 0.0327, 'grad_norm': 0.7559547424316406, 'learning_rate': 3.3922454367003947e-05, 'epoch': 4.85}
{'loss': 0.0369, 'grad_norm': 0.47055891156196594, 'learning_rate': 3.3630290672692027e-05, 'epoch': 4.92}
{'loss': 0.0336, 'grad_norm': 0.7276046276092529, 'learning_rate': 3.3334813495462e-05, 'epoch': 5.0}
{'eval_loss': 0.06711426377296448, 'eval_runtime': 24.0374, 'eval_samples_per_second': 1.955, 'eval_steps_per_second': 1.955, 'epoch': 5.0}
{'loss': 0.0188, 'grad_norm': 0.37336936593055725, 'learning_rate': 3.30361036158238e-05, 'epoch': 5.08}
{'loss': 0.0159, 'grad_norm': 0.4007631838321686, 'learning_rate': 3.273424269807593e-05, 'epoch': 5.15}
{'loss': 0.0173, 'grad_norm': 0.3975946307182312, 'learning_rate': 3.242931326797924e-05, 'epoch': 5.23}
{'loss': 0.0174, 'grad_norm': 0.3400276005268097, 'learning_rate': 3.212139869019521e-05, 'epoch': 5.31}
{'loss': 0.0174, 'grad_norm': 0.3025565445423126, 'learning_rate': 3.1810583145494894e-05, 'epoch': 5.38}
{'loss': 0.0149, 'grad_norm': 0.31117239594459534, 'learning_rate': 3.149695160774476e-05, 'epoch': 5.46}
{'loss': 0.016, 'grad_norm': 0.4330451488494873, 'learning_rate': 3.11805898206756e-05, 'epoch': 5.54}
{'loss': 0.0131, 'grad_norm': 0.523681640625, 'learning_rate': 3.086158427444118e-05, 'epoch': 5.62}
{'loss': 0.0167, 'grad_norm': 0.286080926656723, 'learning_rate': 3.0540022181972576e-05, 'epoch': 5.69}
{'loss': 0.0184, 'grad_norm': 0.42506474256515503, 'learning_rate': 3.021599145513509e-05, 'epoch': 5.77}
{'loss': 0.0142, 'grad_norm': 0.354697585105896, 'learning_rate': 2.988958068069402e-05, 'epoch': 5.85}
{'loss': 0.0193, 'grad_norm': 0.3651197850704193, 'learning_rate': 2.95608790960959e-05, 'epoch': 5.92}
{'loss': 0.016, 'grad_norm': 0.24080350995063782, 'learning_rate': 2.9229976565071902e-05, 'epoch': 6.0}
{'eval_loss': 0.03270391374826431, 'eval_runtime': 24.1559, 'eval_samples_per_second': 1.946, 'eval_steps_per_second': 1.946, 'epoch': 6.0}
{'loss': 0.0088, 'grad_norm': 0.2103874534368515, 'learning_rate': 2.8896963553069963e-05, 'epoch': 6.08}
{'loss': 0.0088, 'grad_norm': 0.37674763798713684, 'learning_rate': 2.856193110252244e-05, 'epoch': 6.15}
{'loss': 0.0077, 'grad_norm': 0.32354414463043213, 'learning_rate': 2.8224970807956054e-05, 'epoch': 6.23}
{'loss': 0.0082, 'grad_norm': 0.343868613243103, 'learning_rate': 2.7886174790950797e-05, 'epoch': 6.31}
{'loss': 0.0071, 'grad_norm': 0.2965851128101349, 'learning_rate': 2.7545635674954862e-05, 'epoch': 6.38}
{'loss': 0.0071, 'grad_norm': 0.3200564980506897, 'learning_rate': 2.7203446559962308e-05, 'epoch': 6.46}
{'loss': 0.0065, 'grad_norm': 0.3308979570865631, 'learning_rate': 2.6859700997060436e-05, 'epoch': 6.54}
{'loss': 0.0081, 'grad_norm': 0.2980238199234009, 'learning_rate': 2.651449296285385e-05, 'epoch': 6.62}
{'loss': 0.0078, 'grad_norm': 0.22034266591072083, 'learning_rate': 2.616791683377224e-05, 'epoch': 6.69}
{'loss': 0.0065, 'grad_norm': 0.20419317483901978, 'learning_rate': 2.5820067360268747e-05, 'epoch': 6.77}
{'loss': 0.007, 'grad_norm': 0.281675785779953, 'learning_rate': 2.5471039640916174e-05, 'epoch': 6.85}
{'loss': 0.0073, 'grad_norm': 0.2833341956138611, 'learning_rate': 2.512092909640797e-05, 'epoch': 6.92}
{'loss': 0.0066, 'grad_norm': 0.27279308438301086, 'learning_rate': 2.4769831443471177e-05, 'epoch': 7.0}
{'eval_loss': 0.017258502542972565, 'eval_runtime': 24.2263, 'eval_samples_per_second': 1.94, 'eval_steps_per_second': 1.94, 'epoch': 7.0}
{'loss': 0.0045, 'grad_norm': 0.17317001521587372, 'learning_rate': 2.4417842668698417e-05, 'epoch': 7.08}
{'loss': 0.0042, 'grad_norm': 0.08465810120105743, 'learning_rate': 2.4065059002306117e-05, 'epoch': 7.15}
{'loss': 0.0042, 'grad_norm': 0.1331031173467636, 'learning_rate': 2.3711576891826163e-05, 'epoch': 7.23}
{'loss': 0.0038, 'grad_norm': 0.14649000763893127, 'learning_rate': 2.3357492975738048e-05, 'epoch': 7.31}
{'loss': 0.0044, 'grad_norm': 0.11940956860780716, 'learning_rate': 2.3002904057048933e-05, 'epoch': 7.38}
{'loss': 0.0044, 'grad_norm': 0.3957114815711975, 'learning_rate': 2.2647907076828636e-05, 'epoch': 7.46}
{'loss': 0.005, 'grad_norm': 0.25075823068618774, 'learning_rate': 2.229259908770693e-05, 'epoch': 7.54}
{'loss': 0.0039, 'grad_norm': 0.18918149173259735, 'learning_rate': 2.19370772273403e-05, 'epoch': 7.62}
{'loss': 0.0045, 'grad_norm': 0.22353731095790863, 'learning_rate': 2.1581438691855526e-05, 'epoch': 7.69}
{'loss': 0.0042, 'grad_norm': 0.14849181473255157, 'learning_rate': 2.122578070927717e-05, 'epoch': 7.77}
{'loss': 0.004, 'grad_norm': 0.1873452216386795, 'learning_rate': 2.0870200512946448e-05, 'epoch': 7.85}
{'loss': 0.004, 'grad_norm': 0.25113505125045776, 'learning_rate': 2.0514795314938585e-05, 'epoch': 7.92}
{'loss': 0.0047, 'grad_norm': 0.16063463687896729, 'learning_rate': 2.0159662279486028e-05, 'epoch': 8.0}
{'eval_loss': 0.012559077702462673, 'eval_runtime': 24.3678, 'eval_samples_per_second': 1.929, 'eval_steps_per_second': 1.929, 'epoch': 8.0}
{'loss': 0.0035, 'grad_norm': 0.16612611711025238, 'learning_rate': 1.980489849641468e-05, 'epoch': 8.08}
{'loss': 0.0038, 'grad_norm': 0.10781572014093399, 'learning_rate': 1.9450600954600544e-05, 'epoch': 8.15}
{'loss': 0.0035, 'grad_norm': 0.20340560376644135, 'learning_rate': 1.9096866515453915e-05, 'epoch': 8.23}
{'loss': 0.0034, 'grad_norm': 0.16484127938747406, 'learning_rate': 1.8743791886438428e-05, 'epoch': 8.31}
{'loss': 0.003, 'grad_norm': 0.09882611781358719, 'learning_rate': 1.8391473594632234e-05, 'epoch': 8.38}
{'loss': 0.0029, 'grad_norm': 0.1975172907114029, 'learning_rate': 1.8040007960338436e-05, 'epoch': 8.46}
{'loss': 0.0033, 'grad_norm': 0.12497919797897339, 'learning_rate': 1.768949107075209e-05, 'epoch': 8.54}
{'loss': 0.0031, 'grad_norm': 0.2708418369293213, 'learning_rate': 1.7340018753690915e-05, 'epoch': 8.62}
{'loss': 0.0029, 'grad_norm': 0.09148239344358444, 'learning_rate': 1.699168655139694e-05, 'epoch': 8.69}
{'loss': 0.0031, 'grad_norm': 0.12412144243717194, 'learning_rate': 1.66445896944162e-05, 'epoch': 8.77}
{'loss': 0.003, 'grad_norm': 0.0875215157866478, 'learning_rate': 1.6298823075563647e-05, 'epoch': 8.85}
{'loss': 0.0031, 'grad_norm': 0.08952359855175018, 'learning_rate': 1.5954481223980417e-05, 'epoch': 8.92}
{'loss': 0.0029, 'grad_norm': 0.0778498500585556, 'learning_rate': 1.5611658279290497e-05, 'epoch': 9.0}
{'eval_loss': 0.009994014166295528, 'eval_runtime': 24.2915, 'eval_samples_per_second': 1.935, 'eval_steps_per_second': 1.935, 'epoch': 9.0}
{'loss': 0.0027, 'grad_norm': 0.13202056288719177, 'learning_rate': 1.527044796586391e-05, 'epoch': 9.08}
{'loss': 0.0024, 'grad_norm': 0.09396682679653168, 'learning_rate': 1.4930943567193379e-05, 'epoch': 9.15}
{'loss': 0.0025, 'grad_norm': 0.09794139117002487, 'learning_rate': 1.4593237900391575e-05, 'epoch': 9.23}
{'loss': 0.0023, 'grad_norm': 0.06960052996873856, 'learning_rate': 1.4257423290815816e-05, 'epoch': 9.31}
{'loss': 0.0023, 'grad_norm': 0.13946954905986786, 'learning_rate': 1.392359154682728e-05, 'epoch': 9.38}
{'loss': 0.0022, 'grad_norm': 0.07907602190971375, 'learning_rate': 1.359183393469149e-05, 'epoch': 9.46}
{'loss': 0.0025, 'grad_norm': 0.1706583946943283, 'learning_rate': 1.3262241153627018e-05, 'epoch': 9.54}
{'loss': 0.0027, 'grad_norm': 0.11062774807214737, 'learning_rate': 1.2934903311009248e-05, 'epoch': 9.62}
{'loss': 0.0024, 'grad_norm': 0.07740378379821777, 'learning_rate': 1.2609909897735901e-05, 'epoch': 9.69}
{'loss': 0.0026, 'grad_norm': 0.08815597742795944, 'learning_rate': 1.2287349763761136e-05, 'epoch': 9.77}
{'loss': 0.0023, 'grad_norm': 0.08012647181749344, 'learning_rate': 1.1967311093804823e-05, 'epoch': 9.85}
{'loss': 0.0021, 'grad_norm': 0.14768660068511963, 'learning_rate': 1.1649881383243768e-05, 'epoch': 9.92}
{'loss': 0.0022, 'grad_norm': 0.14631761610507965, 'learning_rate': 1.1335147414191325e-05, 'epoch': 10.0}
{'eval_loss': 0.008309661410748959, 'eval_runtime': 24.335, 'eval_samples_per_second': 1.931, 'eval_steps_per_second': 1.931, 'epoch': 10.0}
{'loss': 0.0022, 'grad_norm': 0.064207062125206, 'learning_rate': 1.1023195231772029e-05, 'epoch': 10.08}
{'loss': 0.002, 'grad_norm': 0.06603040546178818, 'learning_rate': 1.0714110120597738e-05, 'epoch': 10.15}
{'loss': 0.002, 'grad_norm': 0.061745475977659225, 'learning_rate': 1.0407976581451645e-05, 'epoch': 10.23}
{'loss': 0.0019, 'grad_norm': 0.06364662200212479, 'learning_rate': 1.0104878308186636e-05, 'epoch': 10.31}
{'loss': 0.0017, 'grad_norm': 0.19841603934764862, 'learning_rate': 9.804898164844195e-06, 'epoch': 10.38}
{'loss': 0.0021, 'grad_norm': 0.13780023157596588, 'learning_rate': 9.508118163000229e-06, 'epoch': 10.46}
{'loss': 0.0018, 'grad_norm': 0.10807439684867859, 'learning_rate': 9.214619439343916e-06, 'epoch': 10.54}
{'loss': 0.002, 'grad_norm': 0.08998358249664307, 'learning_rate': 8.924482233495736e-06, 'epoch': 10.62}
{'loss': 0.0018, 'grad_norm': 0.09805876016616821, 'learning_rate': 8.63778586607077e-06, 'epoch': 10.69}
{'loss': 0.0018, 'grad_norm': 0.09059277176856995, 'learning_rate': 8.35460871699322e-06, 'epoch': 10.77}
{'loss': 0.002, 'grad_norm': 0.08333614468574524, 'learning_rate': 8.075028204068141e-06, 'epoch': 10.85}
{'loss': 0.0021, 'grad_norm': 0.1938478648662567, 'learning_rate': 7.79912076181617e-06, 'epoch': 10.92}
{'loss': 0.002, 'grad_norm': 0.05799465626478195, 'learning_rate': 7.526961820577106e-06, 'epoch': 11.0}
{'eval_loss': 0.006726054474711418, 'eval_runtime': 24.3566, 'eval_samples_per_second': 1.93, 'eval_steps_per_second': 1.93, 'epoch': 11.0}
{'loss': 0.0019, 'grad_norm': 0.06864530593156815, 'learning_rate': 7.258625785887988e-06, 'epoch': 11.08}
{'loss': 0.0015, 'grad_norm': 0.03466472029685974, 'learning_rate': 6.994186018141382e-06, 'epoch': 11.15}
{'loss': 0.0014, 'grad_norm': 0.20759472250938416, 'learning_rate': 6.733714812529379e-06, 'epoch': 11.23}
{'loss': 0.0014, 'grad_norm': 0.04799488186836243, 'learning_rate': 6.477283379278799e-06, 'epoch': 11.31}
{'loss': 0.0016, 'grad_norm': 0.05399949476122856, 'learning_rate': 6.224961824183054e-06, 'epoch': 11.38}
{'loss': 0.0017, 'grad_norm': 0.04642825201153755, 'learning_rate': 5.9768191294358725e-06, 'epoch': 11.46}
{'loss': 0.0016, 'grad_norm': 0.05489746853709221, 'learning_rate': 5.732923134772319e-06, 'epoch': 11.54}
{'loss': 0.0015, 'grad_norm': 0.16341999173164368, 'learning_rate': 5.493340518922046e-06, 'epoch': 11.62}
{'loss': 0.0018, 'grad_norm': 0.1456800252199173, 'learning_rate': 5.258136781380014e-06, 'epoch': 11.69}
{'loss': 0.0017, 'grad_norm': 0.10184469074010849, 'learning_rate': 5.027376224499566e-06, 'epoch': 11.77}
{'loss': 0.0018, 'grad_norm': 0.20666104555130005, 'learning_rate': 4.801121935912832e-06, 'epoch': 11.85}
{'loss': 0.0016, 'grad_norm': 0.10343705862760544, 'learning_rate': 4.579435771283167e-06, 'epoch': 11.92}
{'loss': 0.0018, 'grad_norm': 0.062421683222055435, 'learning_rate': 4.362378337394462e-06, 'epoch': 12.0}
{'eval_loss': 0.00605477811768651, 'eval_runtime': 24.3674, 'eval_samples_per_second': 1.929, 'eval_steps_per_second': 1.929, 'epoch': 12.0}
{'loss': 0.0013, 'grad_norm': 0.05933861806988716, 'learning_rate': 4.150008975581838e-06, 'epoch': 12.08}
{'loss': 0.0015, 'grad_norm': 0.09405656158924103, 'learning_rate': 3.942385745508318e-06, 'epoch': 12.15}
{'loss': 0.0014, 'grad_norm': 0.03767882660031319, 'learning_rate': 3.739565409291898e-06, 'epoch': 12.23}
{'loss': 0.0013, 'grad_norm': 0.08129676431417465, 'learning_rate': 3.5416034159873553e-06, 'epoch': 12.31}
{'loss': 0.0014, 'grad_norm': 0.04755596071481705, 'learning_rate': 3.3485538864270243e-06, 'epoch': 12.38}
{'loss': 0.0016, 'grad_norm': 0.121822789311409, 'learning_rate': 3.1604695984246893e-06, 'epoch': 12.46}
{'loss': 0.0014, 'grad_norm': 0.17584051191806793, 'learning_rate': 2.9774019723466843e-06, 'epoch': 12.54}
{'loss': 0.0016, 'grad_norm': 0.08608601242303848, 'learning_rate': 2.79940105705406e-06, 'epoch': 12.62}
{'loss': 0.0013, 'grad_norm': 0.09504809230566025, 'learning_rate': 2.626515516219729e-06, 'epoch': 12.69}
{'loss': 0.0014, 'grad_norm': 0.05576242506504059, 'learning_rate': 2.4587926150243006e-06, 'epoch': 12.77}
{'loss': 0.0016, 'grad_norm': 0.06350047886371613, 'learning_rate': 2.296278207234269e-06, 'epoch': 12.85}
{'loss': 0.0014, 'grad_norm': 0.08711063116788864, 'learning_rate': 2.1390167226660267e-06, 'epoch': 12.92}
{'loss': 0.0014, 'grad_norm': 0.12157965451478958, 'learning_rate': 1.9870511550391985e-06, 'epoch': 13.0}
{'eval_loss': 0.0053302994929254055, 'eval_runtime': 24.2529, 'eval_samples_per_second': 1.938, 'eval_steps_per_second': 1.938, 'epoch': 13.0}
{'loss': 0.0014, 'grad_norm': 0.05498545616865158, 'learning_rate': 1.8404230502226131e-06, 'epoch': 13.08}
{'loss': 0.0013, 'grad_norm': 0.07263310253620148, 'learning_rate': 1.6991724948760516e-06, 'epoch': 13.15}
{'loss': 0.0013, 'grad_norm': 0.05341460928320885, 'learning_rate': 1.563338105490973e-06, 'epoch': 13.23}
{'loss': 0.0013, 'grad_norm': 0.10263530910015106, 'learning_rate': 1.4329570178331316e-06, 'epoch': 13.31}
{'loss': 0.0013, 'grad_norm': 0.055236220359802246, 'learning_rate': 1.308064876790051e-06, 'epoch': 13.38}
{'loss': 0.0012, 'grad_norm': 0.032080620527267456, 'learning_rate': 1.1886958266260504e-06, 'epoch': 13.46}
{'loss': 0.0014, 'grad_norm': 0.04729108139872551, 'learning_rate': 1.074882501647548e-06, 'epoch': 13.54}
{'loss': 0.0011, 'grad_norm': 0.049114931374788284, 'learning_rate': 9.6665601728118e-07, 'epoch': 13.62}
{'loss': 0.0013, 'grad_norm': 0.0775362178683281, 'learning_rate': 8.64045961567132e-07, 'epoch': 13.69}
{'loss': 0.0011, 'grad_norm': 0.03462788835167885, 'learning_rate': 7.670803870700864e-07, 'epoch': 13.77}
{'loss': 0.0014, 'grad_norm': 0.04830805957317352, 'learning_rate': 6.757858032099112e-07, 'epoch': 13.85}
{'loss': 0.0016, 'grad_norm': 0.10457150638103485, 'learning_rate': 5.901871690142665e-07, 'epoch': 13.92}
{'loss': 0.0011, 'grad_norm': 0.035962603986263275, 'learning_rate': 5.103078862950401e-07, 'epoch': 14.0}
{'eval_loss': 0.005301796831190586, 'eval_runtime': 24.2569, 'eval_samples_per_second': 1.938, 'eval_steps_per_second': 1.938, 'epoch': 14.0}
{'train_runtime': 9760.4635, 'train_samples_per_second': 0.799, 'train_steps_per_second': 0.2, 'train_loss': 0.05218662331392477, 'epoch': 14.0}

================================================================================
‚úÖ TRAINING COMPLETED
================================================================================
   Runtime: 162.67 min
   Peak memory: 19.523 GB
   Training memory: 0.0 GB
================================================================================


üíæ Saving model to /home/vault/iwi5/iwi5298h/models_image_text/nanonets/hpo/inven/final_model...
‚úÖ Model saved successfully!

================================================================================
üìä PHASE 3: TEST SET EVALUATION
================================================================================

================================================================================
üîç STARTING TEST SET EVALUATION (AUTOREGRESSIVE)
================================================================================
üìä Loaded 48 test samples

‚è≥ Processing chunk 1/3 (images 1-20)
   [1/48] Processing: inventarbuch-022.jpg ... ‚ùå Poor CER: 0.440
   [2/48] Processing: inventarbuch-099.jpg ... ‚ùå Poor CER: 0.324
   [3/48] Processing: inventarbuch-245.jpg ... ‚ùå Poor CER: 0.435
   [4/48] Processing: inventarbuch-263.jpg ... ‚ùå Poor CER: 0.392
   [5/48] Processing: inventarbuch-033.jpg ... ‚ùå Poor CER: 0.511
   [6/48] Processing: inventarbuch-143.jpg ... ‚ùå Poor CER: 0.312
   [7/48] Processing: inventarbuch-244.jpg ... ‚ùå Poor CER: 0.524
   [8/48] Processing: inventarbuch-024.jpg ... ‚ùå Poor CER: 0.333
   [9/48] Processing: inventarbuch-141.jpg ... ‚ö†Ô∏è  OK CER: 0.228
   [10/48] Processing: inventarbuch-183.jpg ... ‚ùå Poor CER: 0.466
   [11/48] Processing: inventarbuch-191.jpg ... ‚ùå Poor CER: 0.393
   [12/48] Processing: inventarbuch-051.jpg ... ‚ùå Poor CER: 0.326
   [13/48] Processing: inventarbuch-203.jpg ... ‚ö†Ô∏è  OK CER: 0.275
   [14/48] Processing: inventarbuch-296.jpg ... ‚ùå Poor CER: 0.543
   [15/48] Processing: inventarbuch-302.jpg ... ‚ùå Poor CER: 0.661
   [16/48] Processing: inventarbuch-179.jpg ... ‚ùå Poor CER: 0.408
   [17/48] Processing: inventarbuch-114.jpg ... ‚ùå Poor CER: 0.347
   [18/48] Processing: inventarbuch-082.jpg ... ‚ùå Poor CER: 0.444
   [19/48] Processing: inventarbuch-287.jpg ... ‚ùå Poor CER: 0.597
   [20/48] Processing: inventarbuch-181.jpg ... ‚ùå Poor CER: 0.437

‚è≥ Processing chunk 2/3 (images 21-40)
   [21/48] Processing: inventarbuch-299.jpg ... ‚ùå Poor CER: 0.422
   [22/48] Processing: inventarbuch-084.jpg ... ‚ùå Poor CER: 0.541
   [23/48] Processing: inventarbuch-004.jpg ... ‚ùå Poor CER: 0.326
   [24/48] Processing: inventarbuch-148.jpg ... ‚ö†Ô∏è  OK CER: 0.234
   [25/48] Processing: inventarbuch-238.jpg ... ‚ùå Poor CER: 0.335
   [26/48] Processing: inventarbuch-116.jpg ... ‚ùå Poor CER: 0.379
   [27/48] Processing: inventarbuch-223.jpg ... ‚ùå Poor CER: 0.360
   [28/48] Processing: inventarbuch-104.jpg ... ‚ùå Poor CER: 0.527
   [29/48] Processing: inventarbuch-015.jpg ... ‚ùå Poor CER: 0.359
   [30/48] Processing: inventarbuch-272.jpg ... ‚ùå Poor CER: 0.349
   [31/48] Processing: inventarbuch-124.jpg ... ‚ùå Poor CER: 0.304
   [32/48] Processing: inventarbuch-115.jpg ... ‚ùå Poor CER: 0.308
   [33/48] Processing: inventarbuch-049.jpg ... ‚ùå Poor CER: 0.453
   [34/48] Processing: inventarbuch-017.jpg ... ‚ùå Poor CER: 0.376
   [35/48] Processing: inventarbuch-018.jpg ... ‚ùå Poor CER: 0.377
   [36/48] Processing: inventarbuch-225.jpg ... ‚ùå Poor CER: 0.495
   [37/48] Processing: inventarbuch-046.jpg ... ‚ùå Poor CER: 0.340
   [38/48] Processing: inventarbuch-294.jpg ... ‚ùå Poor CER: 0.303
   [39/48] Processing: inventarbuch-054.jpg ... ‚ùå Poor CER: 0.458
   [40/48] Processing: inventarbuch-073.jpg ... ‚ùå Poor CER: 0.462

‚è≥ Processing chunk 3/3 (images 41-48)
   [41/48] Processing: inventarbuch-118.jpg ... ‚ùå Poor CER: 0.347
   [42/48] Processing: inventarbuch-130.jpg ... ‚ùå Poor CER: 0.320
   [43/48] Processing: inventarbuch-146.jpg ... ‚ùå Poor CER: 0.362
   [44/48] Processing: inventarbuch-014.jpg ... ‚ùå Poor CER: 0.340
   [45/48] Processing: inventarbuch-059.jpg ... ‚ùå Poor CER: 0.395
   [46/48] Processing: inventarbuch-256.jpg ... ‚ö†Ô∏è  OK CER: 0.300
   [47/48] Processing: inventarbuch-260.jpg ... ‚ùå Poor CER: 0.386
   [48/48] Processing: inventarbuch-279.jpg ... ‚ùå Poor CER: 0.438

üíæ Predictions saved to: /home/vault/iwi5/iwi5298h/models_image_text/nanonets/hpo/inven/test_predictions.jsonl
üíæ CER results saved to: /home/vault/iwi5/iwi5298h/models_image_text/nanonets/hpo/inven/cer_evaluation_results.txt

================================================================================
üìä TEST EVALUATION SUMMARY
================================================================================
   Total samples: 48
   Average CER: 0.3958 (39.58%)
   Weighted CER: 0.3940 (39.40%)
   Perfect matches: 0/48
================================================================================


üíæ Final summary saved to: /home/vault/iwi5/iwi5298h/models_image_text/nanonets/hpo/inven/final_summary.txt
üóëÔ∏è  Cleaned up temporary directory: /tmp/1294984.tinygpu/augmented_inventory_sd1knogk

================================================================================
üéâ COMPLETE PIPELINE FINISHED SUCCESSFULLY!
================================================================================

üìÅ Results:
   ‚Ä¢ Final model: /home/vault/iwi5/iwi5298h/models_image_text/nanonets/hpo/inven/final_model
   ‚Ä¢ Test predictions: /home/vault/iwi5/iwi5298h/models_image_text/nanonets/hpo/inven/test_predictions.jsonl
   ‚Ä¢ CER results: /home/vault/iwi5/iwi5298h/models_image_text/nanonets/hpo/inven/cer_evaluation_results.txt
   ‚Ä¢ Summary: /home/vault/iwi5/iwi5298h/models_image_text/nanonets/hpo/inven/final_summary.txt


Nano training completed at: Mon Nov  3 02:57:48 PM CET 2025
=== JOB_STATISTICS ===
=== current date     : Mon Nov  3 02:57:48 PM CET 2025
= Job-ID             : 1294984 on tinygpu
= Job-Name           : inven_hpo
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_nano.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : v100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 20:58:19
= Total RAM usage    : 17.6 GiB of requested  GiB (%)   
= Node list          : tg072
= Subm/Elig/Start/End: 2025-11-02T17:58:20 / 2025-11-02T17:58:20 / 2025-11-02T17:58:21 / 2025-11-03T14:56:40
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody           184.1G  1000.0G  1500.0G        N/A     841K   5,000K   7,500K        N/A    
    /home/hpc             102.2G   104.9G   209.7G        N/A  30,546      500K   1,000K        N/A    
    /home/vault           863.0G  1048.6G  2097.2G        N/A   5,001      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:AF:00.0, 2163176, 40 %, 20 %, 20400 MiB, 75284858 ms
