Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
`torch_dtype` is deprecated! Use `dtype` instead!
Running inference:   0%|          | 0/24 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Running inference:   4%|▍         | 1/24 [00:08<03:07,  8.15s/it]Running inference:   8%|▊         | 2/24 [00:15<02:53,  7.86s/it]Running inference:  12%|█▎        | 3/24 [00:23<02:44,  7.82s/it]Running inference:  17%|█▋        | 4/24 [00:31<02:38,  7.92s/it]Running inference:  21%|██        | 5/24 [00:39<02:28,  7.80s/it]Running inference:  25%|██▌       | 6/24 [00:45<02:12,  7.38s/it]Running inference:  29%|██▉       | 7/24 [00:52<02:03,  7.26s/it]Running inference:  33%|███▎      | 8/24 [01:05<02:25,  9.08s/it]Running inference:  38%|███▊      | 9/24 [01:13<02:11,  8.74s/it]Running inference:  42%|████▏     | 10/24 [01:26<02:20, 10.03s/it]Running inference:  46%|████▌     | 11/24 [01:35<02:05,  9.63s/it]Running inference:  50%|█████     | 12/24 [01:42<01:45,  8.77s/it]Running inference:  54%|█████▍    | 13/24 [01:49<01:31,  8.36s/it]Running inference:  58%|█████▊    | 14/24 [01:56<01:19,  7.96s/it]Running inference:  62%|██████▎   | 15/24 [02:04<01:11,  7.99s/it]Running inference:  67%|██████▋   | 16/24 [02:17<01:15,  9.47s/it]Running inference:  71%|███████   | 17/24 [02:30<01:13, 10.49s/it]Running inference:  75%|███████▌  | 18/24 [02:37<00:57,  9.51s/it]Running inference:  79%|███████▉  | 19/24 [02:44<00:43,  8.64s/it]Running inference:  83%|████████▎ | 20/24 [02:51<00:32,  8.06s/it]Running inference:  88%|████████▊ | 21/24 [02:58<00:24,  8.00s/it]Running inference:  92%|█████████▏| 22/24 [03:11<00:18,  9.46s/it]Running inference:  96%|█████████▌| 23/24 [03:24<00:10, 10.50s/it]Running inference: 100%|██████████| 24/24 [03:33<00:00,  9.84s/it]Running inference: 100%|██████████| 24/24 [03:33<00:00,  8.88s/it]
[W1118 12:51:21.892750767 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
