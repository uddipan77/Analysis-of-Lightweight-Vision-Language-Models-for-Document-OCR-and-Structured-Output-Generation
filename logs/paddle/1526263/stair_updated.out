### Starting TaskPrologue of job 1526263 on tg072 at Sat Feb  7 04:09:53 PM CET 2026
Running on cores 0-1,8-9,16-17,24-25 with governor ondemand
Sat Feb  7 16:09:53 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.211.01             Driver Version: 570.211.01     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           On  |   00000000:18:00.0 Off |                    0 |
| N/A   37C    P0             27W /  250W |       0MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

Configured torch.backends.cuda.sdp_kernel(mem_efficient=True, math=True, flash=False)

============================================================
PADDLEOCR-VL FINETUNING - STAIRCASE DATASET
BEST MODEL SELECTION: CER(GT JSON string vs prediction_stripped_for_cer)
============================================================
Model: PaddlePaddle/PaddleOCR-VL
Local cache: /home/vault/iwi5/iwi5298h/models/PaddleOCR-VL
Output run dir: /home/vault/iwi5/iwi5298h/models_image_text/paddleocr/stair/run_20260207_161015_cer
Prompt task: ocr -> 'OCR:'
Attention impl override: None
Image downscale max side: 768
Max seq length: 1024
Max new tokens (val/test): 256
============================================================

Using device: cuda
Loading PaddleOCR-VL from local cache: /home/vault/iwi5/iwi5298h/models/PaddleOCR-VL
Enabled gradient checkpointing (use_reentrant=False).
Disabled use_cache for training.
Loaded 115 samples from /home/woody/iwi5/iwi5298h/json_staircase/train.jsonl
Loaded 25 samples from /home/woody/iwi5/iwi5298h/json_staircase/val.jsonl
Loaded 24 samples from /home/woody/iwi5/iwi5298h/json_staircase/test.jsonl

============================================================
Epoch 1/10
============================================================
Epoch 1 - train loss: 5.7114

Running validation (CER-based model selection)...
Validation CER macro (PRIMARY): 0.7141 (71.41%)
Validation CER micro:          0.7137 (71.37%)
Validation structured CER (debug): 71.3699%
ðŸŽ¯ New BEST validation macro CER: 0.7141 (71.41%), improvement 0.0000

============================================================
Epoch 2/10
============================================================
Epoch 2 - train loss: 0.3256

Running validation (CER-based model selection)...
Validation CER macro (PRIMARY): 0.8545 (85.45%)
Validation CER micro:          0.8550 (85.50%)
Validation structured CER (debug): 85.4990%
No improvement. Best macro CER remains 0.7141 (71.41%) from epoch 1

============================================================
Epoch 3/10
============================================================
Epoch 3 - train loss: 0.0513

Running validation (CER-based model selection)...
Validation CER macro (PRIMARY): 0.6696 (66.96%)
Validation CER micro:          0.6719 (67.19%)
Validation structured CER (debug): 67.1939%
ðŸŽ¯ New BEST validation macro CER: 0.6696 (66.96%), improvement 0.0445

============================================================
Epoch 4/10
============================================================
Epoch 4 - train loss: 0.0227

Running validation (CER-based model selection)...
Paddle training completed at: Sat Feb  7 07:27:22 PM CET 2026
=== JOB_STATISTICS ===
=== current date     : Sat Feb  7 07:27:22 PM CET 2026
= Job-ID             : 1526263 on tinygpu
= Job-Name           : stair_updated
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_paddle2.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : v100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 03:17:31
= Total RAM usage    : 12.0 GiB of requested  GiB (%)   
= Node list          : tg072
= Subm/Elig/Start/End: 2026-02-07T15:48:48 / 2026-02-07T15:48:48 / 2026-02-07T16:09:51 / 2026-02-07T19:27:22
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody           408.1G  1000.0G  1500.0G        N/A   1,018K   5,000K   7,500K        N/A    
    /home/hpc              91.4G   104.9G   209.7G        N/A  30,023      500K   1,000K        N/A    
    /home/vault           943.8G  1048.6G  2097.2G        N/A   9,491      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:18:00.0, 3059746, 79 %, 25 %, 11842 MiB, 11827216 ms
