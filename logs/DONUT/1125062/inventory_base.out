### Starting TaskPrologue of job 1125062 on tg071 at Sun Jul 20 07:18:30 PM CEST 2025
Running on cores 6-7,14-15,22-23,30-31 with governor ondemand
Sun Jul 20 19:18:30 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.158.01             Driver Version: 570.158.01     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           On  |   00000000:AF:00.0 Off |                    0 |
| N/A   40C    P0             27W /  250W |       0MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

===================================
DONUT Fine-tuning Configuration:
===================================
Job ID: 1125062
Log Directory: /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/logs/DONUT/1125062
Data Directory: /home/woody/iwi5/iwi5298h/json_inventory_images
Image Directory: /home/woody/iwi5/iwi5298h/inventory_images
Model Cache Directory: /home/vault/iwi5/iwi5298h/models/donut_base
Output Directory: /home/vault/iwi5/iwi5298h/models_image_text/donut/inventory/inventory_data_base_20250720_191833
Num Epochs: 50
Batch Size: 2
Learning Rate: 1e-5
Max Length: 512
Prediction On: test
Prediction Batch Size: 2
Early Stopping Patience: 5
Early Stopping Threshold: 0.00
===================================
[2025-07-20 19:19:35,339] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-20 19:19:41,483] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
Using device: cuda
All output will be saved in: /home/vault/iwi5/iwi5298h/models_with_post_process/donut/inventory_data_20250720_191947
Checking for model at: /home/vault/iwi5/iwi5298h/models/donut_base
Downloading model naver-clova-ix/donut-base to /home/vault/iwi5/iwi5298h/models/donut_base...
Saving model to /home/vault/iwi5/iwi5298h/models/donut_base...
Model downloaded and cached successfully!
Loaded 205 samples from /home/woody/iwi5/iwi5298h/json_inventory_images/train.jsonl
Loaded 44 samples from /home/woody/iwi5/iwi5298h/json_inventory_images/val.jsonl
Loaded 45 samples from /home/woody/iwi5/iwi5298h/json_inventory_images/test.jsonl
Starting training...
{'loss': 6.7736, 'grad_norm': 8.286999702453613, 'learning_rate': 4.9000000000000005e-06, 'epoch': 0.49}
{'loss': 4.3569, 'grad_norm': 10.728006362915039, 'learning_rate': 9.9e-06, 'epoch': 0.97}
{'eval_loss': 2.972278594970703, 'eval_runtime': 35.4689, 'eval_samples_per_second': 1.241, 'eval_steps_per_second': 0.62, 'epoch': 1.0}
{'loss': 2.7267, 'grad_norm': 7.679727077484131, 'learning_rate': 9.902970297029704e-06, 'epoch': 1.46}
{'loss': 2.0383, 'grad_norm': 8.513274192810059, 'learning_rate': 9.803960396039604e-06, 'epoch': 1.94}
{'eval_loss': 1.8438212871551514, 'eval_runtime': 35.7193, 'eval_samples_per_second': 1.232, 'eval_steps_per_second': 0.616, 'epoch': 2.0}
{'loss': 1.841, 'grad_norm': 6.693889617919922, 'learning_rate': 9.704950495049505e-06, 'epoch': 2.43}
{'loss': 1.679, 'grad_norm': 6.443860054016113, 'learning_rate': 9.605940594059407e-06, 'epoch': 2.91}
{'eval_loss': 1.6411455869674683, 'eval_runtime': 36.7526, 'eval_samples_per_second': 1.197, 'eval_steps_per_second': 0.599, 'epoch': 3.0}
{'loss': 1.4922, 'grad_norm': 5.269433975219727, 'learning_rate': 9.506930693069307e-06, 'epoch': 3.4}
{'loss': 1.4952, 'grad_norm': 4.928300380706787, 'learning_rate': 9.407920792079208e-06, 'epoch': 3.88}
{'eval_loss': 1.5529866218566895, 'eval_runtime': 35.0354, 'eval_samples_per_second': 1.256, 'eval_steps_per_second': 0.628, 'epoch': 4.0}
{'loss': 1.3905, 'grad_norm': 8.137801170349121, 'learning_rate': 9.30891089108911e-06, 'epoch': 4.37}
{'loss': 1.3257, 'grad_norm': 5.376767635345459, 'learning_rate': 9.20990099009901e-06, 'epoch': 4.85}
{'eval_loss': 1.4883666038513184, 'eval_runtime': 34.722, 'eval_samples_per_second': 1.267, 'eval_steps_per_second': 0.634, 'epoch': 5.0}
{'loss': 1.2095, 'grad_norm': 4.7427544593811035, 'learning_rate': 9.110891089108911e-06, 'epoch': 5.34}
{'loss': 1.2767, 'grad_norm': 4.502388954162598, 'learning_rate': 9.011881188118813e-06, 'epoch': 5.83}
{'eval_loss': 1.4572428464889526, 'eval_runtime': 37.424, 'eval_samples_per_second': 1.176, 'eval_steps_per_second': 0.588, 'epoch': 6.0}
{'loss': 1.1606, 'grad_norm': 3.3240950107574463, 'learning_rate': 8.912871287128714e-06, 'epoch': 6.31}
{'loss': 1.1524, 'grad_norm': 4.96930456161499, 'learning_rate': 8.813861386138614e-06, 'epoch': 6.8}
{'eval_loss': 1.4400649070739746, 'eval_runtime': 35.2342, 'eval_samples_per_second': 1.249, 'eval_steps_per_second': 0.624, 'epoch': 7.0}
{'loss': 1.0864, 'grad_norm': 3.891387939453125, 'learning_rate': 8.714851485148515e-06, 'epoch': 7.28}
{'loss': 1.0976, 'grad_norm': 4.644947052001953, 'learning_rate': 8.615841584158417e-06, 'epoch': 7.77}
{'eval_loss': 1.4454255104064941, 'eval_runtime': 35.4586, 'eval_samples_per_second': 1.241, 'eval_steps_per_second': 0.62, 'epoch': 8.0}
{'loss': 0.9624, 'grad_norm': 3.5549166202545166, 'learning_rate': 8.516831683168317e-06, 'epoch': 8.25}
{'loss': 0.9813, 'grad_norm': 4.013498306274414, 'learning_rate': 8.417821782178218e-06, 'epoch': 8.74}
{'eval_loss': 1.4392393827438354, 'eval_runtime': 35.9194, 'eval_samples_per_second': 1.225, 'eval_steps_per_second': 0.612, 'epoch': 9.0}
{'loss': 0.9759, 'grad_norm': 3.7090466022491455, 'learning_rate': 8.318811881188118e-06, 'epoch': 9.22}
{'loss': 0.8733, 'grad_norm': 5.351269721984863, 'learning_rate': 8.21980198019802e-06, 'epoch': 9.71}
{'eval_loss': 1.4535346031188965, 'eval_runtime': 35.1362, 'eval_samples_per_second': 1.252, 'eval_steps_per_second': 0.626, 'epoch': 10.0}
{'loss': 0.8593, 'grad_norm': 5.3125834465026855, 'learning_rate': 8.120792079207921e-06, 'epoch': 10.19}
{'loss': 0.8823, 'grad_norm': 4.4001665115356445, 'learning_rate': 8.021782178217823e-06, 'epoch': 10.68}
{'eval_loss': 1.458676815032959, 'eval_runtime': 36.0553, 'eval_samples_per_second': 1.22, 'eval_steps_per_second': 0.61, 'epoch': 11.0}
{'loss': 0.7935, 'grad_norm': 4.253840446472168, 'learning_rate': 7.922772277227724e-06, 'epoch': 11.17}
{'loss': 0.7778, 'grad_norm': 3.6226305961608887, 'learning_rate': 7.823762376237624e-06, 'epoch': 11.65}
{'eval_loss': 1.5074936151504517, 'eval_runtime': 36.2875, 'eval_samples_per_second': 1.213, 'eval_steps_per_second': 0.606, 'epoch': 12.0}
{'loss': 0.7294, 'grad_norm': 4.169581413269043, 'learning_rate': 7.724752475247525e-06, 'epoch': 12.14}
{'loss': 0.7349, 'grad_norm': 6.911965847015381, 'learning_rate': 7.625742574257426e-06, 'epoch': 12.62}
{'eval_loss': 1.5338668823242188, 'eval_runtime': 34.8416, 'eval_samples_per_second': 1.263, 'eval_steps_per_second': 0.631, 'epoch': 13.0}
{'loss': 0.7655, 'grad_norm': 3.5444846153259277, 'learning_rate': 7.5267326732673275e-06, 'epoch': 13.11}
{'loss': 0.6803, 'grad_norm': 4.49445915222168, 'learning_rate': 7.427722772277228e-06, 'epoch': 13.59}
{'eval_loss': 1.5590438842773438, 'eval_runtime': 35.8812, 'eval_samples_per_second': 1.226, 'eval_steps_per_second': 0.613, 'epoch': 14.0}
{'train_runtime': 6917.2175, 'train_samples_per_second': 1.482, 'train_steps_per_second': 0.745, 'train_loss': 1.481122854182525, 'epoch': 14.0}
Saving final model and processor...
Model and processor saved.
Generating predictions on test set...
Saving 45 predictions to /home/vault/iwi5/iwi5298h/models_with_post_process/donut/inventory_data_20250720_191947/test_predictions.jsonl
Predictions saved successfully!
CER scores written to /home/vault/iwi5/iwi5298h/models_with_post_process/donut/inventory_data_20250720_191947/final_CER_scores.txt

All outputs saved to: /home/vault/iwi5/iwi5298h/models_with_post_process/donut/inventory_data_20250720_191947

To view TensorBoard loss curves, run:
  tensorboard --logdir /home/vault/iwi5/iwi5298h/models_with_post_process/donut/inventory_data_20250720_191947/tensorboard_logs
===================================
Training completed successfully!
Output directory: /home/vault/iwi5/iwi5298h/models_image_text/donut/inventory/inventory_data_base_20250720_191833
Log directory: /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/logs/DONUT/1125062
Job completed at: Sun Jul 20 09:19:03 PM CEST 2025
=== JOB_STATISTICS ===
=== current date     : Sun Jul 20 09:19:03 PM CEST 2025
= Job-ID             : 1125062 on tinygpu
= Job-Name           : donut_base
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_donut2.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : v100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 15:00:00
= Elapsed runtime    : 02:00:37
= Total RAM usage    : 12.2 GiB of requested  GiB (%)   
= Node list          : tg071
= Subm/Elig/Start/End: 2025-07-20T18:49:51 / 2025-07-20T18:49:51 / 2025-07-20T19:18:28 / 2025-07-20T21:19:05
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody            68.4G  1000.0G  1500.0G        N/A     207K   5,000K   7,500K        N/A    
    /home/hpc              65.6G   104.9G   209.7G        N/A  30,421      500K   1,000K        N/A    
    /home/vault           141.5G  1048.6G  2097.2G        N/A     449      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:AF:00.0, 1946201, 63 %, 28 %, 32490 MiB, 7167951 ms
