### Starting TaskPrologue of job 1306921 on tg072 at Wed Nov  5 04:38:30 PM CET 2025
Running on cores 6-7,14-15,22-23,30-31 with governor ondemand
Wed Nov  5 16:38:30 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           Off |   00000000:AF:00.0 Off |                    0 |
| N/A   30C    P0             26W /  250W |       0MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Created run directory: /home/vault/iwi5/iwi5298h/models_image_text/qwen/multi/inven/run_20251105_164108
Loading Qwen2.5-VL model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.7.3: Fast Qwen2_5_Vl patching. Transformers: 4.51.3.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.1+cu126. CUDA: 7.0. CUDA Toolkit: 12.6. Triton: 3.3.1
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to eager!
Unsloth: Making `model.base_model.model.visual` require gradients
Model loaded successfully with optimized LoRA adapters!
============================================================
STARTING MULTI-STAGE TRAINING WITH TEACHER FORCING + CER SELECTION (PREPROCESSED)
============================================================
Preparing training and validation datasets...
Training: 213 samples, Validation: 47 samples

===== STAGE 1: Warm-up training (no eval, teacher forcing) =====

Unsloth: Model does not have a default image size - using 512
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 3.6934, 'grad_norm': 12.926567077636719, 'learning_rate': 6.000000000000001e-06, 'epoch': 0.37}
{'loss': 2.7332, 'grad_norm': 10.537967681884766, 'learning_rate': 1.8e-05, 'epoch': 0.75}
{'loss': 1.8974, 'grad_norm': nan, 'learning_rate': 3.0000000000000004e-05, 'epoch': 1.15}
{'loss': 1.1863, 'grad_norm': 24.711153030395508, 'learning_rate': 4.080000000000001e-05, 'epoch': 1.52}
{'loss': 1.1641, 'grad_norm': 3.239020347595215, 'learning_rate': 5.280000000000001e-05, 'epoch': 1.9}
{'loss': 0.9734, 'grad_norm': 2.3309266567230225, 'learning_rate': 5.9630650217854145e-05, 'epoch': 2.3}
{'loss': 0.8981, 'grad_norm': 2.7198169231414795, 'learning_rate': 5.5579204930622776e-05, 'epoch': 2.67}
{'loss': 0.9498, 'grad_norm': 3.054361581802368, 'learning_rate': 4.76335575687742e-05, 'epoch': 3.07}
{'loss': 0.6643, 'grad_norm': 22.009384155273438, 'learning_rate': 3.700336091567717e-05, 'epoch': 3.45}
{'loss': 0.6771, 'grad_norm': 3.0786662101745605, 'learning_rate': 2.647387807626488e-05, 'epoch': 3.82}
{'loss': 0.6551, 'grad_norm': 2.370837926864624, 'learning_rate': 1.5341362755091364e-05, 'epoch': 4.22}
{'loss': 0.5436, 'grad_norm': 3.736318826675415, 'learning_rate': 6.4404920735776595e-06, 'epoch': 4.6}
{'loss': 0.5212, 'grad_norm': 2.7805287837982178, 'learning_rate': 1.1263429063905852e-06, 'epoch': 4.97}
{'train_runtime': 1404.2496, 'train_samples_per_second': 0.758, 'train_steps_per_second': 0.093, 'train_loss': 1.2736395579117996, 'epoch': 4.97}

===== STAGE 2: Main training (eval each epoch, CER-based best model) =====

Unsloth: Model does not have a default image size - using 512
GPU = Tesla V100-PCIE-32GB. Max memory = 31.733 GB.
9.631 GB of memory reserved.
{'loss': 0.4375, 'grad_norm': 2.9208998680114746, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.37}
{'loss': 0.4914, 'grad_norm': 3.1585865020751953, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.75}
{'eval_loss': 1.1016875505447388, 'eval_runtime': 21.0313, 'eval_samples_per_second': 2.235, 'eval_steps_per_second': 1.141, 'epoch': 0.97}

[ValidationCERCallback] Computing CER on 47 validation samples...

[ValidationCERCallback] Epoch 0.97 CER: 0.2329 (23.29%)
[ValidationCERCallback] New best CER: 0.2329 (improved by inf)
[ValidationCERCallback] Saving best CER model to /home/vault/iwi5/iwi5298h/models_image_text/qwen/multi/inven/run_20251105_164108/best_model_cer
{'loss': 0.4962, 'grad_norm': 2.2512810230255127, 'learning_rate': 1.1200000000000001e-05, 'epoch': 1.15}
{'loss': 0.4061, 'grad_norm': 2.9015140533447266, 'learning_rate': 1.4400000000000001e-05, 'epoch': 1.52}
{'loss': 0.4321, 'grad_norm': 4.413610935211182, 'learning_rate': 1.8400000000000003e-05, 'epoch': 1.9}
{'eval_loss': 1.1520699262619019, 'eval_runtime': 20.6293, 'eval_samples_per_second': 2.278, 'eval_steps_per_second': 1.163, 'epoch': 1.97}

[ValidationCERCallback] Computing CER on 47 validation samples...

[ValidationCERCallback] Epoch 1.97 CER: 0.2491 (24.91%)
[ValidationCERCallback] No improvement. Best CER remains 0.2329
{'loss': 0.3193, 'grad_norm': 2.626263380050659, 'learning_rate': 1.9991958847061786e-05, 'epoch': 2.3}
{'loss': 0.2969, 'grad_norm': 3.519353151321411, 'learning_rate': 1.9942865292219837e-05, 'epoch': 2.67}
{'eval_loss': 1.2512139081954956, 'eval_runtime': 20.2059, 'eval_samples_per_second': 2.326, 'eval_steps_per_second': 1.188, 'epoch': 2.97}

[ValidationCERCallback] Computing CER on 47 validation samples...

[ValidationCERCallback] Epoch 2.97 CER: 0.2377 (23.77%)
[ValidationCERCallback] No improvement. Best CER remains 0.2329
{'loss': 0.316, 'grad_norm': 2.6862714290618896, 'learning_rate': 1.984936448731556e-05, 'epoch': 3.07}
{'loss': 0.1702, 'grad_norm': 5.171763896942139, 'learning_rate': 1.971187402964132e-05, 'epoch': 3.45}
{'loss': 0.1797, 'grad_norm': 3.8488402366638184, 'learning_rate': 1.9551024972069127e-05, 'epoch': 3.82}
{'eval_loss': 1.327614426612854, 'eval_runtime': 20.2779, 'eval_samples_per_second': 2.318, 'eval_steps_per_second': 1.184, 'epoch': 3.97}

[ValidationCERCallback] Computing CER on 47 validation samples...

[ValidationCERCallback] Epoch 3.97 CER: 0.2469 (24.69%)
[ValidationCERCallback] No improvement. Best CER remains 0.2329
{'train_runtime': 5516.2087, 'train_samples_per_second': 0.772, 'train_steps_per_second': 0.094, 'train_loss': 0.3513053242976849, 'epoch': 3.97}
5516.2087 seconds used for training.
91.94 minutes used for training.
Peak reserved memory = 10.111 GB.
Peak reserved memory for training = 0.48 GB.
Peak reserved memory % of max memory = 31.863 %.
Peak reserved memory for training % of max memory = 1.513 %.

[train_model] Best CER model saved at /home/vault/iwi5/iwi5298h/models_image_text/qwen/multi/inven/run_20251105_164108/best_model_cer (CER=0.2329).
Saving final trainer model to /home/vault/iwi5/iwi5298h/models_image_text/qwen/multi/inven/run_20251105_164108...
Final trainer model saved. Best-CER model (if found) is under: /home/vault/iwi5/iwi5298h/models_image_text/qwen/multi/inven/run_20251105_164108/best_model_cer

============================================================
STARTING EVALUATION ON TEST.JSONL (USING IN-MEMORY MODEL)
============================================================
Starting evaluation on test.jsonl...
Loaded 48 test samples
Processing test image 1/48: inventarbuch-022.jpg
  Processed successfully. CER: 0.234
Processing test image 2/48: inventarbuch-099.jpg
  Processed successfully. CER: 0.144
Processing test image 3/48: inventarbuch-245.jpg
  Processed successfully. CER: 0.243
Processing test image 4/48: inventarbuch-263.jpg
  Processed successfully. CER: 0.157
Processing test image 5/48: inventarbuch-033.jpg
  Processed successfully. CER: 0.323
Processing test image 6/48: inventarbuch-143.jpg
  Processed successfully. CER: 0.163
Processing test image 7/48: inventarbuch-244.jpg
  Processed successfully. CER: 0.399
Processing test image 8/48: inventarbuch-024.jpg
  Processed successfully. CER: 0.053
Processing test image 9/48: inventarbuch-141.jpg
  Processed successfully. CER: 0.104
Processing test image 10/48: inventarbuch-183.jpg
  Processed successfully. CER: 0.369
Processing test image 11/48: inventarbuch-191.jpg
  Processed successfully. CER: 0.238
Processing test image 12/48: inventarbuch-051.jpg
  Processed successfully. CER: 0.089
Processing test image 13/48: inventarbuch-203.jpg
  Processed successfully. CER: 0.179
Processing test image 14/48: inventarbuch-296.jpg
  Processed successfully. CER: 0.242
Processing test image 15/48: inventarbuch-302.jpg
  Processed successfully. CER: 0.040
Processing test image 16/48: inventarbuch-179.jpg
  Processed successfully. CER: 0.239
Processing test image 17/48: inventarbuch-114.jpg
  Processed successfully. CER: 0.246
Processing test image 18/48: inventarbuch-082.jpg
  Processed successfully. CER: 0.330
Processing test image 19/48: inventarbuch-287.jpg
  Processed successfully. CER: 0.339
Processing test image 20/48: inventarbuch-181.jpg
  Processed successfully. CER: 0.255
Processing test image 21/48: inventarbuch-299.jpg
  Processed successfully. CER: 0.265
Processing test image 22/48: inventarbuch-084.jpg
  Processed successfully. CER: 0.404
Processing test image 23/48: inventarbuch-004.jpg
  Processed successfully. CER: 0.190
Processing test image 24/48: inventarbuch-148.jpg
  Processed successfully. CER: 0.125
Processing test image 25/48: inventarbuch-238.jpg
  Processed successfully. CER: 0.228
Processing test image 26/48: inventarbuch-116.jpg
  Processed successfully. CER: 0.134
Processing test image 27/48: inventarbuch-223.jpg
  Processed successfully. CER: 0.186
Processing test image 28/48: inventarbuch-104.jpg
  Processed successfully. CER: 0.268
Processing test image 29/48: inventarbuch-015.jpg
  Processed successfully. CER: 0.204
Processing test image 30/48: inventarbuch-272.jpg
  Processed successfully. CER: 0.237
Processing test image 31/48: inventarbuch-124.jpg
  Processed successfully. CER: 0.136
Processing test image 32/48: inventarbuch-115.jpg
  Processed successfully. CER: 0.247
Processing test image 33/48: inventarbuch-049.jpg
  Processed successfully. CER: 0.022
Processing test image 34/48: inventarbuch-017.jpg
  Processed successfully. CER: 0.047
Processing test image 35/48: inventarbuch-018.jpg
  Processed successfully. CER: 0.216
Processing test image 36/48: inventarbuch-225.jpg
  Processed successfully. CER: 0.367
Processing test image 37/48: inventarbuch-046.jpg
  Processed successfully. CER: 0.261
Processing test image 38/48: inventarbuch-294.jpg
  Processed successfully. CER: 0.143
Processing test image 39/48: inventarbuch-054.jpg
  Processed successfully. CER: 0.327
Processing test image 40/48: inventarbuch-073.jpg
  Processed successfully. CER: 0.334
Processing test image 41/48: inventarbuch-118.jpg
  Processed successfully. CER: 0.240
Processing test image 42/48: inventarbuch-130.jpg
  Processed successfully. CER: 0.193
Processing test image 43/48: inventarbuch-146.jpg
  Processed successfully. CER: 0.249
Processing test image 44/48: inventarbuch-014.jpg
  Processed successfully. CER: 0.222
Processing test image 45/48: inventarbuch-059.jpg
  Processed successfully. CER: 0.183
Processing test image 46/48: inventarbuch-256.jpg
  Processed successfully. CER: 0.190
Processing test image 47/48: inventarbuch-260.jpg
  Processed successfully. CER: 0.242
Processing test image 48/48: inventarbuch-279.jpg
  Processed successfully. CER: 0.287
CER evaluation results saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/multi/inven/run_20251105_164108/cer_evaluation_results.txt

Evaluation completed!
Predictions saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/multi/inven/run_20251105_164108/test_predictions.jsonl
CER results saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/multi/inven/run_20251105_164108/cer_evaluation_results.txt
All files saved in: /home/vault/iwi5/iwi5298h/models_image_text/qwen/multi/inven/run_20251105_164108

============================================================
FINAL RESULTS SUMMARY
============================================================
Average CER: 0.2195 (21.95%)
Median CER: 0.2356 (23.56%)
Perfect matches: 0/48 (0.00%)
Total images processed: 48

Training and evaluation completed successfully!
All outputs saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/multi/inven/run_20251105_164108
=== JOB_STATISTICS ===
=== current date     : Wed Nov  5 07:00:56 PM CET 2025
= Job-ID             : 1306921 on tinygpu
= Job-Name           : qwen_inven_ms
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_qwen.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : v100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 02:22:31
= Total RAM usage    : 18.6 GiB of requested  GiB (%)   
= Node list          : tg072
= Subm/Elig/Start/End: 2025-11-05T16:37:13 / 2025-11-05T16:37:13 / 2025-11-05T16:37:14 / 2025-11-05T18:59:45
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody           184.1G  1000.0G  1500.0G        N/A     841K   5,000K   7,500K        N/A    
    /home/hpc             102.2G   104.9G   209.7G        N/A  30,682      500K   1,000K        N/A    
    /home/vault           902.3G  1048.6G  2097.2G        N/A   5,767      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:AF:00.0, 2389702, 33 %, 14 %, 10764 MiB, 8455333 ms
