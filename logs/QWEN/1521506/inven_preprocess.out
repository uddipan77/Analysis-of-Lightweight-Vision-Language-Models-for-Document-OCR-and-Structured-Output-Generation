### Starting TaskPrologue of job 1521506 on tg071 at Sun Feb  1 09:38:15 AM CET 2026
Running on cores 6-7,14-15,22-23,30-31 with governor ondemand
Sun Feb  1 09:38:15 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.211.01             Driver Version: 570.211.01     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           On  |   00000000:AF:00.0 Off |                    0 |
| N/A   30C    P0             25W /  250W |       0MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Unsloth: We'll be using `/tmp/1521506.tinygpu/unsloth_compiled_cache` for temporary Unsloth patches.
Standard import failed for UnslothDDPOTrainer: name 's' is not defined. Using tempfile instead!
Created run directory: /home/vault/iwi5/iwi5298h/models_image_text/qwen/inventory_dataset/run_20260201_093903
Loading Qwen2.5-VL model from /home/vault/iwi5/iwi5298h/models/qwen7b with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.7.3: Fast Qwen2_5_Vl patching. Transformers: 4.51.3.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.1+cu126. CUDA: 7.0. CUDA Toolkit: 12.6. Triton: 3.3.1
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to eager!
Unsloth: Making `model.base_model.model.visual` require gradients
Model loaded successfully with LoRA (r=16, no offload)!
============================================================
STARTING INVENTORY DATASET TRAINING (BEST MODEL BY VALIDATION CER)
============================================================
Preparing training and validation datasets...
Preparing training data from /home/woody/iwi5/iwi5298h/json_inven/train.jsonl ...
Training samples prepared: 213
Validation samples: 47
Training: 213 samples, Validation (raw): 47 records
Unsloth: Model does not have a default image size - using 512
GPU = Tesla V100-PCIE-32GB. Max memory = 31.733 GB.
7.854 GB of memory reserved.
Starting training (best model tracked by CER callback)...
=== JOB_STATISTICS ===
=== current date     : Sun Feb  1 09:42:56 AM CET 2026
= Job-ID             : 1521506 on tinygpu
= Job-Name           : inven_preprocess
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_qwen2.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : v100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 00:04:43
= Total RAM usage    : 8.9 GiB of requested  GiB (%)   
= Node list          : tg071
= Subm/Elig/Start/End: 2026-02-01T00:59:58 / 2026-02-01T00:59:58 / 2026-02-01T09:38:13 / 2026-02-01T09:42:56
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc              88.1G   104.9G   209.7G        N/A  29,344      500K   1,000K        N/A    
    /home/woody           408.0G  1000.0G  1500.0G        N/A   1,017K   5,000K   7,500K        N/A    
    /home/vault           750.4G  1048.6G  2097.2G        N/A   8,467      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:AF:00.0, 3354036, 2 %, 0 %, 8426 MiB, 269549 ms
