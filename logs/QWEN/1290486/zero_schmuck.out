### Starting TaskPrologue of job 1290486 on tg071 at Sun Oct 26 09:58:32 PM CET 2025
Running on cores 2-3,10-11,16,19,26-27 with governor ondemand
Sun Oct 26 21:58:32 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           Off |   00000000:3B:00.0 Off |                    0 |
| N/A   34C    P0             27W /  250W |       0MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

===================================
TrOCR Training Job Configuration:
===================================
Job ID: 1290486
Log Directory: /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/logs/QWEN/1290486
CUDA Device: 0
Job started at: Sun Oct 26 09:58:34 PM CET 2025
===================================
============================================================
QWEN2.5-VL ZERO-SHOT JEWELRY CATALOG OCR PROCESSING
============================================================

Loading test data...
Loaded 89 test samples

Note: Using ZERO-SHOT learning (no training examples)
Loading Qwen2.5-VL model...
Model loaded successfully!

Processing 89 test images with zero-shot prompting...
------------------------------------------------------------
Processing image 1/89: SCH_2891_118.jpg
Error processing SCH_2891_118.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 2/89: SCH_2891_225.jpg
Error processing SCH_2891_225.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 3/89: SCH_3071.jpg
Error processing SCH_3071.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 4/89: SCH_3213.jpg
Error processing SCH_3213.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 5/89: SCH_3129.jpg
Error processing SCH_3129.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 6/89: SCH_2984.jpg
Error processing SCH_2984.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 7/89: SCH_2891_162.jpg
Error processing SCH_2891_162.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 8/89: SCH_3043.jpg
Error processing SCH_3043.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 9/89: SCH_3005.jpg
Error processing SCH_3005.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 10/89: SCH_3192_41.jpg
Error processing SCH_3192_41.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 11/89: SCH_2106.jpg
Error processing SCH_2106.jpg: CUDA out of memory. Tried to allocate 118.03 GiB. GPU 0 has a total capacity of 31.73 GiB of which 13.66 GiB is free. Including non-PyTorch memory, this process has 18.06 GiB memory in use. Of the allocated memory 17.67 GiB is allocated by PyTorch, and 27.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 12/89: SCH_2891_143.jpg
Error processing SCH_2891_143.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 13/89: SCH_2892.jpg
Error processing SCH_2892.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 14/89: SCH_2891_211.jpg
Error processing SCH_2891_211.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 15/89: SCH_3170.jpg
Error processing SCH_3170.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 16/89: SCH_2891_73.jpg
Error processing SCH_2891_73.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 17/89: SCH_2087.jpg
Error processing SCH_2087.jpg: CUDA out of memory. Tried to allocate 118.03 GiB. GPU 0 has a total capacity of 31.73 GiB of which 13.66 GiB is free. Including non-PyTorch memory, this process has 18.06 GiB memory in use. Of the allocated memory 17.67 GiB is allocated by PyTorch, and 27.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 18/89: SCH_2891_222.jpg
Error processing SCH_2891_222.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 19/89: SCH_2891_63.jpg
Error processing SCH_2891_63.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 20/89: SCH_2891_145.jpg
Error processing SCH_2891_145.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 21/89: SCH_2891_292.jpg
Error processing SCH_2891_292.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 22/89: SCH_3030.jpg
Error processing SCH_3030.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 23/89: SCH_3220.jpg
Error processing SCH_3220.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 24/89: SCH_3179.jpg
Error processing SCH_3179.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 25/89: SCH_3239.jpg
Error processing SCH_3239.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 26/89: SCH_3192_6.jpg
Error processing SCH_3192_6.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 27/89: SCH_2891_142.jpg
Error processing SCH_2891_142.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 28/89: SCH_2891_53.jpg
Error processing SCH_2891_53.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 29/89: SCH_2891_262_263.jpg
Error processing SCH_2891_262_263.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 30/89: SCH_2891_282.jpg
Error processing SCH_2891_282.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 31/89: SCH_3218.jpg
Error processing SCH_3218.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 32/89: SCH_2891_275.jpg
Error processing SCH_2891_275.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 33/89: SCH_3002.jpg
Error processing SCH_3002.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 34/89: SCH_3137_a.jpg
Error processing SCH_3137_a.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 35/89: SCH_3131.jpg
Error processing SCH_3131.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 36/89: SCH_3192_36.jpg
Error processing SCH_3192_36.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 37/89: SCH_3165.jpg
Error processing SCH_3165.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 38/89: SCH_3192_14.jpg
Error processing SCH_3192_14.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 39/89: SCH_2891_173.jpg
Error processing SCH_2891_173.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 40/89: SCH_2891_72.jpg
Error processing SCH_2891_72.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 41/89: SCH_2067_recto.jpg
Error processing SCH_2067_recto.jpg: CUDA out of memory. Tried to allocate 118.03 GiB. GPU 0 has a total capacity of 31.73 GiB of which 13.66 GiB is free. Including non-PyTorch memory, this process has 18.06 GiB memory in use. Of the allocated memory 17.67 GiB is allocated by PyTorch, and 27.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 42/89: SCH_3192_4.jpg
Error processing SCH_3192_4.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 43/89: SCH_2891_29_30.jpg
Error processing SCH_2891_29_30.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 44/89: SCH_2891_272.jpg
Error processing SCH_2891_272.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 45/89: SCH_2891_177.jpg
Error processing SCH_2891_177.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 46/89: SCH_3192_13.jpg
Error processing SCH_3192_13.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 47/89: SCH_2891_291.jpg
Error processing SCH_2891_291.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 48/89: SCH_3192_60.jpg
Error processing SCH_3192_60.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 49/89: SCH_3124.jpg
Error processing SCH_3124.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 50/89: SCH_3026.jpg
Error processing SCH_3026.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 51/89: SCH_2065.jpg
Error processing SCH_2065.jpg: CUDA out of memory. Tried to allocate 118.03 GiB. GPU 0 has a total capacity of 31.73 GiB of which 13.66 GiB is free. Including non-PyTorch memory, this process has 18.06 GiB memory in use. Of the allocated memory 17.67 GiB is allocated by PyTorch, and 27.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 52/89: SCH_2891_138.jpg
Error processing SCH_2891_138.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 53/89: SCH_2891_245.jpg
Error processing SCH_2891_245.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 54/89: SCH_2891_268.jpg
Error processing SCH_2891_268.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 55/89: SCH_3192_32.jpg
Error processing SCH_3192_32.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 56/89: SCH_2891_293.jpg
Error processing SCH_2891_293.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 57/89: SCH_3192_27.jpg
Error processing SCH_3192_27.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 58/89: SCH_3174.jpg
Error processing SCH_3174.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 59/89: SCH_2891_235_236.jpg
Error processing SCH_2891_235_236.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 60/89: SCH_2891_59.jpg
Error processing SCH_2891_59.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 61/89: SCH_3211.jpg
Error processing SCH_3211.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 62/89: SCH_3141.jpg
Error processing SCH_3141.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 63/89: SCH_2891_241.jpg
Error processing SCH_2891_241.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 64/89: SCH_3171.jpg
Error processing SCH_3171.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 65/89: SCH_3215.jpg
Error processing SCH_3215.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 66/89: SCH_1938.jpg
Error processing SCH_1938.jpg: CUDA out of memory. Tried to allocate 118.03 GiB. GPU 0 has a total capacity of 31.73 GiB of which 13.66 GiB is free. Including non-PyTorch memory, this process has 18.06 GiB memory in use. Of the allocated memory 17.67 GiB is allocated by PyTorch, and 27.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 67/89: SCH_2891_153_154.jpg
Error processing SCH_2891_153_154.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 68/89: SCH_2997.jpg
Error processing SCH_2997.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 69/89: SCH_2891_64.jpg
Error processing SCH_2891_64.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 70/89: SCH_2944.jpg
Error processing SCH_2944.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 71/89: SCH_3173_ab.jpg
Error processing SCH_3173_ab.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 72/89: SCH_2891_41.jpg
Error processing SCH_2891_41.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 73/89: SCH_2032.jpg
Error processing SCH_2032.jpg: CUDA out of memory. Tried to allocate 118.03 GiB. GPU 0 has a total capacity of 31.73 GiB of which 13.66 GiB is free. Including non-PyTorch memory, this process has 18.06 GiB memory in use. Of the allocated memory 17.67 GiB is allocated by PyTorch, and 27.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 74/89: SCH_3078.jpg
Error processing SCH_3078.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 75/89: SCH_2891_77_78.jpg
Error processing SCH_2891_77_78.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 76/89: SCH_2891_62.jpg
Error processing SCH_2891_62.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 77/89: SCH_3192_28.jpg
Error processing SCH_3192_28.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 78/89: SCH_2043_recto.jpg
Error processing SCH_2043_recto.jpg: CUDA out of memory. Tried to allocate 118.03 GiB. GPU 0 has a total capacity of 31.73 GiB of which 13.66 GiB is free. Including non-PyTorch memory, this process has 18.06 GiB memory in use. Of the allocated memory 17.67 GiB is allocated by PyTorch, and 27.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 79/89: SCH_2045.jpg
Error processing SCH_2045.jpg: CUDA out of memory. Tried to allocate 118.03 GiB. GPU 0 has a total capacity of 31.73 GiB of which 13.66 GiB is free. Including non-PyTorch memory, this process has 18.06 GiB memory in use. Of the allocated memory 17.67 GiB is allocated by PyTorch, and 27.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 80/89: SCH_2965.jpg
Error processing SCH_2965.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 81/89: SCH_3192_22.jpg
Error processing SCH_3192_22.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 82/89: SCH_3133_a.jpg
Error processing SCH_3133_a.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 83/89: SCH_3192_37.jpg
Error processing SCH_3192_37.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 84/89: SCH_3195_9.jpg
Error processing SCH_3195_9.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 85/89: SCH_2891_67_recto.jpg
Error processing SCH_2891_67_recto.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 86/89: SCH_2891_99.jpg
Error processing SCH_2891_99.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 87/89: SCH_2891_150.jpg
Error processing SCH_2891_150.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 88/89: SCH_2025.jpg
Error processing SCH_2025.jpg: CUDA out of memory. Tried to allocate 118.03 GiB. GPU 0 has a total capacity of 31.73 GiB of which 13.66 GiB is free. Including non-PyTorch memory, this process has 18.06 GiB memory in use. Of the allocated memory 17.67 GiB is allocated by PyTorch, and 27.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing image 89/89: SCH_3192_48.jpg
Error processing SCH_3192_48.jpg: CUDA out of memory. Tried to allocate 23.43 GiB. GPU 0 has a total capacity of 31.73 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 16.85 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, and 46.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Saving results to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/shots_schmuck/run_zeroshot_20251026_220722
Predictions saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/shots_schmuck/run_zeroshot_20251026_220722/predictions_zeroshot.jsonl

============================================================
QWEN2.5-VL ZERO-SHOT CER EVALUATION RESULTS
JEWELRY CATALOG DATASET
============================================================

CER Statistics across 89 images:
--------------------------------------------------
Average CER: 1.0000 (100.00%)
Minimum CER: 1.0000 (100.00%)
Maximum CER: 1.0000 (100.00%)

Weighted CER: 1.0000 (100.00%)
Total characters: 31651
Total errors: 31651
Perfect matches: 0/89 (0.0%)

Summary saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/shots_schmuck/run_zeroshot_20251026_220722/evaluation_summary_zeroshot.json

============================================================
ZERO-SHOT PROCESSING COMPLETE!
============================================================
Model: Qwen2.5-VL-7B-Instruct
Dataset: Jewelry Catalog
Method: Zero-Shot Learning (no training examples)
Results saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/shots_schmuck/run_zeroshot_20251026_220722
Total images processed: 89
Average CER on test set: 1.0000 (100.00%)
============================================================

=== JOB_STATISTICS ===
=== current date     : Sun Oct 26 10:07:24 PM CET 2025
= Job-ID             : 1290486 on tinygpu
= Job-Name           : zero_schmuck
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_qwen_shots.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : v100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 02:00:00
= Elapsed runtime    : 00:08:53
= Total RAM usage    : 17.9 GiB of requested  GiB (%)   
= Node list          : tg071
= Subm/Elig/Start/End: 2025-10-26T21:58:13 / 2025-10-26T21:58:13 / 2025-10-26T21:58:14 / 2025-10-26T22:07:07
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody           183.6G  1000.0G  1500.0G        N/A     833K   5,000K   7,500K        N/A    
    /home/hpc             101.9G   104.9G   209.7G        N/A  29,972      500K   1,000K        N/A    
    /home/vault           849.3G  1048.6G  2097.2G        N/A   4,585      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:3B:00.0, 3692445, 48 %, 4 %, 32488 MiB, 501745 ms
