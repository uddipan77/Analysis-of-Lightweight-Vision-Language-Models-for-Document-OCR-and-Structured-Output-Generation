Unsloth: KwargsForCausalLM cannot be inherited from TransformersKwargs since it's of type = <class 'type'>
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:31, 37.83s/it]Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:16<01:55, 38.58s/it]Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:55<01:17, 38.73s/it]Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:34<00:38, 38.79s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:44<00:00, 28.21s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:44<00:00, 32.84s/it]
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
  0%|          | 0/180 [00:00<?, ?it/s]Unsloth: Not an error, but Qwen2_5_VLForConditionalGeneration does not accept `num_items_in_batch`.
Using gradient accumulation will be very slightly less accurate.
Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 1/180 [00:20<59:59, 20.11s/it]  1%|          | 2/180 [00:39<58:12, 19.62s/it]  2%|â–         | 3/180 [00:59<57:53, 19.62s/it]  2%|â–         | 4/180 [01:17<55:44, 19.00s/it]  3%|â–Ž         | 5/180 [01:33<52:49, 18.11s/it]  3%|â–Ž         | 6/180 [01:50<51:36, 17.80s/it]  4%|â–         | 7/180 [02:08<51:37, 17.90s/it]  4%|â–         | 8/180 [02:26<51:19, 17.91s/it]  5%|â–Œ         | 9/180 [02:45<51:45, 18.16s/it]
  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|â–ˆâ–ˆâ–       | 2/9 [00:01<00:03,  1.80it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:03<00:07,  1.29s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:04<00:06,  1.23s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:09<00:10,  2.53s/it][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:10<00:06,  2.07s/it][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:15<00:05,  2.82s/it][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:16<00:02,  2.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:20<00:00,  3.00s/it][A                                               
                                             [A  5%|â–Œ         | 9/180 [03:23<51:45, 18.16s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:26<00:00,  3.00s/it][A
                                             [A  6%|â–Œ         | 10/180 [03:51<1:33:05, 32.86s/it]                                                    6%|â–Œ         | 10/180 [03:51<1:33:05, 32.86s/it]  6%|â–Œ         | 11/180 [04:09<1:20:16, 28.50s/it]  7%|â–‹         | 12/180 [04:29<1:11:52, 25.67s/it]  7%|â–‹         | 13/180 [04:46<1:04:13, 23.07s/it]  8%|â–Š         | 14/180 [05:04<59:36, 21.55s/it]    8%|â–Š         | 15/180 [05:22<56:28, 20.54s/it]  9%|â–‰         | 16/180 [05:40<53:45, 19.67s/it]  9%|â–‰         | 17/180 [05:59<52:49, 19.44s/it] 10%|â–ˆ         | 18/180 [06:16<50:32, 18.72s/it]
  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|â–ˆâ–ˆâ–       | 2/9 [00:01<00:03,  1.89it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:03<00:07,  1.20s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:04<00:05,  1.14s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:07<00:07,  1.94s/it][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:08<00:04,  1.65s/it][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:12<00:04,  2.36s/it][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:13<00:01,  1.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:17<00:00,  2.63s/it][A                                                
                                             [A 10%|â–ˆ         | 18/180 [06:49<50:32, 18.72s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:22<00:00,  2.63s/it][A
                                             [A 11%|â–ˆ         | 19/180 [07:15<1:22:56, 30.91s/it] 11%|â–ˆ         | 20/180 [07:33<1:12:07, 27.05s/it]                                                   11%|â–ˆ         | 20/180 [07:33<1:12:07, 27.05s/it] 12%|â–ˆâ–        | 21/180 [07:51<1:04:23, 24.30s/it] 12%|â–ˆâ–        | 22/180 [08:09<59:07, 22.45s/it]   13%|â–ˆâ–Ž        | 23/180 [08:27<54:57, 21.00s/it] 13%|â–ˆâ–Ž        | 24/180 [08:44<52:09, 20.06s/it] 14%|â–ˆâ–        | 25/180 [09:04<51:13, 19.83s/it] 14%|â–ˆâ–        | 26/180 [09:21<48:36, 18.94s/it] 15%|â–ˆâ–Œ        | 27/180 [09:39<47:53, 18.78s/it]
  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|â–ˆâ–ˆâ–       | 2/9 [00:01<00:03,  1.78it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:03<00:07,  1.24s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:04<00:05,  1.19s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:07<00:07,  1.99s/it][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:09<00:05,  1.70s/it][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:12<00:04,  2.43s/it][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:14<00:02,  2.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:18<00:00,  2.69s/it][A                                                
                                             [A 15%|â–ˆâ–Œ        | 27/180 [10:12<47:53, 18.78s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:23<00:00,  2.69s/it][A
                                             [A 16%|â–ˆâ–Œ        | 28/180 [10:38<1:18:05, 30.83s/it] 16%|â–ˆâ–Œ        | 29/180 [10:55<1:07:06, 26.66s/it] 17%|â–ˆâ–‹        | 30/180 [11:13<59:54, 23.96s/it]                                                   17%|â–ˆâ–‹        | 30/180 [11:13<59:54, 23.96s/it] 17%|â–ˆâ–‹        | 31/180 [11:30<54:35, 21.98s/it] 18%|â–ˆâ–Š        | 32/180 [11:48<51:16, 20.78s/it] 18%|â–ˆâ–Š        | 33/180 [12:05<48:23, 19.75s/it] 19%|â–ˆâ–‰        | 34/180 [12:24<47:30, 19.52s/it] 19%|â–ˆâ–‰        | 35/180 [12:43<46:38, 19.30s/it] 20%|â–ˆâ–ˆ        | 36/180 [13:02<46:15, 19.28s/it]
  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|â–ˆâ–ˆâ–       | 2/9 [00:01<00:03,  1.83it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:03<00:07,  1.24s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:04<00:05,  1.19s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:07<00:07,  2.00s/it][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:09<00:05,  1.70s/it][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:12<00:04,  2.41s/it][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:14<00:01,  2.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:18<00:00,  2.67s/it][A                                                
                                             [A 20%|â–ˆâ–ˆ        | 36/180 [13:36<46:15, 19.28s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:23<00:00,  2.67s/it][A
                                             [A 21%|â–ˆâ–ˆ        | 37/180 [14:01<1:14:25, 31.23s/it] 21%|â–ˆâ–ˆ        | 38/180 [14:21<1:05:26, 27.65s/it] 22%|â–ˆâ–ˆâ–       | 39/180 [14:38<58:01, 24.69s/it]   22%|â–ˆâ–ˆâ–       | 40/180 [14:57<53:37, 22.99s/it]                                                 22%|â–ˆâ–ˆâ–       | 40/180 [14:57<53:37, 22.99s/it] 23%|â–ˆâ–ˆâ–Ž       | 41/180 [15:16<50:25, 21.77s/it] 23%|â–ˆâ–ˆâ–Ž       | 42/180 [15:33<46:49, 20.36s/it] 24%|â–ˆâ–ˆâ–       | 43/180 [15:51<44:14, 19.38s/it] 24%|â–ˆâ–ˆâ–       | 44/180 [16:08<42:41, 18.83s/it] 25%|â–ˆâ–ˆâ–Œ       | 45/180 [16:27<42:34, 18.92s/it]
  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|â–ˆâ–ˆâ–       | 2/9 [00:01<00:03,  1.83it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:03<00:07,  1.23s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:04<00:05,  1.19s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:07<00:07,  2.00s/it][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:09<00:05,  1.70s/it][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:12<00:04,  2.43s/it][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:14<00:02,  2.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:18<00:00,  2.69s/it][A                                                
                                             [A 25%|â–ˆâ–ˆâ–Œ       | 45/180 [17:00<42:34, 18.92s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:23<00:00,  2.69s/it][A
                                             [A 26%|â–ˆâ–ˆâ–Œ       | 46/180 [17:26<1:09:01, 30.91s/it] 26%|â–ˆâ–ˆâ–Œ       | 47/180 [17:45<1:00:13, 27.17s/it] 27%|â–ˆâ–ˆâ–‹       | 48/180 [18:01<52:39, 23.94s/it]   27%|â–ˆâ–ˆâ–‹       | 49/180 [18:18<48:06, 22.03s/it] 28%|â–ˆâ–ˆâ–Š       | 50/180 [18:37<45:24, 20.96s/it]                                                 28%|â–ˆâ–ˆâ–Š       | 50/180 [18:37<45:24, 20.96s/it] 28%|â–ˆâ–ˆâ–Š       | 51/180 [18:54<42:25, 19.73s/it] 29%|â–ˆâ–ˆâ–‰       | 52/180 [19:13<41:44, 19.57s/it] 29%|â–ˆâ–ˆâ–‰       | 53/180 [19:31<40:28, 19.12s/it] 30%|â–ˆâ–ˆâ–ˆ       | 54/180 [19:50<40:11, 19.14s/it]
  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|â–ˆâ–ˆâ–       | 2/9 [00:01<00:03,  1.83it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:03<00:07,  1.23s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:04<00:05,  1.19s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:07<00:08,  2.01s/it][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:09<00:05,  1.71s/it][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:13<00:04,  2.44s/it][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:14<00:02,  2.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:18<00:00,  2.69s/it][A                                                
                                             [A 30%|â–ˆâ–ˆâ–ˆ       | 54/180 [20:24<40:11, 19.14s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:23<00:00,  2.69s/it][A
                                             [A                                                 30%|â–ˆâ–ˆâ–ˆ       | 54/180 [20:31<40:11, 19.14s/it] 30%|â–ˆâ–ˆâ–ˆ       | 54/180 [20:31<47:53, 22.81s/it]
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Unsloth: Merging weights into 16bit:   0%|          | 0/5 [00:00<?, ?it/s]Unsloth: Merging weights into 16bit:  20%|â–ˆâ–ˆ        | 1/5 [00:29<01:59, 29.76s/it]Unsloth: Merging weights into 16bit:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [02:22<03:56, 78.83s/it]Unsloth: Merging weights into 16bit:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [04:47<03:37, 108.83s/it]Unsloth: Merging weights into 16bit:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [07:07<02:01, 121.17s/it]Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [09:43<00:00, 133.58s/it]Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [09:43<00:00, 116.63s/it]
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Unsloth: Merging weights into 16bit:   0%|          | 0/5 [00:00<?, ?it/s]Unsloth: Merging weights into 16bit:  20%|â–ˆâ–ˆ        | 1/5 [00:38<02:34, 38.50s/it]Unsloth: Merging weights into 16bit:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [03:00<04:58, 99.37s/it]Unsloth: Merging weights into 16bit:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [05:23<03:58, 119.11s/it]Unsloth: Merging weights into 16bit:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [07:43<02:07, 127.42s/it]Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [10:06<00:00, 133.08s/it]Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [10:06<00:00, 121.27s/it]
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:36<02:25, 36.35s/it]Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.50s/it]Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:53<01:16, 38.07s/it]Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:32<00:38, 38.51s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:41<00:00, 28.01s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:41<00:00, 32.39s/it]
Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/qwen/finetune/stair_finetune_fewshot.py", line 705, in <module>
    main()
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/qwen/finetune/stair_finetune_fewshot.py", line 668, in main
    finetuner.reload_best_model_for_inference(config["output_dir"])
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/qwen/finetune/stair_finetune_fewshot.py", line 434, in reload_best_model_for_inference
    self.model, _ = FastVisionModel.from_pretrained(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/unsloth/models/loader.py", line 856, in from_pretrained
    model = FastBaseModel.post_patch_model(model, use_gradient_checkpointing)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/unsloth/models/vision.py", line 681, in post_patch_model
    raise RuntimeError('Unsloth: Unsuccessfully patched inner_training_loop')
RuntimeError: Unsloth: Unsuccessfully patched inner_training_loop
