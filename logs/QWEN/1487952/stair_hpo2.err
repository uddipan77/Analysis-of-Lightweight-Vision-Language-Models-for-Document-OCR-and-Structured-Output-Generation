Unsloth: KwargsForCausalLM cannot be inherited from TransformersKwargs since it's of type = <class 'type'>
/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.
  warnings.warn(
/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``group`` is an experimental feature. The interface can change in the future.
  warnings.warn(
[I 2026-01-13 18:43:55,714] A new study created in RDB with name: qwen_stair_enhanced_v2
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:44<02:56, 44.04s/it]Loading checkpoint shards:  40%|████      | 2/5 [01:27<02:10, 43.45s/it]Loading checkpoint shards:  60%|██████    | 3/5 [02:11<01:27, 43.73s/it]Loading checkpoint shards:  80%|████████  | 4/5 [02:55<00:44, 44.01s/it]Loading checkpoint shards: 100%|██████████| 5/5 [03:05<00:00, 31.85s/it]Loading checkpoint shards: 100%|██████████| 5/5 [03:05<00:00, 37.18s/it]
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.04246782213565523.
Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.
  0%|          | 0/140 [00:00<?, ?it/s]Unsloth: Not an error, but Qwen2_5_VLForConditionalGeneration does not accept `num_items_in_batch`.
Using gradient accumulation will be very slightly less accurate.
Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  1%|          | 1/140 [00:15<36:38, 15.82s/it]  1%|▏         | 2/140 [00:28<32:02, 13.93s/it]  2%|▏         | 3/140 [00:40<30:20, 13.29s/it]  3%|▎         | 4/140 [00:53<29:22, 12.96s/it]  4%|▎         | 5/140 [01:05<28:44, 12.77s/it]  4%|▍         | 6/140 [01:18<28:20, 12.69s/it]  5%|▌         | 7/140 [01:30<28:00, 12.63s/it]  6%|▌         | 8/140 [01:43<27:39, 12.57s/it]  6%|▋         | 9/140 [01:55<27:19, 12.51s/it]  7%|▋         | 10/140 [02:08<27:11, 12.55s/it]  8%|▊         | 11/140 [02:20<26:56, 12.53s/it]  9%|▊         | 12/140 [02:33<26:40, 12.51s/it]  9%|▉         | 13/140 [02:45<26:32, 12.54s/it] 10%|█         | 14/140 [02:58<26:14, 12.50s/it] 11%|█         | 15/140 [03:10<25:53, 12.43s/it] 11%|█▏        | 16/140 [03:23<25:42, 12.44s/it] 12%|█▏        | 17/140 [03:35<25:27, 12.42s/it] 13%|█▎        | 18/140 [03:48<25:24, 12.50s/it] 14%|█▎        | 19/140 [04:00<25:09, 12.48s/it] 14%|█▍        | 20/140 [04:13<24:58, 12.48s/it]                                                 14%|█▍        | 20/140 [04:13<24:58, 12.48s/it] 15%|█▌        | 21/140 [04:25<24:41, 12.45s/it] 16%|█▌        | 22/140 [04:37<24:27, 12.44s/it] 16%|█▋        | 23/140 [04:50<24:15, 12.44s/it] 17%|█▋        | 24/140 [05:02<23:56, 12.39s/it] 18%|█▊        | 25/140 [05:14<23:47, 12.41s/it] 19%|█▊        | 26/140 [05:27<23:34, 12.41s/it] 19%|█▉        | 27/140 [05:39<23:16, 12.36s/it] 20%|██        | 28/140 [05:51<23:04, 12.36s/it] 21%|██        | 29/140 [06:00<20:59, 11.35s/it] 21%|██▏       | 30/140 [06:13<21:31, 11.74s/it] 22%|██▏       | 31/140 [06:26<21:43, 11.96s/it] 23%|██▎       | 32/140 [06:38<21:46, 12.10s/it] 24%|██▎       | 33/140 [06:50<21:38, 12.14s/it] 24%|██▍       | 34/140 [07:03<21:37, 12.24s/it] 25%|██▌       | 35/140 [07:15<21:26, 12.26s/it] 26%|██▌       | 36/140 [07:27<21:14, 12.26s/it] 26%|██▋       | 37/140 [07:40<21:06, 12.29s/it] 27%|██▋       | 38/140 [07:52<20:55, 12.31s/it] 28%|██▊       | 39/140 [08:04<20:45, 12.34s/it] 29%|██▊       | 40/140 [08:17<20:27, 12.28s/it]                                                 29%|██▊       | 40/140 [08:17<20:27, 12.28s/it] 29%|██▉       | 41/140 [08:29<20:21, 12.34s/it] 30%|███       | 42/140 [08:41<20:12, 12.37s/it] 31%|███       | 43/140 [08:54<19:57, 12.35s/it] 31%|███▏      | 44/140 [09:06<19:45, 12.35s/it] 32%|███▏      | 45/140 [09:18<19:33, 12.36s/it] 33%|███▎      | 46/140 [09:31<19:18, 12.32s/it] 34%|███▎      | 47/140 [09:43<19:07, 12.34s/it] 34%|███▍      | 48/140 [09:55<18:52, 12.31s/it] 35%|███▌      | 49/140 [10:08<18:42, 12.33s/it] 36%|███▌      | 50/140 [10:20<18:30, 12.34s/it] 36%|███▋      | 51/140 [10:32<18:16, 12.32s/it] 37%|███▋      | 52/140 [10:44<17:59, 12.26s/it] 38%|███▊      | 53/140 [10:57<17:46, 12.26s/it] 39%|███▊      | 54/140 [11:09<17:33, 12.25s/it] 39%|███▉      | 55/140 [11:21<17:20, 12.24s/it] 40%|████      | 56/140 [11:34<17:10, 12.27s/it] 41%|████      | 57/140 [11:46<17:00, 12.29s/it] 41%|████▏     | 58/140 [11:55<15:22, 11.25s/it] 42%|████▏     | 59/140 [12:07<15:42, 11.63s/it] 43%|████▎     | 60/140 [12:20<15:47, 11.84s/it]                                                 43%|████▎     | 60/140 [12:20<15:47, 11.84s/it] 44%|████▎     | 61/140 [12:32<15:51, 12.04s/it] 44%|████▍     | 62/140 [12:44<15:46, 12.13s/it] 45%|████▌     | 63/140 [12:57<15:38, 12.19s/it] 46%|████▌     | 64/140 [13:09<15:29, 12.24s/it] 46%|████▋     | 65/140 [13:21<15:18, 12.25s/it] 47%|████▋     | 66/140 [13:34<15:09, 12.30s/it] 48%|████▊     | 67/140 [13:46<15:00, 12.33s/it] 49%|████▊     | 68/140 [13:59<14:48, 12.34s/it] 49%|████▉     | 69/140 [14:11<14:38, 12.37s/it] 50%|█████     | 70/140 [14:23<14:24, 12.35s/it] 51%|█████     | 71/140 [14:36<14:10, 12.33s/it] 51%|█████▏    | 72/140 [14:48<13:54, 12.27s/it] 52%|█████▏    | 73/140 [15:00<13:42, 12.28s/it] 53%|█████▎    | 74/140 [15:12<13:33, 12.32s/it] 54%|█████▎    | 75/140 [15:25<13:23, 12.37s/it] 54%|█████▍    | 76/140 [15:37<13:10, 12.35s/it] 55%|█████▌    | 77/140 [15:50<12:58, 12.35s/it] 56%|█████▌    | 78/140 [16:02<12:49, 12.41s/it] 56%|█████▋    | 79/140 [16:14<12:36, 12.40s/it] 57%|█████▋    | 80/140 [16:27<12:21, 12.36s/it]                                                 57%|█████▋    | 80/140 [16:27<12:21, 12.36s/it] 58%|█████▊    | 81/140 [16:39<12:06, 12.31s/it] 59%|█████▊    | 82/140 [16:51<11:55, 12.34s/it] 59%|█████▉    | 83/140 [17:04<11:44, 12.36s/it] 60%|██████    | 84/140 [17:16<11:31, 12.35s/it] 61%|██████    | 85/140 [17:28<11:18, 12.33s/it] 61%|██████▏   | 86/140 [17:41<11:05, 12.32s/it] 62%|██████▏   | 87/140 [17:49<09:56, 11.26s/it] 63%|██████▎   | 88/140 [18:02<10:07, 11.69s/it] 64%|██████▎   | 89/140 [18:14<10:05, 11.87s/it] 64%|██████▍   | 90/140 [18:27<09:56, 11.93s/it] 65%|██████▌   | 91/140 [18:39<09:45, 11.95s/it] 66%|██████▌   | 92/140 [18:51<09:35, 11.99s/it] 66%|██████▋   | 93/140 [19:03<09:24, 12.01s/it] 67%|██████▋   | 94/140 [19:15<09:14, 12.06s/it] 68%|██████▊   | 95/140 [19:27<09:04, 12.10s/it] 69%|██████▊   | 96/140 [19:39<08:55, 12.16s/it] 69%|██████▉   | 97/140 [19:51<08:42, 12.16s/it] 70%|███████   | 98/140 [20:04<08:34, 12.26s/it] 71%|███████   | 99/140 [20:16<08:23, 12.27s/it] 71%|███████▏  | 100/140 [20:28<08:09, 12.23s/it]                                                  71%|███████▏  | 100/140 [20:28<08:09, 12.23s/it] 72%|███████▏  | 101/140 [20:41<07:59, 12.29s/it] 73%|███████▎  | 102/140 [20:53<07:46, 12.28s/it] 74%|███████▎  | 103/140 [21:05<07:35, 12.32s/it] 74%|███████▍  | 104/140 [21:18<07:23, 12.31s/it] 75%|███████▌  | 105/140 [21:30<07:10, 12.29s/it] 76%|███████▌  | 106/140 [21:42<06:57, 12.27s/it] 76%|███████▋  | 107/140 [21:55<06:45, 12.30s/it] 77%|███████▋  | 108/140 [22:07<06:33, 12.28s/it] 78%|███████▊  | 109/140 [22:19<06:21, 12.31s/it] 79%|███████▊  | 110/140 [22:31<06:08, 12.29s/it] 79%|███████▉  | 111/140 [22:44<05:57, 12.32s/it] 80%|████████  | 112/140 [22:56<05:45, 12.34s/it] 81%|████████  | 113/140 [23:08<05:31, 12.29s/it] 81%|████████▏ | 114/140 [23:21<05:19, 12.28s/it] 82%|████████▏ | 115/140 [23:33<05:06, 12.27s/it] 83%|████████▎ | 116/140 [23:42<04:29, 11.24s/it] 84%|████████▎ | 117/140 [23:54<04:28, 11.68s/it] 84%|████████▍ | 118/140 [24:07<04:19, 11.81s/it] 85%|████████▌ | 119/140 [24:19<04:10, 11.95s/it] 86%|████████▌ | 120/140 [24:31<04:00, 12.05s/it]                                                  86%|████████▌ | 120/140 [24:31<04:00, 12.05s/it] 86%|████████▋ | 121/140 [24:43<03:49, 12.08s/it] 87%|████████▋ | 122/140 [24:56<03:38, 12.13s/it] 88%|████████▊ | 123/140 [25:08<03:26, 12.17s/it] 89%|████████▊ | 124/140 [25:20<03:15, 12.20s/it] 89%|████████▉ | 125/140 [25:32<03:03, 12.20s/it] 90%|█████████ | 126/140 [25:44<02:50, 12.18s/it] 91%|█████████ | 127/140 [25:57<02:38, 12.18s/it] 91%|█████████▏| 128/140 [26:09<02:27, 12.25s/it] 92%|█████████▏| 129/140 [26:21<02:14, 12.27s/it] 93%|█████████▎| 130/140 [26:34<02:02, 12.26s/it] 94%|█████████▎| 131/140 [26:46<01:50, 12.28s/it] 94%|█████████▍| 132/140 [26:58<01:38, 12.31s/it] 95%|█████████▌| 133/140 [27:11<01:26, 12.36s/it] 96%|█████████▌| 134/140 [27:23<01:14, 12.39s/it] 96%|█████████▋| 135/140 [27:35<01:01, 12.35s/it] 97%|█████████▋| 136/140 [27:47<00:49, 12.26s/it] 98%|█████████▊| 137/140 [28:00<00:36, 12.22s/it] 99%|█████████▊| 138/140 [28:12<00:24, 12.21s/it] 99%|█████████▉| 139/140 [28:24<00:12, 12.17s/it]100%|██████████| 140/140 [28:36<00:00, 12.16s/it]                                                 100%|██████████| 140/140 [28:36<00:00, 12.16s/it]                                                 100%|██████████| 140/140 [28:36<00:00, 12.16s/it]100%|██████████| 140/140 [28:36<00:00, 12.26s/it]
[I 2026-01-13 19:30:55,067] Trial 0 finished with value: 0.5684488817313827 and parameters: {'learning_rate': 1.9906996673933362e-05, 'weight_decay': 0.1426071459614874, 'gradient_accumulation_steps': 4, 'lora_r': 32, 'lora_alpha': 64, 'lora_dropout': 0.04246782213565523, 'warmup_ratio': 0.03636499344142013, 'max_seq_length': 2048}. Best is trial 0 with value: 0.5684488817313827.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:40<02:42, 40.60s/it]Loading checkpoint shards:  40%|████      | 2/5 [01:22<02:03, 41.09s/it]Loading checkpoint shards:  60%|██████    | 3/5 [02:02<01:21, 40.92s/it]Loading checkpoint shards:  80%|████████  | 4/5 [02:43<00:40, 40.99s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:53<00:00, 29.81s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:53<00:00, 34.77s/it]
Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.03410482473745831.
Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.
  0%|          | 0/140 [00:00<?, ?it/s]  1%|          | 1/140 [00:12<28:28, 12.29s/it]  1%|▏         | 2/140 [00:23<27:12, 11.83s/it]  2%|▏         | 3/140 [00:35<26:38, 11.67s/it]  3%|▎         | 4/140 [00:46<26:13, 11.57s/it]  4%|▎         | 5/140 [00:58<25:50, 11.48s/it]  4%|▍         | 6/140 [01:09<25:35, 11.46s/it]  5%|▌         | 7/140 [01:20<25:22, 11.45s/it]  6%|▌         | 8/140 [01:32<25:17, 11.50s/it]  6%|▋         | 9/140 [01:43<25:06, 11.50s/it]  7%|▋         | 10/140 [01:55<24:54, 11.50s/it]  8%|▊         | 11/140 [02:06<24:36, 11.44s/it]  9%|▊         | 12/140 [02:18<24:22, 11.43s/it]  9%|▉         | 13/140 [02:29<24:07, 11.40s/it] 10%|█         | 14/140 [02:40<23:49, 11.35s/it] 11%|█         | 15/140 [02:52<23:39, 11.35s/it] 11%|█▏        | 16/140 [03:03<23:33, 11.40s/it] 12%|█▏        | 17/140 [03:14<23:17, 11.36s/it] 13%|█▎        | 18/140 [03:26<23:08, 11.38s/it] 14%|█▎        | 19/140 [03:37<22:55, 11.37s/it] 14%|█▍        | 20/140 [03:49<22:45, 11.38s/it]                                                 14%|█▍        | 20/140 [03:49<22:45, 11.38s/it] 15%|█▌        | 21/140 [04:00<22:34, 11.39s/it] 16%|█▌        | 22/140 [04:11<22:23, 11.38s/it] 16%|█▋        | 23/140 [04:23<22:12, 11.39s/it] 17%|█▋        | 24/140 [04:34<21:53, 11.32s/it] 18%|█▊        | 25/140 [04:45<21:43, 11.33s/it] 19%|█▊        | 26/140 [04:57<21:32, 11.34s/it] 19%|█▉        | 27/140 [05:08<21:16, 11.29s/it] 20%|██        | 28/140 [05:19<21:06, 11.31s/it] 21%|██        | 29/140 [05:27<19:10, 10.36s/it] 21%|██▏       | 30/140 [05:39<19:45, 10.78s/it] 22%|██▏       | 31/140 [05:50<19:53, 10.95s/it] 23%|██▎       | 32/140 [06:02<19:55, 11.07s/it] 24%|██▎       | 33/140 [06:13<19:48, 11.11s/it] 24%|██▍       | 34/140 [06:24<19:44, 11.17s/it] 25%|██▌       | 35/140 [06:36<19:40, 11.24s/it] 26%|██▌       | 36/140 [06:47<19:32, 11.27s/it] 26%|██▋       | 37/140 [06:58<19:23, 11.30s/it] 27%|██▋       | 38/140 [07:10<19:14, 11.31s/it] 28%|██▊       | 39/140 [07:21<19:03, 11.32s/it] 29%|██▊       | 40/140 [07:32<18:52, 11.32s/it]                                                 29%|██▊       | 40/140 [07:32<18:52, 11.32s/it] 29%|██▉       | 41/140 [07:44<18:41, 11.33s/it] 30%|███       | 42/140 [07:55<18:32, 11.35s/it] 31%|███       | 43/140 [08:06<18:20, 11.35s/it] 31%|███▏      | 44/140 [08:18<18:10, 11.36s/it] 32%|███▏      | 45/140 [08:29<18:00, 11.38s/it] 33%|███▎      | 46/140 [08:41<17:46, 11.34s/it] 34%|███▎      | 47/140 [08:52<17:33, 11.32s/it] 34%|███▍      | 48/140 [09:03<17:23, 11.34s/it] 35%|███▌      | 49/140 [09:15<17:17, 11.40s/it] 36%|███▌      | 50/140 [09:26<17:02, 11.36s/it] 36%|███▋      | 51/140 [09:37<16:46, 11.31s/it] 37%|███▋      | 52/140 [09:48<16:31, 11.27s/it] 38%|███▊      | 53/140 [10:00<16:21, 11.28s/it] 39%|███▊      | 54/140 [10:11<16:10, 11.29s/it] 39%|███▉      | 55/140 [10:22<16:00, 11.30s/it] 40%|████      | 56/140 [10:34<15:51, 11.33s/it] 41%|████      | 57/140 [10:45<15:40, 11.33s/it] 41%|████▏     | 58/140 [10:53<14:10, 10.37s/it] 42%|████▏     | 59/140 [11:05<14:28, 10.72s/it] 43%|████▎     | 60/140 [11:16<14:32, 10.91s/it]                                                 43%|████▎     | 60/140 [11:16<14:32, 10.91s/it] 44%|████▎     | 61/140 [11:27<14:31, 11.03s/it] 44%|████▍     | 62/140 [11:39<14:27, 11.13s/it] 45%|████▌     | 63/140 [11:50<14:19, 11.16s/it] 46%|████▌     | 64/140 [12:01<14:15, 11.26s/it] 46%|████▋     | 65/140 [12:13<14:03, 11.24s/it] 47%|████▋     | 66/140 [12:24<13:54, 11.27s/it] 48%|████▊     | 67/140 [12:35<13:45, 11.31s/it] 49%|████▊     | 68/140 [12:47<13:34, 11.32s/it] 49%|████▉     | 69/140 [12:58<13:23, 11.32s/it] 50%|█████     | 70/140 [13:09<13:13, 11.33s/it] 51%|█████     | 71/140 [13:21<12:59, 11.30s/it] 51%|█████▏    | 72/140 [13:32<12:47, 11.29s/it] 52%|█████▏    | 73/140 [13:43<12:37, 11.31s/it] 53%|█████▎    | 74/140 [13:55<12:27, 11.33s/it] 54%|█████▎    | 75/140 [14:06<12:18, 11.36s/it] 54%|█████▍    | 76/140 [14:17<12:06, 11.36s/it] 55%|█████▌    | 77/140 [14:29<11:55, 11.36s/it] 56%|█████▌    | 78/140 [14:40<11:43, 11.35s/it] 56%|█████▋    | 79/140 [14:52<11:34, 11.38s/it] 57%|█████▋    | 80/140 [15:03<11:24, 11.40s/it]                                                 57%|█████▋    | 80/140 [15:03<11:24, 11.40s/it] 58%|█████▊    | 81/140 [15:14<11:12, 11.41s/it] 59%|█████▊    | 82/140 [15:26<10:59, 11.38s/it] 59%|█████▉    | 83/140 [15:37<10:48, 11.37s/it] 60%|██████    | 84/140 [15:48<10:35, 11.34s/it] 61%|██████    | 85/140 [16:00<10:21, 11.31s/it] 61%|██████▏   | 86/140 [16:11<10:08, 11.28s/it] 62%|██████▏   | 87/140 [16:19<09:08, 10.35s/it] 63%|██████▎   | 88/140 [16:31<09:21, 10.80s/it] 64%|██████▎   | 89/140 [16:42<09:22, 11.03s/it] 64%|██████▍   | 90/140 [16:54<09:14, 11.10s/it] 65%|██████▌   | 91/140 [17:05<09:06, 11.15s/it] 66%|██████▌   | 92/140 [17:16<08:58, 11.22s/it] 66%|██████▋   | 93/140 [17:27<08:46, 11.21s/it] 67%|██████▋   | 94/140 [17:39<08:37, 11.24s/it] 68%|██████▊   | 95/140 [17:50<08:27, 11.28s/it] 69%|██████▊   | 96/140 [18:02<08:17, 11.31s/it] 69%|██████▉   | 97/140 [18:13<08:07, 11.33s/it] 70%|███████   | 98/140 [18:24<07:54, 11.30s/it] 71%|███████   | 99/140 [18:35<07:43, 11.32s/it] 71%|███████▏  | 100/140 [18:47<07:30, 11.27s/it]                                                  71%|███████▏  | 100/140 [18:47<07:30, 11.27s/it] 72%|███████▏  | 101/140 [18:58<07:20, 11.30s/it] 73%|███████▎  | 102/140 [19:09<07:09, 11.31s/it] 74%|███████▎  | 103/140 [19:21<06:59, 11.34s/it] 74%|███████▍  | 104/140 [19:32<06:49, 11.37s/it] 75%|███████▌  | 105/140 [19:44<06:38, 11.38s/it] 76%|███████▌  | 106/140 [19:55<06:26, 11.38s/it] 76%|███████▋  | 107/140 [20:06<06:16, 11.41s/it] 77%|███████▋  | 108/140 [20:18<06:04, 11.39s/it] 78%|███████▊  | 109/140 [20:29<05:52, 11.38s/it] 79%|███████▊  | 110/140 [20:41<05:41, 11.38s/it] 79%|███████▉  | 111/140 [20:52<05:30, 11.39s/it] 80%|████████  | 112/140 [21:03<05:18, 11.37s/it] 81%|████████  | 113/140 [21:15<05:06, 11.35s/it] 81%|████████▏ | 114/140 [21:26<04:54, 11.34s/it] 82%|████████▏ | 115/140 [21:37<04:42, 11.32s/it] 83%|████████▎ | 116/140 [21:45<04:08, 10.36s/it] 84%|████████▎ | 117/140 [21:57<04:08, 10.80s/it] 84%|████████▍ | 118/140 [22:08<04:00, 10.95s/it] 85%|████████▌ | 119/140 [22:20<03:52, 11.08s/it] 86%|████████▌ | 120/140 [22:31<03:43, 11.20s/it]                                                  86%|████████▌ | 120/140 [22:31<03:43, 11.20s/it] 86%|████████▋ | 121/140 [22:42<03:32, 11.20s/it] 87%|████████▋ | 122/140 [22:54<03:22, 11.27s/it] 88%|████████▊ | 123/140 [23:05<03:11, 11.28s/it] 89%|████████▊ | 124/140 [23:17<03:00, 11.29s/it] 89%|████████▉ | 125/140 [23:28<02:49, 11.29s/it] 90%|█████████ | 126/140 [23:39<02:38, 11.29s/it] 91%|█████████ | 127/140 [23:51<02:27, 11.33s/it] 91%|█████████▏| 128/140 [24:02<02:16, 11.35s/it] 92%|█████████▏| 129/140 [24:13<02:04, 11.36s/it] 93%|█████████▎| 130/140 [24:25<01:53, 11.32s/it] 94%|█████████▎| 131/140 [24:36<01:41, 11.33s/it] 94%|█████████▍| 132/140 [24:47<01:30, 11.35s/it] 95%|█████████▌| 133/140 [24:59<01:19, 11.33s/it] 96%|█████████▌| 134/140 [25:10<01:08, 11.34s/it] 96%|█████████▋| 135/140 [25:21<00:56, 11.35s/it] 97%|█████████▋| 136/140 [25:33<00:45, 11.31s/it] 98%|█████████▊| 137/140 [25:44<00:33, 11.31s/it] 99%|█████████▊| 138/140 [25:55<00:22, 11.33s/it] 99%|█████████▉| 139/140 [26:06<00:11, 11.31s/it]100%|██████████| 140/140 [26:18<00:00, 11.32s/it]                                                 100%|██████████| 140/140 [26:18<00:00, 11.32s/it]                                                 100%|██████████| 140/140 [26:18<00:00, 11.32s/it]100%|██████████| 140/140 [26:18<00:00, 11.27s/it]
[I 2026-01-13 20:16:29,303] Trial 1 finished with value: 0.5602551356715969 and parameters: {'learning_rate': 2.4602080610141604e-05, 'weight_decay': 0.043684371029706286, 'gradient_accumulation_steps': 4, 'lora_r': 32, 'lora_alpha': 128, 'lora_dropout': 0.03410482473745831, 'warmup_ratio': 0.013010318597055905, 'max_seq_length': 1024}. Best is trial 1 with value: 0.5602551356715969.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:37<02:30, 37.72s/it]Loading checkpoint shards:  40%|████      | 2/5 [01:17<01:56, 38.76s/it]Loading checkpoint shards:  60%|██████    | 3/5 [01:56<01:17, 38.94s/it]Loading checkpoint shards:  80%|████████  | 4/5 [02:36<00:39, 39.38s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:46<00:00, 28.65s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:46<00:00, 33.21s/it]
Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.03697089110510541.
Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.
  0%|          | 0/140 [00:00<?, ?it/s]  1%|          | 1/140 [00:13<30:35, 13.20s/it]  1%|▏         | 2/140 [00:24<28:25, 12.36s/it]  2%|▏         | 3/140 [00:36<27:40, 12.12s/it]  3%|▎         | 4/140 [00:48<27:14, 12.02s/it]  4%|▎         | 5/140 [01:00<26:55, 11.96s/it]  4%|▍         | 6/140 [01:12<26:21, 11.80s/it]  5%|▌         | 7/140 [01:23<26:01, 11.74s/it]  6%|▌         | 8/140 [01:35<25:46, 11.71s/it]  6%|▋         | 9/140 [01:46<25:27, 11.66s/it]  7%|▋         | 10/140 [01:58<25:14, 11.65s/it]  8%|▊         | 11/140 [02:10<24:58, 11.62s/it]  9%|▊         | 12/140 [02:21<24:46, 11.61s/it]  9%|▉         | 13/140 [02:33<24:34, 11.61s/it] 10%|█         | 14/140 [02:44<24:16, 11.56s/it] 11%|█         | 15/140 [02:56<24:02, 11.54s/it] 11%|█▏        | 16/140 [03:07<23:52, 11.55s/it] 12%|█▏        | 17/140 [03:19<23:44, 11.58s/it] 13%|█▎        | 18/140 [03:31<23:40, 11.64s/it] 14%|█▎        | 19/140 [03:42<23:28, 11.64s/it] 14%|█▍        | 20/140 [03:54<23:19, 11.66s/it]                                                 14%|█▍        | 20/140 [03:54<23:19, 11.66s/it] 15%|█▌        | 21/140 [04:06<23:06, 11.65s/it] 16%|█▌        | 22/140 [04:17<22:53, 11.64s/it] 16%|█▋        | 23/140 [04:29<22:39, 11.62s/it] 17%|█▋        | 24/140 [04:40<22:23, 11.58s/it] 18%|█▊        | 25/140 [04:52<22:17, 11.63s/it] 19%|█▊        | 26/140 [05:04<22:04, 11.62s/it] 19%|█▉        | 27/140 [05:15<21:45, 11.55s/it] 20%|██        | 28/140 [05:27<21:32, 11.54s/it] 21%|██        | 29/140 [05:35<19:32, 10.56s/it] 21%|██▏       | 30/140 [05:47<20:08, 10.99s/it] 22%|██▏       | 31/140 [05:58<20:16, 11.16s/it] 23%|██▎       | 32/140 [06:10<20:18, 11.28s/it] 24%|██▎       | 33/140 [06:21<20:15, 11.36s/it] 24%|██▍       | 34/140 [06:33<20:11, 11.43s/it] 25%|██▌       | 35/140 [06:45<20:07, 11.50s/it] 26%|██▌       | 36/140 [06:56<19:58, 11.52s/it] 26%|██▋       | 37/140 [07:08<19:49, 11.55s/it] 27%|██▋       | 38/140 [07:20<19:41, 11.58s/it] 28%|██▊       | 39/140 [07:31<19:29, 11.58s/it] 29%|██▊       | 40/140 [07:43<19:17, 11.57s/it]                                                 29%|██▊       | 40/140 [07:43<19:17, 11.57s/it] 29%|██▉       | 41/140 [07:54<19:09, 11.61s/it] 30%|███       | 42/140 [08:06<19:04, 11.68s/it] 31%|███       | 43/140 [08:18<18:54, 11.69s/it] 31%|███▏      | 44/140 [08:30<18:42, 11.70s/it] 32%|███▏      | 45/140 [08:41<18:29, 11.68s/it] 33%|███▎      | 46/140 [08:53<18:15, 11.65s/it] 34%|███▎      | 47/140 [09:04<17:57, 11.58s/it] 34%|███▍      | 48/140 [09:16<17:43, 11.56s/it] 35%|███▌      | 49/140 [09:28<17:35, 11.60s/it] 36%|███▌      | 50/140 [09:39<17:22, 11.58s/it] 36%|███▋      | 51/140 [09:51<17:08, 11.56s/it] 37%|███▋      | 52/140 [10:02<16:54, 11.53s/it] 38%|███▊      | 53/140 [10:14<16:43, 11.53s/it] 39%|███▊      | 54/140 [10:25<16:29, 11.51s/it] 39%|███▉      | 55/140 [10:37<16:19, 11.52s/it] 40%|████      | 56/140 [10:48<16:09, 11.54s/it] 41%|████      | 57/140 [11:00<15:58, 11.55s/it] 41%|████▏     | 58/140 [11:08<14:27, 10.58s/it] 42%|████▏     | 59/140 [11:20<14:47, 10.95s/it] 43%|████▎     | 60/140 [11:32<14:53, 11.17s/it]                                                 43%|████▎     | 60/140 [11:32<14:53, 11.17s/it] 44%|████▎     | 61/140 [11:43<14:53, 11.31s/it] 44%|████▍     | 62/140 [11:55<14:47, 11.37s/it] 45%|████▌     | 63/140 [12:06<14:38, 11.41s/it] 46%|████▌     | 64/140 [12:18<14:34, 11.50s/it] 46%|████▋     | 65/140 [12:29<14:20, 11.47s/it] 47%|████▋     | 66/140 [12:41<14:08, 11.47s/it] 48%|████▊     | 67/140 [12:52<13:59, 11.50s/it] 49%|████▊     | 68/140 [13:04<13:49, 11.52s/it] 49%|████▉     | 69/140 [13:16<13:40, 11.55s/it] 50%|█████     | 70/140 [13:27<13:29, 11.57s/it] 51%|█████     | 71/140 [13:39<13:16, 11.55s/it] 51%|█████▏    | 72/140 [13:50<13:05, 11.55s/it] 52%|█████▏    | 73/140 [14:02<12:54, 11.56s/it] 53%|█████▎    | 74/140 [14:13<12:43, 11.57s/it] 54%|█████▎    | 75/140 [14:25<12:33, 11.60s/it] 54%|█████▍    | 76/140 [14:37<12:21, 11.58s/it] 55%|█████▌    | 77/140 [14:49<12:21, 11.76s/it] 56%|█████▌    | 78/140 [15:00<12:05, 11.71s/it] 56%|█████▋    | 79/140 [15:12<11:52, 11.69s/it] 57%|█████▋    | 80/140 [15:24<11:42, 11.71s/it]                                                 57%|█████▋    | 80/140 [15:24<11:42, 11.71s/it] 58%|█████▊    | 81/140 [15:35<11:30, 11.70s/it] 59%|█████▊    | 82/140 [15:47<11:18, 11.69s/it] 59%|█████▉    | 83/140 [15:59<11:05, 11.68s/it] 60%|██████    | 84/140 [16:10<10:51, 11.64s/it] 61%|██████    | 85/140 [16:22<10:37, 11.59s/it] 61%|██████▏   | 86/140 [16:33<10:23, 11.55s/it] 62%|██████▏   | 87/140 [16:41<09:18, 10.55s/it] 63%|██████▎   | 88/140 [16:53<09:30, 10.97s/it] 64%|██████▎   | 89/140 [17:05<09:27, 11.13s/it] 64%|██████▍   | 90/140 [17:16<09:19, 11.19s/it] 65%|██████▌   | 91/140 [17:28<09:12, 11.27s/it] 66%|██████▌   | 92/140 [17:39<09:05, 11.36s/it] 66%|██████▋   | 93/140 [17:51<08:53, 11.35s/it] 67%|██████▋   | 94/140 [18:02<08:44, 11.40s/it] 68%|██████▊   | 95/140 [18:13<08:33, 11.40s/it] 69%|██████▊   | 96/140 [18:25<08:22, 11.42s/it] 69%|██████▉   | 97/140 [18:36<08:12, 11.45s/it] 70%|███████   | 98/140 [18:48<07:59, 11.41s/it] 71%|███████   | 99/140 [18:59<07:48, 11.42s/it] 71%|███████▏  | 100/140 [19:11<07:35, 11.38s/it]                                                  71%|███████▏  | 100/140 [19:11<07:35, 11.38s/it] 72%|███████▏  | 101/140 [19:22<07:25, 11.42s/it] 73%|███████▎  | 102/140 [19:33<07:14, 11.42s/it] 74%|███████▎  | 103/140 [19:45<07:03, 11.45s/it] 74%|███████▍  | 104/140 [19:56<06:52, 11.46s/it] 75%|███████▌  | 105/140 [20:08<06:41, 11.46s/it] 76%|███████▌  | 106/140 [20:19<06:29, 11.47s/it] 76%|███████▋  | 107/140 [20:31<06:19, 11.50s/it] 77%|███████▋  | 108/140 [20:42<06:07, 11.47s/it] 78%|███████▊  | 109/140 [20:54<05:55, 11.47s/it] 79%|███████▊  | 110/140 [21:05<05:45, 11.51s/it] 79%|███████▉  | 111/140 [21:17<05:34, 11.52s/it] 80%|████████  | 112/140 [21:28<05:22, 11.51s/it] 81%|████████  | 113/140 [21:40<05:09, 11.48s/it] 81%|████████▏ | 114/140 [21:51<04:58, 11.48s/it] 82%|████████▏ | 115/140 [22:03<04:46, 11.45s/it] 83%|████████▎ | 116/140 [22:11<04:11, 10.48s/it] 84%|████████▎ | 117/140 [22:23<04:12, 10.99s/it] 84%|████████▍ | 118/140 [22:35<04:05, 11.18s/it] 85%|████████▌ | 119/140 [22:47<03:58, 11.35s/it] 86%|████████▌ | 120/140 [22:58<03:48, 11.40s/it]                                                  86%|████████▌ | 120/140 [22:58<03:48, 11.40s/it] 86%|████████▋ | 121/140 [23:09<03:36, 11.40s/it] 87%|████████▋ | 122/140 [23:21<03:25, 11.43s/it] 88%|████████▊ | 123/140 [23:32<03:13, 11.41s/it] 89%|████████▊ | 124/140 [23:44<03:03, 11.45s/it] 89%|████████▉ | 125/140 [23:55<02:52, 11.48s/it] 90%|█████████ | 126/140 [24:07<02:40, 11.48s/it] 91%|█████████ | 127/140 [24:18<02:29, 11.51s/it] 91%|█████████▏| 128/140 [24:30<02:18, 11.54s/it] 92%|█████████▏| 129/140 [24:42<02:07, 11.56s/it] 93%|█████████▎| 130/140 [24:53<01:55, 11.51s/it] 94%|█████████▎| 131/140 [25:05<01:43, 11.52s/it] 94%|█████████▍| 132/140 [25:16<01:32, 11.52s/it] 95%|█████████▌| 133/140 [25:28<01:20, 11.49s/it] 96%|█████████▌| 134/140 [25:39<01:08, 11.49s/it] 96%|█████████▋| 135/140 [25:51<00:57, 11.49s/it] 97%|█████████▋| 136/140 [26:02<00:45, 11.45s/it] 98%|█████████▊| 137/140 [26:13<00:34, 11.44s/it] 99%|█████████▊| 138/140 [26:25<00:22, 11.45s/it] 99%|█████████▉| 139/140 [26:36<00:11, 11.45s/it]100%|██████████| 140/140 [26:48<00:00, 11.45s/it]                                                 100%|██████████| 140/140 [26:48<00:00, 11.45s/it]                                                 100%|██████████| 140/140 [26:48<00:00, 11.45s/it]100%|██████████| 140/140 [26:48<00:00, 11.49s/it]
[I 2026-01-13 20:59:59,683] Trial 2 finished with value: 0.7269403336864876 and parameters: {'learning_rate': 1.53808216661567e-05, 'weight_decay': 0.014650817100957579, 'gradient_accumulation_steps': 4, 'lora_r': 32, 'lora_alpha': 16, 'lora_dropout': 0.03697089110510541, 'warmup_ratio': 0.19391692555291173, 'max_seq_length': 1024}. Best is trial 1 with value: 0.5602551356715969.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:36<02:27, 36.82s/it]Loading checkpoint shards:  40%|████      | 2/5 [01:14<01:52, 37.50s/it]Loading checkpoint shards:  60%|██████    | 3/5 [01:32<00:56, 28.25s/it]Loading checkpoint shards:  80%|████████  | 4/5 [01:59<00:28, 28.08s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:09<00:00, 21.34s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:09<00:00, 25.85s/it]
Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.16043939615080793.
Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.
  0%|          | 0/70 [00:00<?, ?it/s][W 2026-01-13 21:02:25,937] Trial 3 failed with parameters: {'learning_rate': 4.537761219144585e-05, 'weight_decay': 0.13828113525346752, 'gradient_accumulation_steps': 8, 'lora_r': 64, 'lora_alpha': 64, 'lora_dropout': 0.16043939615080793, 'warmup_ratio': 0.014910128735954166, 'max_seq_length': 512} because of the following error: ValueError('Image features and image tokens do not match: tokens: 285, features 468').
Traceback (most recent call last):
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/optuna/study/_optimize.py", line 201, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/qwen/hpo/stair_hpo2.py", line 767, in objective
    best_cer, cer_history = train_one_config(
                            ^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/qwen/hpo/stair_hpo2.py", line 631, in train_one_config
    trainer.train()
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/transformers/trainer.py", line 2560, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/qwen/hpo/unsloth_compiled_cache/UnslothSFTTrainer.py", line 894, in training_step
    return super().training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 31, in _unsloth_training_step
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/qwen/hpo/unsloth_compiled_cache/UnslothSFTTrainer.py", line 883, in compute_loss
    outputs = super().compute_loss(
              ^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/unsloth/models/_utils.py", line 1098, in _unsloth_pre_compute_loss
    outputs = self._old_compute_loss(model, inputs, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/transformers/trainer.py", line 3801, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/accelerate/utils/operations.py", line 818, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/accelerate/utils/operations.py", line 806, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/peft/peft_model.py", line 1850, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/peft/tuners/tuners_utils.py", line 222, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1761, in forward
    raise ValueError(
ValueError: Image features and image tokens do not match: tokens: 285, features 468
[W 2026-01-13 21:02:26,122] Trial 3 failed with value None.
Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/qwen/hpo/stair_hpo2.py", line 877, in <module>
    main()
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/qwen/hpo/stair_hpo2.py", line 872, in main
    run_optuna_hpo()
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/qwen/hpo/stair_hpo2.py", line 786, in run_optuna_hpo
    study.optimize(
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/optuna/study/study.py", line 490, in optimize
    _optimize(
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/optuna/study/_optimize.py", line 63, in _optimize
    _optimize_sequential(
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial_id = _run_trial(study, func, catch)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/optuna/study/_optimize.py", line 258, in _run_trial
    raise func_err
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/optuna/study/_optimize.py", line 201, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/qwen/hpo/stair_hpo2.py", line 767, in objective
    best_cer, cer_history = train_one_config(
                            ^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/qwen/hpo/stair_hpo2.py", line 631, in train_one_config
    trainer.train()
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/transformers/trainer.py", line 2560, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/qwen/hpo/unsloth_compiled_cache/UnslothSFTTrainer.py", line 894, in training_step
    return super().training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 31, in _unsloth_training_step
  File "/home/hpc/iwi5/iwi5298h/Uddipan-Thesis/qwen/hpo/unsloth_compiled_cache/UnslothSFTTrainer.py", line 883, in compute_loss
    outputs = super().compute_loss(
              ^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/unsloth/models/_utils.py", line 1098, in _unsloth_pre_compute_loss
    outputs = self._old_compute_loss(model, inputs, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/transformers/trainer.py", line 3801, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/accelerate/utils/operations.py", line 818, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/accelerate/utils/operations.py", line 806, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/peft/peft_model.py", line 1850, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/peft/tuners/tuners_utils.py", line 222, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/iwi5/iwi5298h/software/private/conda/envs/qwen_vision/lib/python3.11/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1761, in forward
    raise ValueError(
ValueError: Image features and image tokens do not match: tokens: 285, features 468
  0%|          | 0/70 [00:09<?, ?it/s]
