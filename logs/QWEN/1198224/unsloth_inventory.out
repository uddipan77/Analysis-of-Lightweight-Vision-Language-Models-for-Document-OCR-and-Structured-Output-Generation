### Starting TaskPrologue of job 1198224 on tg074 at Mon Sep  1 12:42:50 AM CEST 2025
Running on cores 0-1,8-9,16-17,24-25 with governor ondemand
Mon Sep  1 00:42:50 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.158.01             Driver Version: 570.158.01     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           On  |   00000000:18:00.0 Off |                    0 |
| N/A   37C    P0             27W /  250W |       0MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
[2025-09-01 00:43:17,347] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-01 00:43:19,147] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Created run directory: /home/vault/iwi5/iwi5298h/models_image_text/qwen/inventory_dataset/run_20250901_004326
Loading Qwen2.5-VL model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.7.11: Fast Qwen2_5_Vl patching. Transformers: 4.51.3.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.1+cu126. CUDA: 7.0. CUDA Toolkit: 12.6. Triton: 3.3.1
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to eager!
Unsloth: Making `model.base_model.model.visual` require gradients
Model loaded successfully with optimized LoRA adapters!
============================================================
STARTING TRAINING WITH VALIDATION MONITORING
============================================================
Preparing training and validation datasets...
Training: 213 samples, Validation: 47 samples
Unsloth: Model does not have a default image size - using 512
GPU = Tesla V100-PCIE-32GB. Max memory = 31.733 GB.
7.854 GB of memory reserved.
Starting training with early stopping...
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 3.6595, 'grad_norm': 12.879862785339355, 'learning_rate': 6e-06, 'epoch': 0.37}
{'loss': 2.7075, 'grad_norm': 10.054265975952148, 'learning_rate': 1.5e-05, 'epoch': 0.75}
{'eval_loss': 1.7742812633514404, 'eval_runtime': 20.1195, 'eval_samples_per_second': 2.336, 'eval_steps_per_second': 1.193, 'epoch': 0.97}
{'loss': 2.0, 'grad_norm': 14.518654823303223, 'learning_rate': 2.5e-05, 'epoch': 1.15}
{'loss': 1.2328, 'grad_norm': 3.165458917617798, 'learning_rate': 3.5e-05, 'epoch': 1.52}
{'loss': 1.1818, 'grad_norm': 2.669591188430786, 'learning_rate': 4.5e-05, 'epoch': 1.9}
{'eval_loss': 1.0738784074783325, 'eval_runtime': 19.5956, 'eval_samples_per_second': 2.399, 'eval_steps_per_second': 1.225, 'epoch': 1.97}
{'loss': 0.9857, 'grad_norm': 3.7301738262176514, 'learning_rate': 4.998603909325637e-05, 'epoch': 2.3}
{'loss': 0.9038, 'grad_norm': 3.0380871295928955, 'learning_rate': 4.9874445377212606e-05, 'epoch': 2.67}
{'eval_loss': 1.020566701889038, 'eval_runtime': 19.9383, 'eval_samples_per_second': 2.357, 'eval_steps_per_second': 1.204, 'epoch': 2.97}
{'loss': 0.947, 'grad_norm': 2.9681668281555176, 'learning_rate': 4.9651756349750716e-05, 'epoch': 3.07}
{'loss': 0.7034, 'grad_norm': 3.51847767829895, 'learning_rate': 4.931896659412593e-05, 'epoch': 3.45}
{'loss': 0.7111, 'grad_norm': 2.721550703048706, 'learning_rate': 4.8877562430172815e-05, 'epoch': 3.82}
{'eval_loss': 1.0514613389968872, 'eval_runtime': 20.6653, 'eval_samples_per_second': 2.274, 'eval_steps_per_second': 1.161, 'epoch': 3.97}
{'loss': 0.6313, 'grad_norm': 3.7752938270568848, 'learning_rate': 4.832951527604007e-05, 'epoch': 4.22}
{'loss': 0.5129, 'grad_norm': 3.1274917125701904, 'learning_rate': 4.767727284335852e-05, 'epoch': 4.6}
{'loss': 0.5174, 'grad_norm': 4.19878625869751, 'learning_rate': 4.692374820516679e-05, 'epoch': 4.97}
{'eval_loss': 1.1222805976867676, 'eval_runtime': 20.4967, 'eval_samples_per_second': 2.293, 'eval_steps_per_second': 1.171, 'epoch': 4.97}
{'loss': 0.3267, 'grad_norm': 7.718276500701904, 'learning_rate': 4.6072306785419926e-05, 'epoch': 5.37}
{'loss': 0.3153, 'grad_norm': 9.021956443786621, 'learning_rate': 4.512675132818908e-05, 'epoch': 5.75}
{'eval_loss': 1.2485201358795166, 'eval_runtime': 20.5248, 'eval_samples_per_second': 2.29, 'eval_steps_per_second': 1.169, 'epoch': 5.97}
{'train_runtime': 1784.2322, 'train_samples_per_second': 2.388, 'train_steps_per_second': 0.291, 'train_loss': 1.12335944099304, 'epoch': 5.97}
1784.2322 seconds used for training.
29.74 minutes used for training.
Peak reserved memory = 9.875 GB.
Peak reserved memory for training = 2.021 GB.
Peak reserved memory % of max memory = 31.119 %.
Peak reserved memory for training % of max memory = 6.369 %.
Saving model to /home/vault/iwi5/iwi5298h/models_image_text/qwen/inventory_dataset/run_20250901_004326...
Saving model in recommended formats...
Model saved successfully in multiple formats!

============================================================
STARTING EVALUATION ON TEST.JSONL
============================================================
Starting evaluation on test.jsonl...
Loaded 48 test samples
Processing test image 1/48: inventarbuch-022.jpg
  Processed successfully. CER: 0.280
Processing test image 2/48: inventarbuch-099.jpg
  Processed successfully. CER: 0.158
Processing test image 3/48: inventarbuch-245.jpg
  Processed successfully. CER: 0.243
Processing test image 4/48: inventarbuch-263.jpg
  Processed successfully. CER: 0.141
Processing test image 5/48: inventarbuch-033.jpg
  Processed successfully. CER: 0.296
Processing test image 6/48: inventarbuch-143.jpg
  Processed successfully. CER: 0.162
Processing test image 7/48: inventarbuch-244.jpg
  Processed successfully. CER: 0.383
Processing test image 8/48: inventarbuch-024.jpg
  Processed successfully. CER: 0.062
Processing test image 9/48: inventarbuch-141.jpg
  Processed successfully. CER: 0.092
Processing test image 10/48: inventarbuch-183.jpg
  Processed successfully. CER: 0.318
Processing test image 11/48: inventarbuch-191.jpg
  Processed successfully. CER: 0.218
Processing test image 12/48: inventarbuch-051.jpg
  Processed successfully. CER: 0.058
Processing test image 13/48: inventarbuch-203.jpg
  Processed successfully. CER: 0.190
Processing test image 14/48: inventarbuch-296.jpg
  Processed successfully. CER: 0.331
Processing test image 15/48: inventarbuch-302.jpg
  Processed successfully. CER: 0.032
Processing test image 16/48: inventarbuch-179.jpg
  Processed successfully. CER: 0.230
Processing test image 17/48: inventarbuch-114.jpg
  Processed successfully. CER: 0.218
Processing test image 18/48: inventarbuch-082.jpg
  Processed successfully. CER: 0.275
Processing test image 19/48: inventarbuch-287.jpg
  Processed successfully. CER: 0.508
Processing test image 20/48: inventarbuch-181.jpg
  Processed successfully. CER: 0.266
Processing test image 21/48: inventarbuch-299.jpg
  Processed successfully. CER: 0.235
Processing test image 22/48: inventarbuch-084.jpg
  Processed successfully. CER: 0.353
Processing test image 23/48: inventarbuch-004.jpg
  Processed successfully. CER: 0.170
Processing test image 24/48: inventarbuch-148.jpg
  Processed successfully. CER: 0.087
Processing test image 25/48: inventarbuch-238.jpg
  Processed successfully. CER: 0.187
Processing test image 26/48: inventarbuch-116.jpg
  Processed successfully. CER: 0.141
Processing test image 27/48: inventarbuch-223.jpg
  Processed successfully. CER: 0.171
Processing test image 28/48: inventarbuch-104.jpg
  Processed successfully. CER: 0.283
Processing test image 29/48: inventarbuch-015.jpg
  Processed successfully. CER: 0.228
Processing test image 30/48: inventarbuch-272.jpg
  Processed successfully. CER: 0.218
Processing test image 31/48: inventarbuch-124.jpg
  Processed successfully. CER: 0.142
Processing test image 32/48: inventarbuch-115.jpg
  Processed successfully. CER: 0.213
Processing test image 33/48: inventarbuch-049.jpg
  Processed successfully. CER: 0.033
Processing test image 34/48: inventarbuch-017.jpg
  Processed successfully. CER: 0.038
Processing test image 35/48: inventarbuch-018.jpg
  Processed successfully. CER: 0.188
Processing test image 36/48: inventarbuch-225.jpg
  Processed successfully. CER: 0.371
Processing test image 37/48: inventarbuch-046.jpg
  Processed successfully. CER: 0.209
Processing test image 38/48: inventarbuch-294.jpg
  Processed successfully. CER: 0.130
Processing test image 39/48: inventarbuch-054.jpg
  Processed successfully. CER: 0.319
Processing test image 40/48: inventarbuch-073.jpg
  Processed successfully. CER: 0.302
Processing test image 41/48: inventarbuch-118.jpg
  Processed successfully. CER: 0.201
Processing test image 42/48: inventarbuch-130.jpg
  Processed successfully. CER: 0.173
Processing test image 43/48: inventarbuch-146.jpg
  Processed successfully. CER: 0.227
Processing test image 44/48: inventarbuch-014.jpg
  Processed successfully. CER: 0.263
Processing test image 45/48: inventarbuch-059.jpg
  Processed successfully. CER: 0.209
Processing test image 46/48: inventarbuch-256.jpg
  Processed successfully. CER: 0.140
Processing test image 47/48: inventarbuch-260.jpg
  Processed successfully. CER: 0.148
Processing test image 48/48: inventarbuch-279.jpg
  Processed successfully. CER: 0.278
CER evaluation results saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/inventory_dataset/run_20250901_004326/cer_evaluation_results.txt

Evaluation completed!
Predictions saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/inventory_dataset/run_20250901_004326/test_predictions.jsonl
CER results saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/inventory_dataset/run_20250901_004326/cer_evaluation_results.txt
All files saved in: /home/vault/iwi5/iwi5298h/models_image_text/qwen/inventory_dataset/run_20250901_004326

============================================================
FINAL RESULTS SUMMARY
============================================================
Average CER: 0.2108 (21.08%)
Median CER: 0.2112 (21.12%)
Perfect matches: 0/48 (0.00%)
Total images processed: 48

Training and evaluation completed successfully!
All outputs saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/inventory_dataset/run_20250901_004326
=== JOB_STATISTICS ===
=== current date     : Mon Sep  1 01:35:55 AM CEST 2025
= Job-ID             : 1198224 on tinygpu
= Job-Name           : qwen_inven
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_qwen.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : v100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 10:00:00
= Elapsed runtime    : 00:53:06
= Total RAM usage    : 20.7 GiB of requested  GiB (%)   
= Node list          : tg074
= Subm/Elig/Start/End: 2025-09-01T00:42:49 / 2025-09-01T00:42:49 / 2025-09-01T00:42:49 / 2025-09-01T01:35:55
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc              26.1G   104.9G   209.7G        N/A  32,239      500K   1,000K        N/A    
    /home/woody            46.7G  1000.0G  1500.0G        N/A     238K   5,000K   7,500K        N/A    
    /home/vault           762.0G  1048.6G  2097.2G        N/A   1,868      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:18:00.0, 2474035, 41 %, 18 %, 10522 MiB, 3176061 ms
