### Starting TaskPrologue of job 1243571 on tg071 at Sun Oct 19 04:21:30 PM CEST 2025
Running on cores 4-5,12-13,20-21,28-29 with governor ondemand
Sun Oct 19 16:21:30 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           Off |   00000000:86:00.0 Off |                    0 |
| N/A   32C    P0             26W /  250W |       0MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Created run directory: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_162211
Loading Qwen2.5-VL model from /home/vault/iwi5/iwi5298h/models/qwen7b with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.7.3: Fast Qwen2_5_Vl patching. Transformers: 4.51.3.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.1+cu126. CUDA: 7.0. CUDA Toolkit: 12.6. Triton: 3.3.1
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to eager!
Unsloth: Making `model.base_model.model.visual` require gradients
Created temporary directory for augmented images: /tmp/1243571.tinygpu/augmented_images_qvenjnmh
Model loaded successfully with optimized LoRA adapters!
============================================================
STARTING STAIRCASE DATASET TRAINING WITH CER-BASED MODEL SELECTION
============================================================
Cached 2 training few-shot exemplars for test-time inference.
Preparing training and validation datasets...
Preparing training data with augmentation factor: 2
Creating augmentation 1/2 for image 1/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (14).jpg
Creating augmentation 2/2 for image 1/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (14).jpg
Creating augmentation 1/2 for image 2/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (18).jpg
Creating augmentation 2/2 for image 2/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (18).jpg
Creating augmentation 1/2 for image 3/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (35).jpg
Creating augmentation 2/2 for image 3/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (35).jpg
Creating augmentation 1/2 for image 4/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (12).jpg
Creating augmentation 2/2 for image 4/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (12).jpg
Creating augmentation 1/2 for image 5/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (27).jpg
Creating augmentation 2/2 for image 5/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (27).jpg
Creating augmentation 1/2 for image 6/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (2).jpg
Creating augmentation 2/2 for image 6/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (2).jpg
Creating augmentation 1/2 for image 7/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (3).jpg
Creating augmentation 2/2 for image 7/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (3).jpg
Creating augmentation 1/2 for image 8/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (25).jpg
Creating augmentation 2/2 for image 8/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (25).jpg
Creating augmentation 1/2 for image 9/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (37).jpg
Creating augmentation 2/2 for image 9/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (37).jpg
Creating augmentation 1/2 for image 10/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (15).jpg
Creating augmentation 2/2 for image 10/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (15).jpg
Creating augmentation 1/2 for image 11/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (34).jpg
Creating augmentation 2/2 for image 11/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (34).jpg
Creating augmentation 1/2 for image 12/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (22).jpg
Creating augmentation 2/2 for image 12/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (22).jpg
Creating augmentation 1/2 for image 13/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (38).jpg
Creating augmentation 2/2 for image 13/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (38).jpg
Creating augmentation 1/2 for image 14/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (28).jpg
Creating augmentation 2/2 for image 14/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (28).jpg
Creating augmentation 1/2 for image 15/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (4).jpg
Creating augmentation 2/2 for image 15/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (4).jpg
Creating augmentation 1/2 for image 16/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (16).jpg
Creating augmentation 2/2 for image 16/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (16).jpg
Creating augmentation 1/2 for image 17/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (24).jpg
Creating augmentation 2/2 for image 17/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (24).jpg
Creating augmentation 1/2 for image 18/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (11).jpg
Creating augmentation 2/2 for image 18/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (11).jpg
Creating augmentation 1/2 for image 19/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (39).jpg
Creating augmentation 2/2 for image 19/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (39).jpg
Creating augmentation 1/2 for image 20/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (41).jpg
Creating augmentation 2/2 for image 20/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (41).jpg
Creating augmentation 1/2 for image 21/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (21).jpg
Creating augmentation 2/2 for image 21/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (21).jpg
Creating augmentation 1/2 for image 22/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (8).jpg
Creating augmentation 2/2 for image 22/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (8).jpg
Creating augmentation 1/2 for image 23/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (7).jpg
Creating augmentation 2/2 for image 23/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (7).jpg
Creating augmentation 1/2 for image 24/26: FMIS_FormblaÌˆtterMielke_Vorlage1.jpg
Creating augmentation 2/2 for image 24/26: FMIS_FormblaÌˆtterMielke_Vorlage1.jpg
Creating augmentation 1/2 for image 25/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (36).jpg
Creating augmentation 2/2 for image 25/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (36).jpg
Creating augmentation 1/2 for image 26/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (26).jpg
Creating augmentation 2/2 for image 26/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (26).jpg
Successfully created 52 augmented images
Total training samples: 78 (original: 26, augmented: 52)
Training: 78 samples, Validation: 9 samples
Unsloth: Model does not have a default image size - using 512
GPU = Tesla V100-PCIE-32GB. Max memory = 31.733 GB.
7.854 GB of memory reserved.
Starting training with CER-based model selection and early stopping...
Model selection based on: eval_cer_jiwer (lower is better)
Unsloth: Will smartly offload gradients to save VRAM!
{'eval_loss': 1.4647094011306763, 'eval_cer_jiwer': 82.01013595308301, 'eval_runtime': 23.2972, 'eval_samples_per_second': 0.386, 'eval_steps_per_second': 0.215, 'epoch': 0.92}
{'loss': 1.9467, 'grad_norm': 11.513476371765137, 'learning_rate': 7.000000000000001e-06, 'epoch': 1.1}
{'eval_loss': 1.001952052116394, 'eval_cer_jiwer': 85.46290017977924, 'eval_runtime': 20.9426, 'eval_samples_per_second': 0.43, 'eval_steps_per_second': 0.239, 'epoch': 1.92}
{'loss': 1.4072, 'grad_norm': 7.582539081573486, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.21}
{'eval_loss': 0.6996960043907166, 'eval_cer_jiwer': 86.66815530670466, 'eval_runtime': 20.8192, 'eval_samples_per_second': 0.432, 'eval_steps_per_second': 0.24, 'epoch': 2.92}
{'loss': 0.9807, 'grad_norm': 3.6314003467559814, 'learning_rate': 2.5e-05, 'epoch': 3.31}
{'eval_loss': 0.3751867413520813, 'eval_cer_jiwer': 83.25816034712038, 'eval_runtime': 20.8616, 'eval_samples_per_second': 0.431, 'eval_steps_per_second': 0.24, 'epoch': 3.92}
{'train_runtime': 808.0426, 'train_samples_per_second': 1.931, 'train_steps_per_second': 0.223, 'train_loss': 1.3055818147129483, 'epoch': 3.92}
808.0426 seconds used for training.
13.47 minutes used for training.
Peak reserved memory = 13.373 GB.
Peak reserved memory for training = 5.519 GB.
Peak reserved memory % of max memory = 42.142 %.
Peak reserved memory for training % of max memory = 17.392 %.
Saving best model (selected by CER) to /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_162211...
Saving model in recommended formats...
Detected local model directory: /home/vault/iwi5/iwi5298h/models/qwen7b
Found HuggingFace hub cache directory: /home/hpc/iwi5/iwi5298h/.cache/huggingface/hub
Copying safetensors from local directory: /home/vault/iwi5/iwi5298h/models/qwen7b
Copied safetensors index file from local model
Copied model-00005-of-00005.safetensors from local model directory
Copied model-00004-of-00005.safetensors from local model directory
Copied model-00002-of-00005.safetensors from local model directory
Copied model-00003-of-00005.safetensors from local model directory
Copied model-00001-of-00005.safetensors from local model directory
Detected local model directory: /home/vault/iwi5/iwi5298h/models/qwen7b
Found HuggingFace hub cache directory: /home/hpc/iwi5/iwi5298h/.cache/huggingface/hub
Copying safetensors from local directory: /home/vault/iwi5/iwi5298h/models/qwen7b
Copied safetensors index file from local model
Copied model-00005-of-00005.safetensors from local model directory
Copied model-00004-of-00005.safetensors from local model directory
Copied model-00002-of-00005.safetensors from local model directory
Copied model-00003-of-00005.safetensors from local model directory
Copied model-00001-of-00005.safetensors from local model directory
Best model saved successfully in multiple formats (selected based on CER)!

============================================================
STARTING EVALUATION ON STAIRCASE TEST.JSONL
============================================================
Starting evaluation on test.jsonl...
Loaded 9 test samples
Processing test image 1/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (6).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (6).jpg: CUDA out of memory. Tried to allocate 328.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 48.25 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.93 GiB is allocated by PyTorch, and 344.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing test image 2/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (31).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (31).jpg: CUDA out of memory. Tried to allocate 328.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 108.25 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.92 GiB is allocated by PyTorch, and 285.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing test image 3/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (32).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (32).jpg: CUDA out of memory. Tried to allocate 328.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 68.25 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.93 GiB is allocated by PyTorch, and 324.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing test image 4/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (5).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (5).jpg: CUDA out of memory. Tried to allocate 328.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 108.25 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.93 GiB is allocated by PyTorch, and 284.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing test image 5/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (40).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (40).jpg: CUDA out of memory. Tried to allocate 328.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 48.25 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.92 GiB is allocated by PyTorch, and 345.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing test image 6/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (9).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (9).jpg: CUDA out of memory. Tried to allocate 328.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 48.25 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.93 GiB is allocated by PyTorch, and 344.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing test image 7/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (13).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (13).jpg: CUDA out of memory. Tried to allocate 328.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 88.25 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.92 GiB is allocated by PyTorch, and 305.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing test image 8/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (20).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (20).jpg: CUDA out of memory. Tried to allocate 328.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 28.25 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.92 GiB is allocated by PyTorch, and 366.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing test image 9/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (17).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (17).jpg: CUDA out of memory. Tried to allocate 656.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 248.25 MiB is free. Including non-PyTorch memory, this process has 31.47 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 364.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
CER evaluation results saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_162211/cer_evaluation_results.txt

Evaluation completed!
Predictions saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_162211/test_predictions.jsonl
CER results saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_162211/cer_evaluation_results.txt
All files saved in: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_162211

============================================================
FINAL RESULTS SUMMARY - STAIRCASE DATASET WITH CER-BASED SELECTION
============================================================
Model selection: CER-based (eval_cer_jiwer)
Augmentation factor: 2
Average CER: 1.0000 (100.00%)
Median CER: 1.0000 (100.00%)
Perfect matches: 0/9 (0.00%)
Total images processed: 9

Staircase dataset training and evaluation completed successfully!
Best model (based on CER) saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_162211
Cleaned up temporary directory: /tmp/1243571.tinygpu/augmented_images_qvenjnmh
=== JOB_STATISTICS ===
=== current date     : Sun Oct 19 04:59:32 PM CEST 2025
= Job-ID             : 1243571 on tinygpu
= Job-Name           : qwen_stair_finetune_fewshot
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_qwen2.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : v100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 18:00:00
= Elapsed runtime    : 00:38:06
= Total RAM usage    : 20.7 GiB of requested  GiB (%)   
= Node list          : tg071
= Subm/Elig/Start/End: 2025-10-19T16:21:14 / 2025-10-19T16:21:14 / 2025-10-19T16:21:15 / 2025-10-19T16:59:21
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody           127.7G  1000.0G  1500.0G        N/A     630K   5,000K   7,500K        N/A    
    /home/hpc              96.7G   104.9G   209.7G        N/A  33,143      500K   1,000K        N/A    
    /home/vault           614.0G  1048.6G  2097.2G        N/A   3,700      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:86:00.0, 3732318, 21 %, 9 %, 32464 MiB, 2269511 ms
