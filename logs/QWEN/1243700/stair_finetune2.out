### Starting TaskPrologue of job 1243700 on tg071 at Sun Oct 19 06:42:49 PM CEST 2025
Running on cores 4-5,12-13,20-21,28-29 with governor ondemand
Sun Oct 19 18:42:49 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           Off |   00000000:86:00.0 Off |                    0 |
| N/A   32C    P0             27W /  250W |       0MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Created run directory: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_184319
Loading Qwen2.5-VL model from /home/vault/iwi5/iwi5298h/models/qwen7b with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.7.3: Fast Qwen2 patching. Transformers: 4.51.3.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.1+cu126. CUDA: 7.0. CUDA Toolkit: 12.6. Triton: 3.3.1
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2 does not support SDPA - switching to eager!
Unsloth: Making `model.base_model.model.visual` require gradients
Created temporary directory for augmented images: /tmp/1243700.tinygpu/augmented_images_ahl442ys
Model loaded successfully with optimized LoRA adapters!
============================================================
STARTING TRAINING (single-image teacher forcing) + CER-based selection
============================================================
Preparing training and validation datasets...
Inferred schema key order: ['stair_type', 'Name des Hauses', 'Adresse', 'Bauherr', 'Baumeister', 'Bauzeit', 'MATERIAL', 'TREPPENTYP (Laufform)', 'LÃ„UFE', 'Notes', 'STUFENPROFIL', 'Schweifung', 'Untertritt', 'WANGE / HOLM', 'GELÃ„NDER', 'ANFÃ„NGER', 'DEKORATION', 'HANDLAUFPROFIL', 'Datum', 'Signature', 'ORT']
Preparing training data with augmentation factor: 2
Augmented: 52, total train samples: 78
Training: 78 samples, Validation: 9 samples
Unsloth: Model does not have a default image size - using 512
GPU = Tesla V100-PCIE-32GB. Max memory = 31.733 GB.
7.854 GB of memory reserved before training.
Starting training with CER-based model selection and early stopping...
Unsloth: Will smartly offload gradients to save VRAM!
{'eval_loss': 17.500314712524414, 'eval_cer_jiwer': 169.19685240268865, 'eval_runtime': 22.7916, 'eval_samples_per_second': 0.395, 'eval_steps_per_second': 0.219, 'epoch': 0.92}
{'loss': 19.1821, 'grad_norm': 42.096683502197266, 'learning_rate': 1.1111111111111112e-05, 'epoch': 1.1}
{'eval_loss': 11.239253997802734, 'eval_cer_jiwer': 112.782394827458, 'eval_runtime': 20.2341, 'eval_samples_per_second': 0.445, 'eval_steps_per_second': 0.247, 'epoch': 1.92}
{'loss': 14.0092, 'grad_norm': 15.331206321716309, 'learning_rate': 2.5925925925925925e-05, 'epoch': 2.21}
{'eval_loss': 5.10276985168457, 'eval_cer_jiwer': 117.74181074659475, 'eval_runtime': 20.4163, 'eval_samples_per_second': 0.441, 'eval_steps_per_second': 0.245, 'epoch': 2.92}
{'loss': 6.8238, 'grad_norm': 24.4251766204834, 'learning_rate': 4.4444444444444447e-05, 'epoch': 3.31}
{'eval_loss': 1.7780710458755493, 'eval_cer_jiwer': 108.4647278602635, 'eval_runtime': 20.2736, 'eval_samples_per_second': 0.444, 'eval_steps_per_second': 0.247, 'epoch': 3.92}
{'loss': 2.1543, 'grad_norm': 2.052488327026367, 'learning_rate': 4.974220459770639e-05, 'epoch': 4.41}
{'eval_loss': 0.9106661677360535, 'eval_cer_jiwer': 96.94831231031894, 'eval_runtime': 20.4277, 'eval_samples_per_second': 0.441, 'eval_steps_per_second': 0.245, 'epoch': 4.92}
{'loss': 0.989, 'grad_norm': 0.3183618187904358, 'learning_rate': 4.849231551964771e-05, 'epoch': 5.51}
{'eval_loss': 0.8513950109481812, 'eval_cer_jiwer': 90.69247428395482, 'eval_runtime': 20.1925, 'eval_samples_per_second': 0.446, 'eval_steps_per_second': 0.248, 'epoch': 5.92}
{'loss': 0.893, 'grad_norm': 0.3284480571746826, 'learning_rate': 4.625542839324036e-05, 'epoch': 6.62}
{'eval_loss': 0.8366417288780212, 'eval_cer_jiwer': 93.15737129269226, 'eval_runtime': 20.0358, 'eval_samples_per_second': 0.449, 'eval_steps_per_second': 0.25, 'epoch': 6.92}
{'loss': 0.876, 'grad_norm': 0.13454410433769226, 'learning_rate': 4.312552302333982e-05, 'epoch': 7.72}
{'eval_loss': 0.8301860094070435, 'eval_cer_jiwer': 94.94977431907472, 'eval_runtime': 20.1327, 'eval_samples_per_second': 0.447, 'eval_steps_per_second': 0.248, 'epoch': 7.92}
{'loss': 0.8689, 'grad_norm': 0.14555023610591888, 'learning_rate': 3.923409817553284e-05, 'epoch': 8.82}
{'eval_loss': 0.8260796070098877, 'eval_cer_jiwer': 96.39943490506185, 'eval_runtime': 20.2877, 'eval_samples_per_second': 0.444, 'eval_steps_per_second': 0.246, 'epoch': 8.92}
{'loss': 0.8647, 'grad_norm': 0.12471425533294678, 'learning_rate': 3.474464683231698e-05, 'epoch': 9.92}
{'eval_loss': 0.8232625126838684, 'eval_cer_jiwer': 96.93556720682966, 'eval_runtime': 20.1078, 'eval_samples_per_second': 0.448, 'eval_steps_per_second': 0.249, 'epoch': 9.92}
{'train_runtime': 1992.7459, 'train_samples_per_second': 0.783, 'train_steps_per_second': 0.09, 'train_loss': 5.189116129610274, 'epoch': 9.92}
Train runtime: 1992.7459s (33.21 min). Peak reserved: 13.281 GB (delta 5.427 GB).
Saving best model (selected by CER) to /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_184319...
Saving model in recommended formats...
Detected local model directory: /home/vault/iwi5/iwi5298h/models/qwen7b
Found HuggingFace hub cache directory: /home/hpc/iwi5/iwi5298h/.cache/huggingface/hub
Copying safetensors from local directory: /home/vault/iwi5/iwi5298h/models/qwen7b
Copied safetensors index file from local model
Copied model-00005-of-00005.safetensors from local model directory
Copied model-00004-of-00005.safetensors from local model directory
Copied model-00002-of-00005.safetensors from local model directory
Copied model-00003-of-00005.safetensors from local model directory
Copied model-00001-of-00005.safetensors from local model directory
Detected local model directory: /home/vault/iwi5/iwi5298h/models/qwen7b
Found HuggingFace hub cache directory: /home/hpc/iwi5/iwi5298h/.cache/huggingface/hub
Copying safetensors from local directory: /home/vault/iwi5/iwi5298h/models/qwen7b
Copied safetensors index file from local model
Copied model-00005-of-00005.safetensors from local model directory
Copied model-00004-of-00005.safetensors from local model directory
Copied model-00002-of-00005.safetensors from local model directory
Copied model-00003-of-00005.safetensors from local model directory
Copied model-00001-of-00005.safetensors from local model directory
Best model saved successfully in multiple formats (selected based on CER)!

============================================================
STARTING ZERO-SHOT EVALUATION ON TEST
============================================================
Starting evaluation on test.jsonl...
Loaded 9 test samples
Processing test image 1/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (6).jpg
Processing test image 2/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (31).jpg
Processing test image 3/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (32).jpg
Processing test image 4/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (5).jpg
Processing test image 5/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (40).jpg
Processing test image 6/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (9).jpg
Processing test image 7/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (13).jpg
Processing test image 8/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (20).jpg
Processing test image 9/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (17).jpg
CER evaluation results saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_184319/cer_evaluation_results.txt

Evaluation completed!
Predictions: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_184319/test_predictions.jsonl
CER results: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_184319/cer_evaluation_results.txt
All files saved in: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_184319

============================================================
FINAL RESULTS SUMMARY - STAIRCASE DATASET
============================================================
Average CER: 1.0000 (100.00%)
Median CER: 1.0000 (100.00%)
Perfect matches: 0/9 (0.00%)
Total images processed: 9
Cleaned up temporary directory: /tmp/1243700.tinygpu/augmented_images_ahl442ys
=== JOB_STATISTICS ===
=== current date     : Sun Oct 19 07:40:23 PM CEST 2025
= Job-ID             : 1243700 on tinygpu
= Job-Name           : stair_finetune2
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_qwen2.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : v100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 18:00:00
= Elapsed runtime    : 00:57:39
= Total RAM usage    : 20.7 GiB of requested  GiB (%)   
= Node list          : tg071
= Subm/Elig/Start/End: 2025-10-19T18:42:32 / 2025-10-19T18:42:32 / 2025-10-19T18:42:33 / 2025-10-19T19:40:12
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody           136.1G  1000.0G  1500.0G        N/A     680K   5,000K   7,500K        N/A    
!!! /home/hpc             115.6G   104.9G   209.7G  -29323days  33,822      500K   1,000K        N/A !!!
    /home/vault           748.7G  1048.6G  2097.2G        N/A   3,865      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:86:00.0, 3902730, 35 %, 15 %, 32468 MiB, 3446495 ms
