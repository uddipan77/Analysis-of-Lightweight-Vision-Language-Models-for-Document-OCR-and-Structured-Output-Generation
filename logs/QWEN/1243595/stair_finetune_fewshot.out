### Starting TaskPrologue of job 1243595 on tg071 at Sun Oct 19 05:13:01 PM CEST 2025
Running on cores 0-1,8-9,17-18,24-25 with governor ondemand
Sun Oct 19 17:13:01 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           Off |   00000000:18:00.0 Off |                    0 |
| N/A   29C    P0             26W /  250W |       0MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Created run directory: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_171333
Loading Qwen2.5-VL model from /home/vault/iwi5/iwi5298h/models/qwen7b with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.7.3: Fast Qwen2_5_Vl patching. Transformers: 4.51.3.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.1+cu126. CUDA: 7.0. CUDA Toolkit: 12.6. Triton: 3.3.1
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to eager!
Unsloth: Making `model.base_model.model.visual` require gradients
Created temporary directory: /tmp/1243595.tinygpu/augmented_images_hnhfwc90
Model loaded successfully with optimized LoRA adapters (4-bit weights)!
============================================================
STARTING STAIRCASE DATASET TRAINING WITH CER-BASED MODEL SELECTION
============================================================
Preparing training and validation datasets...
Preparing training data with augmentation factor: 2
Creating augmentation 1/2 for image 1/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (14).jpg
Creating augmentation 2/2 for image 1/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (14).jpg
Creating augmentation 1/2 for image 2/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (18).jpg
Creating augmentation 2/2 for image 2/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (18).jpg
Creating augmentation 1/2 for image 3/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (35).jpg
Creating augmentation 2/2 for image 3/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (35).jpg
Creating augmentation 1/2 for image 4/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (12).jpg
Creating augmentation 2/2 for image 4/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (12).jpg
Creating augmentation 1/2 for image 5/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (27).jpg
Creating augmentation 2/2 for image 5/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (27).jpg
Creating augmentation 1/2 for image 6/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (2).jpg
Creating augmentation 2/2 for image 6/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (2).jpg
Creating augmentation 1/2 for image 7/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (3).jpg
Creating augmentation 2/2 for image 7/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (3).jpg
Creating augmentation 1/2 for image 8/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (25).jpg
Creating augmentation 2/2 for image 8/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (25).jpg
Creating augmentation 1/2 for image 9/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (37).jpg
Creating augmentation 2/2 for image 9/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (37).jpg
Creating augmentation 1/2 for image 10/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (15).jpg
Creating augmentation 2/2 for image 10/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (15).jpg
Creating augmentation 1/2 for image 11/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (34).jpg
Creating augmentation 2/2 for image 11/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (34).jpg
Creating augmentation 1/2 for image 12/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (22).jpg
Creating augmentation 2/2 for image 12/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (22).jpg
Creating augmentation 1/2 for image 13/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (38).jpg
Creating augmentation 2/2 for image 13/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (38).jpg
Creating augmentation 1/2 for image 14/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (28).jpg
Creating augmentation 2/2 for image 14/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (28).jpg
Creating augmentation 1/2 for image 15/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (4).jpg
Creating augmentation 2/2 for image 15/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (4).jpg
Creating augmentation 1/2 for image 16/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (16).jpg
Creating augmentation 2/2 for image 16/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (16).jpg
Creating augmentation 1/2 for image 17/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (24).jpg
Creating augmentation 2/2 for image 17/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (24).jpg
Creating augmentation 1/2 for image 18/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (11).jpg
Creating augmentation 2/2 for image 18/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (11).jpg
Creating augmentation 1/2 for image 19/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (39).jpg
Creating augmentation 2/2 for image 19/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (39).jpg
Creating augmentation 1/2 for image 20/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (41).jpg
Creating augmentation 2/2 for image 20/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (41).jpg
Creating augmentation 1/2 for image 21/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (21).jpg
Creating augmentation 2/2 for image 21/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (21).jpg
Creating augmentation 1/2 for image 22/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (8).jpg
Creating augmentation 2/2 for image 22/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (8).jpg
Creating augmentation 1/2 for image 23/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (7).jpg
Creating augmentation 2/2 for image 23/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (7).jpg
Creating augmentation 1/2 for image 24/26: FMIS_FormblaÌˆtterMielke_Vorlage1.jpg
Creating augmentation 2/2 for image 24/26: FMIS_FormblaÌˆtterMielke_Vorlage1.jpg
Creating augmentation 1/2 for image 25/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (36).jpg
Creating augmentation 2/2 for image 25/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (36).jpg
Creating augmentation 1/2 for image 26/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (26).jpg
Creating augmentation 2/2 for image 26/26: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (26).jpg
Successfully created 52 augmented images
Total training samples: 78 (original: 26, augmented: 52)
Training: 78 samples, Validation: 9 samples
Unsloth: Model does not have a default image size - using 512
GPU = Tesla V100-PCIE-32GB. Max memory = 31.733 GB.
7.854 GB of memory reserved.
Starting training with CER-based model selection and early stopping...
Model selection based on: eval_cer_jiwer (lower is better)
Unsloth: Will smartly offload gradients to save VRAM!
{'eval_loss': 1.6164114475250244, 'eval_cer_jiwer': 82.49555428529834, 'eval_runtime': 27.8723, 'eval_samples_per_second': 0.323, 'eval_steps_per_second': 0.323, 'epoch': 0.92}
{'loss': 1.9745, 'grad_norm': 14.987805366516113, 'learning_rate': 5e-06, 'epoch': 1.1}
{'eval_loss': 1.110513687133789, 'eval_cer_jiwer': 84.84426083976685, 'eval_runtime': 24.6866, 'eval_samples_per_second': 0.365, 'eval_steps_per_second': 0.365, 'epoch': 1.92}
{'loss': 1.567, 'grad_norm': 9.301580429077148, 'learning_rate': 1.4000000000000001e-05, 'epoch': 2.21}
{'eval_loss': 0.7329895496368408, 'eval_cer_jiwer': 82.18774226572702, 'eval_runtime': 24.7826, 'eval_samples_per_second': 0.363, 'eval_steps_per_second': 0.363, 'epoch': 2.92}
{'loss': 1.0455, 'grad_norm': 5.739952087402344, 'learning_rate': 2.4e-05, 'epoch': 3.31}
{'eval_loss': 0.36660903692245483, 'eval_cer_jiwer': 82.48748695223854, 'eval_runtime': 24.7523, 'eval_samples_per_second': 0.364, 'eval_steps_per_second': 0.364, 'epoch': 3.92}
{'loss': 0.5326, 'grad_norm': 4.096501350402832, 'learning_rate': 3.3e-05, 'epoch': 4.41}
{'eval_loss': 0.1777065396308899, 'eval_cer_jiwer': 78.84330421665852, 'eval_runtime': 27.2271, 'eval_samples_per_second': 0.331, 'eval_steps_per_second': 0.331, 'epoch': 4.92}
{'loss': 0.2249, 'grad_norm': 1.7060612440109253, 'learning_rate': 4.3e-05, 'epoch': 5.51}
=== JOB_STATISTICS ===
=== current date     : Sun Oct 19 05:39:42 PM CEST 2025
= Job-ID             : 1243595 on tinygpu
= Job-Name           : qwen_stair_finetune_fewshot
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_qwen2.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : v100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 18:00:00
= Elapsed runtime    : 00:26:40
= Total RAM usage    : 20.7 GiB of requested  GiB (%)   
= Node list          : tg071
= Subm/Elig/Start/End: 2025-10-19T17:12:47 / 2025-10-19T17:12:47 / 2025-10-19T17:12:48 / 2025-10-19T17:39:28
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody           127.7G  1000.0G  1500.0G        N/A     630K   5,000K   7,500K        N/A    
    /home/hpc              96.7G   104.9G   209.7G        N/A  33,158      500K   1,000K        N/A    
    /home/vault           615.1G  1048.6G  2097.2G        N/A   3,727      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:18:00.0, 3790839, 49 %, 22 %, 12800 MiB, 1589757 ms
