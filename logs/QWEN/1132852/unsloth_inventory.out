### Starting TaskPrologue of job 1132852 on tg074 at Sun Jul 27 11:00:07 PM CEST 2025
Running on cores 2-3,10-11,18-19,26-27 with governor ondemand
Sun Jul 27 23:00:07 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.158.01             Driver Version: 570.158.01     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           On  |   00000000:3B:00.0 Off |                    0 |
| N/A   35C    P0             25W /  250W |       0MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
[2025-07-27 23:00:36,136] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-27 23:00:38,077] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Created run directory: /home/vault/iwi5/iwi5298h/models_image_text/qwen/inventory_dataset/run_20250727_230050
Loading Qwen2.5-VL model with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.7.3: Fast Qwen2_5_Vl patching. Transformers: 4.51.3.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.1+cu126. CUDA: 7.0. CUDA Toolkit: 12.6. Triton: 3.3.1
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to eager!
Unsloth: Making `model.base_model.model.visual` require gradients
Model loaded successfully with optimized LoRA adapters!
============================================================
STARTING TRAINING WITH VALIDATION MONITORING
============================================================
Preparing training and validation datasets...
Training: 205 samples, Validation: 44 samples
Unsloth: Model does not have a default image size - using 512
GPU = Tesla V100-PCIE-32GB. Max memory = 31.733 GB.
7.82 GB of memory reserved.
Starting training with early stopping...
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 3.6578, 'grad_norm': 14.599434852600098, 'learning_rate': 6e-06, 'epoch': 0.39}
{'loss': 2.8577, 'grad_norm': 6.571088790893555, 'learning_rate': 1.5e-05, 'epoch': 0.78}
{'eval_loss': 1.8511143922805786, 'eval_runtime': 17.6471, 'eval_samples_per_second': 2.493, 'eval_steps_per_second': 1.247, 'epoch': 0.97}
{'loss': 1.877, 'grad_norm': 5.973433494567871, 'learning_rate': 2.5e-05, 'epoch': 1.19}
{'loss': 1.2359, 'grad_norm': 7.441557884216309, 'learning_rate': 3.5e-05, 'epoch': 1.58}
{'loss': 1.1098, 'grad_norm': 6.209110736846924, 'learning_rate': 4.5e-05, 'epoch': 1.97}
{'eval_loss': 1.1028097867965698, 'eval_runtime': 23.594, 'eval_samples_per_second': 1.865, 'eval_steps_per_second': 0.932, 'epoch': 1.97}
{'loss': 0.9417, 'grad_norm': 6.005845069885254, 'learning_rate': 4.99847706754774e-05, 'epoch': 2.39}
{'loss': 1.0322, 'grad_norm': 4.476022243499756, 'learning_rate': 4.9863047384206835e-05, 'epoch': 2.78}
{'eval_loss': 1.043749451637268, 'eval_runtime': 17.5497, 'eval_samples_per_second': 2.507, 'eval_steps_per_second': 1.254, 'epoch': 2.97}
{'loss': 0.8539, 'grad_norm': 2.124182939529419, 'learning_rate': 4.962019382530521e-05, 'epoch': 3.19}
{'loss': 0.7644, 'grad_norm': 2.793339729309082, 'learning_rate': 4.925739315689991e-05, 'epoch': 3.58}
{'loss': 0.7621, 'grad_norm': 42.374488830566406, 'learning_rate': 4.877641290737884e-05, 'epoch': 3.97}
{'eval_loss': 1.0557173490524292, 'eval_runtime': 17.3156, 'eval_samples_per_second': 2.541, 'eval_steps_per_second': 1.271, 'epoch': 3.97}
{'loss': 0.5739, 'grad_norm': 3.9813685417175293, 'learning_rate': 4.817959636416969e-05, 'epoch': 4.39}
{'loss': 0.5209, 'grad_norm': 3.5540273189544678, 'learning_rate': 4.7469851157479177e-05, 'epoch': 4.78}
{'eval_loss': 1.135254979133606, 'eval_runtime': 17.712, 'eval_samples_per_second': 2.484, 'eval_steps_per_second': 1.242, 'epoch': 4.97}
{'loss': 0.4425, 'grad_norm': 4.732052803039551, 'learning_rate': 4.665063509461097e-05, 'epoch': 5.19}
{'loss': 0.3379, 'grad_norm': 9.282888412475586, 'learning_rate': 4.572593931387604e-05, 'epoch': 5.58}
{'loss': 0.366, 'grad_norm': 4.627243518829346, 'learning_rate': 4.4700268840168045e-05, 'epoch': 5.97}
{'eval_loss': 1.2592726945877075, 'eval_runtime': 17.6971, 'eval_samples_per_second': 2.486, 'eval_steps_per_second': 1.243, 'epoch': 5.97}
{'train_runtime': 1632.6629, 'train_samples_per_second': 2.511, 'train_steps_per_second': 0.306, 'train_loss': 1.156103909810384, 'epoch': 5.97}
1632.6629 seconds used for training.
27.21 minutes used for training.
Peak reserved memory = 10.66 GB.
Peak reserved memory for training = 2.84 GB.
Peak reserved memory % of max memory = 33.593 %.
Peak reserved memory for training % of max memory = 8.95 %.
Saving model to /home/vault/iwi5/iwi5298h/models_image_text/qwen/inventory_dataset/run_20250727_230050...
Saving model in recommended formats...
Model saved successfully in multiple formats!

============================================================
STARTING EVALUATION ON TEST.JSONL
============================================================
Starting evaluation on test.jsonl...
Loaded 45 test samples
Processing test image 1/45: inventarbuch-022.jpg
  Processed successfully. CER: 0.310
Processing test image 2/45: inventarbuch-099.jpg
  Processed successfully. CER: 0.175
Processing test image 3/45: inventarbuch-245.jpg
  Processed successfully. CER: 0.249
Processing test image 4/45: inventarbuch-263.jpg
  Processed successfully. CER: 0.137
Processing test image 5/45: inventarbuch-033.jpg
  Processed successfully. CER: 0.305
Processing test image 6/45: inventarbuch-143.jpg
  Processed successfully. CER: 0.162
Processing test image 7/45: inventarbuch-244.jpg
  Processed successfully. CER: 0.396
Processing test image 8/45: inventarbuch-024.jpg
  Processed successfully. CER: 0.049
Processing test image 9/45: inventarbuch-141.jpg
  Processed successfully. CER: 0.110
Processing test image 10/45: inventarbuch-183.jpg
  Processed successfully. CER: 0.382
Processing test image 11/45: inventarbuch-191.jpg
  Processed successfully. CER: 0.235
Processing test image 12/45: inventarbuch-051.jpg
  Processed successfully. CER: 0.072
Processing test image 13/45: inventarbuch-203.jpg
  Processed successfully. CER: 0.213
Processing test image 14/45: inventarbuch-296.jpg
  Processed successfully. CER: 0.219
Processing test image 15/45: inventarbuch-302.jpg
  Processed successfully. CER: 0.024
Processing test image 16/45: inventarbuch-179.jpg
  Processed successfully. CER: 0.223
Processing test image 17/45: inventarbuch-114.jpg
  Processed successfully. CER: 0.236
Processing test image 18/45: inventarbuch-082.jpg
  Processed successfully. CER: 0.300
Processing test image 19/45: inventarbuch-287.jpg
  Processed successfully. CER: 0.326
Processing test image 20/45: inventarbuch-181.jpg
  Processed successfully. CER: 0.218
Processing test image 21/45: inventarbuch-299.jpg
  Processed successfully. CER: 0.229
Processing test image 22/45: inventarbuch-084.jpg
  Processed successfully. CER: 0.368
Processing test image 23/45: inventarbuch-004.jpg
  Processed successfully. CER: 0.164
Processing test image 24/45: inventarbuch-148.jpg
  Processed successfully. CER: 0.079
Processing test image 25/45: inventarbuch-238.jpg
  Processed successfully. CER: 0.231
Processing test image 26/45: inventarbuch-116.jpg
  Processed successfully. CER: 0.134
Processing test image 27/45: inventarbuch-223.jpg
  Processed successfully. CER: 0.219
Processing test image 28/45: inventarbuch-104.jpg
  Processed successfully. CER: 0.251
Processing test image 29/45: inventarbuch-015.jpg
  Processed successfully. CER: 0.233
Processing test image 30/45: inventarbuch-272.jpg
  Processed successfully. CER: 0.233
Processing test image 31/45: inventarbuch-124.jpg
  Processed successfully. CER: 0.158
Processing test image 32/45: inventarbuch-115.jpg
  Processed successfully. CER: 1.000
Processing test image 33/45: inventarbuch-049.jpg
  Processed successfully. CER: 0.033
Processing test image 34/45: inventarbuch-017.jpg
  Processed successfully. CER: 0.061
Processing test image 35/45: inventarbuch-018.jpg
  Processed successfully. CER: 0.206
Processing test image 36/45: inventarbuch-225.jpg
  Processed successfully. CER: 0.350
Processing test image 37/45: inventarbuch-046.jpg
  Processed successfully. CER: 0.203
Processing test image 38/45: inventarbuch-294.jpg
  Processed successfully. CER: 0.113
Processing test image 39/45: inventarbuch-054.jpg
  Processed successfully. CER: 0.335
Processing test image 40/45: inventarbuch-073.jpg
  Processed successfully. CER: 0.338
Processing test image 41/45: inventarbuch-118.jpg
  Processed successfully. CER: 0.191
Processing test image 42/45: inventarbuch-130.jpg
  Processed successfully. CER: 0.170
Processing test image 43/45: inventarbuch-146.jpg
  Processed successfully. CER: 0.246
Processing test image 44/45: inventarbuch-014.jpg
  Processed successfully. CER: 0.195
Processing test image 45/45: inventarbuch-059.jpg
  Processed successfully. CER: 0.282
CER evaluation results saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/inventory_dataset/run_20250727_230050/cer_evaluation_results.txt

Evaluation completed!
Predictions saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/inventory_dataset/run_20250727_230050/test_predictions.jsonl
CER results saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/inventory_dataset/run_20250727_230050/cer_evaluation_results.txt
All files saved in: /home/vault/iwi5/iwi5298h/models_image_text/qwen/inventory_dataset/run_20250727_230050

============================================================
FINAL RESULTS SUMMARY
============================================================
Average CER: 0.2303 (23.03%)
Median CER: 0.2191 (21.91%)
Perfect matches: 0/45 (0.00%)
Total images processed: 45

Training and evaluation completed successfully!
All outputs saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/inventory_dataset/run_20250727_230050
=== JOB_STATISTICS ===
=== current date     : Sun Jul 27 11:46:33 PM CEST 2025
= Job-ID             : 1132852 on tinygpu
= Job-Name           : qwen_inven
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_qwen.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : v100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 10:00:00
= Elapsed runtime    : 00:46:28
= Total RAM usage    : 10.9 GiB of requested  GiB (%)   
= Node list          : tg074
= Subm/Elig/Start/End: 2025-07-27T23:00:21 / 2025-07-27T23:00:21 / 2025-07-27T23:00:23 / 2025-07-27T23:46:51
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody            71.2G  1000.0G  1500.0G        N/A     239K   5,000K   7,500K        N/A    
    /home/hpc              90.5G   104.9G   209.7G        N/A  31,976      500K   1,000K        N/A    
    /home/vault           159.2G  1048.6G  2097.2G        N/A     771      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:3B:00.0, 2793124, 44 %, 20 %, 11326 MiB, 2777592 ms
