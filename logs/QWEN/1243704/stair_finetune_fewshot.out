### Starting TaskPrologue of job 1243704 on tg071 at Sun Oct 19 07:40:30 PM CEST 2025
Running on cores 0-1,8-9,17-18,24-25 with governor ondemand
Sun Oct 19 19:40:30 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           Off |   00000000:18:00.0 Off |                    0 |
| N/A   31C    P0             27W /  250W |       0MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Created run directory: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_194128
Loading Qwen2.5-VL model from /home/vault/iwi5/iwi5298h/models/qwen7b with Unsloth...
Unsloth: WARNING `trust_remote_code` is True.
Are you certain you want to do remote code execution?
==((====))==  Unsloth 2025.7.3: Fast Qwen2_5_Vl patching. Transformers: 4.51.3.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.1+cu126. CUDA: 7.0. CUDA Toolkit: 12.6. Triton: 3.3.1
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Qwen2_5_Vl does not support SDPA - switching to eager!
Unsloth: Making `model.base_model.model.visual` require gradients
Created temporary directory for augmented images: /tmp/1243704.tinygpu/augmented_images_e7h20zjx
Model loaded with LoRA (4-bit).
============================================================
STARTING STAIRCASE TRAINING (teacher forcing) + CER-based best-model save
============================================================
Cached 1 train exemplar(s) for test-time few-shot.
Preparing training and validation datasets...
Preparing training data with augmentation factor: 2
Successfully created 52 augmented images
Total training samples: 78 (original: 26, augmented: 52)
Training: 78 samples, Validation: 9 samples
Unsloth: Model does not have a default image size - using 512
GPU = Tesla V100-PCIE-32GB. Max memory = 31.733 GB.
7.854 GB of memory reserved.
Starting training with CER-based model selection and early stopping...
Unsloth: Will smartly offload gradients to save VRAM!
{'eval_loss': 1.73457670211792, 'eval_cer_jiwer': 76.2615173529654, 'eval_runtime': 27.353, 'eval_samples_per_second': 0.329, 'eval_steps_per_second': 0.329, 'epoch': 0.92}
{'loss': 2.0965, 'grad_norm': 8.511561393737793, 'learning_rate': 2.8000000000000003e-06, 'epoch': 1.1}
{'eval_loss': 1.3016493320465088, 'eval_cer_jiwer': 83.40340339558051, 'eval_runtime': 24.6827, 'eval_samples_per_second': 0.365, 'eval_steps_per_second': 0.365, 'epoch': 1.92}
{'loss': 1.7354, 'grad_norm': 7.84602689743042, 'learning_rate': 6.800000000000001e-06, 'epoch': 2.21}
{'eval_loss': 0.9764772057533264, 'eval_cer_jiwer': 81.55679854723911, 'eval_runtime': 24.8542, 'eval_samples_per_second': 0.362, 'eval_steps_per_second': 0.362, 'epoch': 2.92}
{'loss': 1.3202, 'grad_norm': 4.194021224975586, 'learning_rate': 1.04e-05, 'epoch': 3.31}
{'eval_loss': 0.7396972179412842, 'eval_cer_jiwer': 82.631358567147, 'eval_runtime': 24.7219, 'eval_samples_per_second': 0.364, 'eval_steps_per_second': 0.364, 'epoch': 3.92}
{'loss': 0.9556, 'grad_norm': 6.5207695960998535, 'learning_rate': 1.4400000000000001e-05, 'epoch': 4.41}
{'eval_loss': 0.450408399105072, 'eval_cer_jiwer': 79.80596420638888, 'eval_runtime': 24.8527, 'eval_samples_per_second': 0.362, 'eval_steps_per_second': 0.362, 'epoch': 4.92}
{'loss': 0.5871, 'grad_norm': 3.590184211730957, 'learning_rate': 1.8400000000000003e-05, 'epoch': 5.51}
{'eval_loss': 0.2103181928396225, 'eval_cer_jiwer': 76.96418715562972, 'eval_runtime': 24.5944, 'eval_samples_per_second': 0.366, 'eval_steps_per_second': 0.366, 'epoch': 5.92}
{'train_runtime': 1231.4755, 'train_samples_per_second': 1.267, 'train_steps_per_second': 0.146, 'train_loss': 1.2679729307139362, 'epoch': 5.92}
1231.4755 seconds used for training.
20.52 minutes used for training.
Peak reserved memory = 12.064 GB.
Saving best model (selected by CER) to /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_194128...
Saving model in recommended formats...
Detected local model directory: /home/vault/iwi5/iwi5298h/models/qwen7b
Found HuggingFace hub cache directory: /home/hpc/iwi5/iwi5298h/.cache/huggingface/hub
Copying safetensors from local directory: /home/vault/iwi5/iwi5298h/models/qwen7b
Copied safetensors index file from local model
Copied model-00005-of-00005.safetensors from local model directory
Copied model-00004-of-00005.safetensors from local model directory
Copied model-00002-of-00005.safetensors from local model directory
Copied model-00003-of-00005.safetensors from local model directory
Copied model-00001-of-00005.safetensors from local model directory
Detected local model directory: /home/vault/iwi5/iwi5298h/models/qwen7b
Found HuggingFace hub cache directory: /home/hpc/iwi5/iwi5298h/.cache/huggingface/hub
Copying safetensors from local directory: /home/vault/iwi5/iwi5298h/models/qwen7b
Copied safetensors index file from local model
Copied model-00005-of-00005.safetensors from local model directory
Copied model-00004-of-00005.safetensors from local model directory
Copied model-00002-of-00005.safetensors from local model directory
Copied model-00003-of-00005.safetensors from local model directory
Copied model-00001-of-00005.safetensors from local model directory
Best model saved successfully in multiple formats!
Releasing trainer and optimizer states from GPU (keeping best model).
Switching current best model to inference mode (no reloading).

============================================================
STARTING TEST EVALUATION WITH FEW-SHOT (k=1) & MEMORY SAFETY
============================================================
Starting evaluation on test.jsonl (few-shot with memory optimizations)...
Loaded 9 test samples
Using 1 train exemplar(s) for test few-shot.
Processing test image 1/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (6).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (6).jpg: Current CUDA Device does not support bfloat16. Please switch dtype to float16.
Processing test image 2/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (31).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (31).jpg: Current CUDA Device does not support bfloat16. Please switch dtype to float16.
Processing test image 3/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (32).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (32).jpg: Current CUDA Device does not support bfloat16. Please switch dtype to float16.
Processing test image 4/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (5).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (5).jpg: Current CUDA Device does not support bfloat16. Please switch dtype to float16.
Processing test image 5/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (40).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (40).jpg: Current CUDA Device does not support bfloat16. Please switch dtype to float16.
Processing test image 6/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (9).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (9).jpg: Current CUDA Device does not support bfloat16. Please switch dtype to float16.
Processing test image 7/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (13).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (13).jpg: Current CUDA Device does not support bfloat16. Please switch dtype to float16.
Processing test image 8/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (20).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (20).jpg: Current CUDA Device does not support bfloat16. Please switch dtype to float16.
Processing test image 9/9: FMIS_FormblaÌˆtterMielke_gefÃ¼llt (17).jpg
Error processing FMIS_FormblaÌˆtterMielke_gefÃ¼llt (17).jpg: Current CUDA Device does not support bfloat16. Please switch dtype to float16.
CER evaluation results saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_194128/cer_evaluation_results.txt

Evaluation completed!
Predictions saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_194128/test_predictions.jsonl
CER results saved to: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_194128/cer_evaluation_results.txt
All files saved in: /home/vault/iwi5/iwi5298h/models_image_text/qwen/staircase_inference/run_20251019_194128

============================================================
FINAL RESULTS SUMMARY - STAIRCASE (few-shot TEST, zero-shot VAL)
============================================================
Average CER: 1.0000 (100.00%)
Median CER:  1.0000 (100.00%)
Perfect matches: 0/9 (0.00%)
Total images processed: 9
Cleaned up temporary directory: /tmp/1243704.tinygpu/augmented_images_e7h20zjx
=== JOB_STATISTICS ===
=== current date     : Sun Oct 19 08:28:19 PM CEST 2025
= Job-ID             : 1243704 on tinygpu
= Job-Name           : stair_finetune_fewshot
= Job-Command        : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles/job_qwen2.sh
= Initial workdir    : /home/hpc/iwi5/iwi5298h/Uddipan-Thesis/jobfiles
= Queue/Partition    : v100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 18:00:00
= Elapsed runtime    : 00:47:59
= Total RAM usage    : 20.7 GiB of requested  GiB (%)   
= Node list          : tg071
= Subm/Elig/Start/End: 2025-10-19T18:45:28 / 2025-10-19T18:45:28 / 2025-10-19T19:40:10 / 2025-10-19T20:28:09
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody           144.7G  1000.0G  1500.0G        N/A     729K   5,000K   7,500K        N/A    
!!! /home/hpc             120.0G   104.9G   209.7G  -29323days  34,622      500K   1,000K        N/A !!!
    /home/vault           820.0G  1048.6G  2097.2G        N/A   3,991      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:18:00.0, 3990676, 25 %, 11 %, 12764 MiB, 2859503 ms
